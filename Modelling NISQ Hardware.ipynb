{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling NIQS Hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qiskit as qk\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit.quantum_info import DensityMatrix\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_trace(X, discard_first = True):\n",
    "    d = X.shape[0]\n",
    "    d_red = int(np.sqrt(d))\n",
    "    Y = np.zeros((d_red, d_red), dtype = \"complex128\")\n",
    "    I = np.eye(d_red)\n",
    "    \n",
    "    for i in range(d_red):\n",
    "        basis_vec = np.zeros((d_red, 1),  dtype = \"complex128\")\n",
    "        basis_vec[i, 0] = 1\n",
    "        \n",
    "        if discard_first:\n",
    "            basis_vec = np.kron(basis_vec, I)\n",
    "        else:\n",
    "            basis_vec = np.kron(I, basis_vec)\n",
    "        \n",
    "        Y = Y + basis_vec.T@X@basis_vec\n",
    "    \n",
    "    return Y\n",
    "\n",
    "\n",
    "def state_fidelity(A, B):\n",
    "    sqrtA = sqrtm(A)\n",
    "    fidelity = np.trace(sqrtm(sqrtA@B@sqrtA))\n",
    "    return np.abs(fidelity)\n",
    "\n",
    "\n",
    "def apply_map(state, choi):\n",
    "    d = state.shape[0]\n",
    "    \n",
    "    #reshuffle\n",
    "    choi = choi.reshape(d,d,d,d).swapaxes(1,2).reshape(d**2, d**2)\n",
    "    \n",
    "    #flatten\n",
    "    state = state.reshape(-1, 1)\n",
    "    \n",
    "    state = (choi@state).reshape(d, d)\n",
    "    return state\n",
    "    \n",
    "\n",
    "def prepare_input(config):\n",
    "    \"\"\"1 = |0>, 2 = |1>, 3 = |+>, 4 = |->, 5 = |+i>, 6 = |-i>\"\"\"\n",
    "    n = len(config)\n",
    "    circuit = qk.QuantumCircuit(n)\n",
    "    for i, gate in enumerate(config):\n",
    "        if gate == 2:\n",
    "            circuit.x(i)\n",
    "        if gate == 3:\n",
    "            circuit.h(i)\n",
    "        if gate == 4:\n",
    "            circuit.x(i)\n",
    "            circuit.h(i)\n",
    "        if gate == 5:\n",
    "            circuit.h(i)\n",
    "            circuit.s(i)\n",
    "        if gate == 6:\n",
    "            circuit.x(i)\n",
    "            circuit.h(i)\n",
    "            circuit.s(i)\n",
    "        \n",
    "            \n",
    "    rho = DensityMatrix(circuit)\n",
    "    return rho.data\n",
    "\n",
    "\n",
    "def generate_ginibre(dim1, dim2, real = False):\n",
    "    ginibre = np.random.normal(0, 1, (dim1, dim2))\n",
    "    if not real:\n",
    "         ginibre = ginibre + 1j*np.random.normal(0, 1, (dim1, dim2))\n",
    "    return ginibre\n",
    "\n",
    "def generate_state(dim1, dim2):\n",
    "    X = generate_ginibre(dim1, dim2)\n",
    "    \n",
    "    state = X@X.conj().T/np.trace(X@X.conj().T)\n",
    "    return state\n",
    "\n",
    "def generate_choi(X):\n",
    "    d = int(np.sqrt(X.shape[0]))  # dim of Hilbert space\n",
    "    I = np.eye(d)\n",
    "\n",
    "    #partial trace\n",
    "    Y = partial_trace(X@(X.conj().T), discard_first = True)\n",
    "    sqrtYinv = np.linalg.inv(sqrtm(Y))\n",
    "\n",
    "    #choi\n",
    "    choi = np.kron(I, sqrtYinv)@X@(X.conj().T)@np.kron(I, sqrtYinv)\n",
    "    \n",
    "    return choi\n",
    "\n",
    "\n",
    "class Adam():\n",
    "    def __init__(self, dims, lr=0.01, beta1=0.9, beta2=0.999, eps=1e-8):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        \n",
    "        self.t = 0\n",
    "        self.m = np.zeros(dims, dtype=\"complex128\")\n",
    "        self.v = np.zeros(dims, dtype=\"complex128\")\n",
    "\n",
    "\n",
    "    def __call__(self, gradient):\n",
    "        self.t += 1\n",
    "\n",
    "        self.m = self.beta1 * self.m + (1 - self.beta1) * gradient\n",
    "        self.v = self.beta2 * self.v + (1 - self.beta2) * np.abs(gradient)**2\n",
    "\n",
    "        m_hat = self.m / (1 - self.beta1**self.t)\n",
    "        v_hat = self.v / (1 - self.beta2**self.t)\n",
    "        gradient_modified = m_hat / (np.sqrt(v_hat) + self.eps)\n",
    "\n",
    "        return gradient_modified\n",
    "    \n",
    "    \n",
    "class ModelQuantumMap:\n",
    "    def __init__(self, n, rank, lr, h):\n",
    "        self.n = n\n",
    "        self.rank = rank\n",
    "        self.lr = lr\n",
    "        self.h = h\n",
    "        \n",
    "        self.d = 2**n\n",
    "        self.X_model = generate_ginibre(self.d**2, self.rank)\n",
    "        \n",
    "        self.adam = Adam(dims = (self.d**2, self.rank))\n",
    "        self.fid_list = []  \n",
    "        \n",
    "    def train(self, choi_target, num_iter, use_adam=False):\n",
    "        for step in range(num_iter):  \n",
    "            grad_matrix = np.zeros((dim1, dim2), dtype=\"complex128\")\n",
    "            indicies = [np.random.randint(1,6) for i in range(n)]\n",
    "            state_input = prepare_input(indicies)\n",
    "            state_target = apply_map(state_input, choi_target)\n",
    "            h = self.h\n",
    "    \n",
    "            for i in range(self.d**2):\n",
    "                for j in range(self.rank):\n",
    "                    \n",
    "                    #Finite difference, real value\n",
    "                    self.X_model[i, j] += h\n",
    "                    choi_plus = generate_choi(self.X_model)\n",
    "                    state_plus = apply_map(state_input, choi_plus)\n",
    "                    fid_plus = state_fidelity(state_plus, state_target)\n",
    "\n",
    "                    self.X_model[i, j] -= 2*h\n",
    "                    choi_minus = generate_choi(self.X_model)\n",
    "                    state_minus = apply_map(state_input, choi_minus)\n",
    "                    fid_minus = state_fidelity(state_minus, state_target)\n",
    "                    self.X_model[i, j] += h\n",
    "\n",
    "                    grad = (fid_plus-fid_minus)/h\n",
    "                    grad_matrix[i, j] += grad \n",
    "\n",
    "                    #Finite difference, imaginary value\n",
    "                    self.X_model[i, j] += 1j*h\n",
    "                    choi_plus = generate_choi(self.X_model)\n",
    "                    state_plus = apply_map(state_input, choi_plus)\n",
    "                    fid_plus = state_fidelity(state_plus, state_target)\n",
    "\n",
    "                    self.X_model[i, j] -= 2j*h\n",
    "                    choi_minus = generate_choi(self.X_model)\n",
    "                    state_minus = apply_map(state_input, choi_minus)\n",
    "                    fid_minus = state_fidelity(state_minus, state_target)\n",
    "                    self.X_model[i, j] += 1j*h\n",
    "\n",
    "                    grad = 1j*(fid_plus-fid_minus)/h\n",
    "                    grad_matrix[i, j] += grad\n",
    "\n",
    "            if use_adam:\n",
    "                grad_matrix = self.adam(grad_matrix)\n",
    "                \n",
    "            self.X_model += self.lr*grad_matrix\n",
    "\n",
    "            choi_model = generate_choi(self.X_model)\n",
    "            state_model = apply_map(state_input, choi_model)\n",
    "            fid = state_fidelity(state_model, state_target)\n",
    "            \n",
    "            self.fid_list.append(fid)\n",
    "            print(f\"{step}: {fid:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.351\n",
      "1: 0.386\n",
      "2: 0.265\n",
      "3: 0.482\n",
      "4: 0.315\n",
      "5: 0.408\n",
      "6: 0.419\n",
      "7: 0.390\n",
      "8: 0.418\n",
      "9: 0.483\n",
      "10: 0.290\n",
      "11: 0.453\n",
      "12: 0.626\n",
      "13: 0.397\n",
      "14: 0.627\n",
      "15: 0.477\n",
      "16: 0.388\n",
      "17: 0.646\n",
      "18: 0.333\n",
      "19: 0.551\n",
      "20: 0.423\n",
      "21: 0.474\n",
      "22: 0.412\n",
      "23: 0.572\n",
      "24: 0.552\n",
      "25: 0.447\n",
      "26: 0.433\n",
      "27: 0.676\n",
      "28: 0.440\n",
      "29: 0.529\n",
      "30: 0.480\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "d = 2**n\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X_target = generate_ginibre(d**2, 2)\n",
    "choi_target = generate_choi(X_target)\n",
    "\n",
    "model1 = ModelQuantumMap(n = 3, \n",
    "                         rank = 2, \n",
    "                         lr = 0.5, \n",
    "                         h = 1e-4)\n",
    "\n",
    "model1.train(choi_target = choi_target, \n",
    "             num_iter = 1000, \n",
    "             use_adam = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "d = 2**n\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X_target = generate_ginibre(d**2, 2)\n",
    "choi_target = generate_choi(X_target)\n",
    "\n",
    "model2 = ModelQuantumMap(n = 3, \n",
    "                         rank = 2, \n",
    "                         lr = 0.05, \n",
    "                         h = 1e-4)\n",
    "\n",
    "model2.train(choi_target = choi_target, \n",
    "            num_iter = 1000, \n",
    "            use_adam = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_qiskit",
   "language": "python",
   "name": "env_qiskit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../src_tf/')\n",
    "\n",
    "import numpy as np\n",
    "import qiskit as qk\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from qiskit.quantum_info import DensityMatrix, random_unitary\n",
    "from qiskit.quantum_info import Operator\n",
    "from scipy.linalg import sqrtm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from loss_functions import *\n",
    "from optimization import *\n",
    "from quantum_channel import *\n",
    "from quantum_tools import *\n",
    "from experimental import *\n",
    "from spam import *\n",
    "\n",
    "#np.set_printoptions(threshold=sys.maxsize)\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recover SPAM and Map\n",
    "\n",
    "### Generate True Model, Full POVM and Inital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "n = 3\n",
    "d = 2**n\n",
    "rank = 16\n",
    "c1 = 0.9\n",
    "c2 = 0.9\n",
    "\n",
    "#prep error and full POVM error\n",
    "spam_target = SPAM(d=d)\n",
    "\n",
    "init_target = c1*init_ideal(d) + (1-c1)*spam_target.init\n",
    "povm_target = c2*povm_ideal(d) + (1-c2)*spam_target.povm\n",
    "\n",
    "spam_target = SPAM(d=d,\n",
    "                  init = init_target,\n",
    "                  povm = povm_target)\n",
    "\n",
    "kraus_target = DilutedKrausMap(\n",
    "                               U=generate_unitary(d=d), \n",
    "                               c=0.1, \n",
    "                               d=d, \n",
    "                               rank=rank-1,\n",
    "                               spam = spam_target\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Synthetic Data with Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "inputs_spam, _ = generate_pauliInput_circuits(n)\n",
    "\n",
    "U_prep = inputs_spam\n",
    "N_spam = U_prep.shape[0]\n",
    "\n",
    "state = tf.repeat(spam_target.init[None,:,:], N_spam, axis=0)\n",
    "state = apply_unitary(state, U_prep)\n",
    "targets_spam = measurement(state, povm = spam_target.povm)\n",
    "\n",
    "#add noise\n",
    "targets_spam = add_noise_to_probs(targets_spam, 0.0316)\n",
    "\n",
    "inputs_map, _ = generate_pauli_circuits(n = n, \n",
    "                                        circuit_target=None, \n",
    "                                        N = 2000-6**3, \n",
    "                                        trace=False)\n",
    "U_prep, U_basis = inputs_map\n",
    "\n",
    "N_map = U_prep.shape[0]\n",
    "state = tf.repeat(tf.expand_dims(spam_target.init, axis=0), N_map, axis=0)\n",
    "state = apply_unitary(state, U_prep)\n",
    "state = kraus_target.apply_channel(state)\n",
    "targets_map = measurement(state, U_basis, spam_target.povm)\n",
    "\n",
    "#add noise\n",
    "targets_map = add_noise_to_probs(targets_map, 0.0316)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model, Initial and Corruption Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(43)\n",
    "random.seed(43)\n",
    "tf.random.set_seed(43)\n",
    "\n",
    "spam_model = SPAM(d=d,\n",
    "#                  use_corr_mat=True,\n",
    "                  optimizer = tf.optimizers.Adam(learning_rate=0.01))\n",
    "\n",
    "spam_model.pretrain(targets = [init_ideal(d), povm_ideal(d)],\n",
    "                    num_iter = 300,\n",
    "                    verbose = False,\n",
    "                    )\n",
    "\n",
    "spam_model.train(inputs = inputs_spam,\n",
    "                 targets = targets_spam,\n",
    "                 num_iter = 1000,\n",
    "                 verbose = False,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da33f8b33084e33b01115b1db6be694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None -0.213161658897458\n",
      "None -0.48236334699370936\n",
      "None -0.6571429577113861\n",
      "None -0.7466226849530683\n",
      "None -0.79748827532225\n",
      "None -0.8276846888582211\n",
      "None -0.8476475903852889\n",
      "None -0.8607127730209194\n",
      "None -0.8697895631572728\n",
      "None -0.8762998578090243\n",
      "None -0.8807792563705651\n",
      "None -0.8846222119561451\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mset_seed(\u001b[38;5;241m43\u001b[39m)\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m ModelQuantumMap(channel \u001b[38;5;241m=\u001b[39m KrausMap(d \u001b[38;5;241m=\u001b[39m d, \n\u001b[0;32m      6\u001b[0m                                            rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m,\n\u001b[0;32m      7\u001b[0m                                            spam \u001b[38;5;241m=\u001b[39m spam_model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m                         logger \u001b[38;5;241m=\u001b[39m Logger(loss_function \u001b[38;5;241m=\u001b[39m channel_fidelity_loss),\n\u001b[0;32m     12\u001b[0m                        )\n\u001b[1;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtargets_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs_val\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtargets_val\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mkraus_target\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43mN\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\ModelNISQ\\notebooks\\experiments\\../../src_tf\\optimization.py:100\u001b[0m, in \u001b[0;36mModelQuantumMap.train\u001b[1;34m(self, inputs, targets, inputs_val, targets_val, num_iter, verbose, N)\u001b[0m\n\u001b[0;32m     98\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m loss_function \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_function: \n\u001b[1;32m--> 100\u001b[0m         loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchannel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannel\u001b[38;5;241m.\u001b[39mparameter_list)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannel\u001b[38;5;241m.\u001b[39mparameter_list))\n",
      "File \u001b[1;32m~\\Documents\\ModelNISQ\\notebooks\\experiments\\../../src_tf\\loss_functions.py:50\u001b[0m, in \u001b[0;36mProbabilityMSE.__call__\u001b[1;34m(self, channel, input, target)\u001b[0m\n\u001b[0;32m     48\u001b[0m state \u001b[38;5;241m=\u001b[39m apply_unitary(state, U_prep)\n\u001b[0;32m     49\u001b[0m state \u001b[38;5;241m=\u001b[39m channel\u001b[38;5;241m.\u001b[39mapply_channel(state)\n\u001b[1;32m---> 50\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmeasurement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mU_basis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpovm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m loss \u001b[38;5;241m=\u001b[39m d\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mtf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mreduce_mean((output \u001b[38;5;241m-\u001b[39m target)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\Documents\\ModelNISQ\\notebooks\\experiments\\../../src_tf\\quantum_tools.py:156\u001b[0m, in \u001b[0;36mmeasurement\u001b[1;34m(state, U_basis, povm)\u001b[0m\n\u001b[0;32m    153\u001b[0m state \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(UstateU, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    154\u001b[0m povm \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(povm, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 156\u001b[0m probs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mtrace(\u001b[43mstate\u001b[49m\u001b[38;5;129;43m@povm\u001b[39;49m)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m probs\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_qiskit\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_qiskit\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1407\u001b[0m, in \u001b[0;36m_OverrideBinaryOperatorHelper.<locals>.binary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1403\u001b[0m   \u001b[38;5;66;03m# force_same_dtype=False to preserve existing TF behavior\u001b[39;00m\n\u001b[0;32m   1404\u001b[0m   \u001b[38;5;66;03m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[39;00m\n\u001b[0;32m   1405\u001b[0m   \u001b[38;5;66;03m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[39;00m\n\u001b[0;32m   1406\u001b[0m   x, y \u001b[38;5;241m=\u001b[39m maybe_promote_tensors(x, y)\n\u001b[1;32m-> 1407\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1408\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1409\u001b[0m   \u001b[38;5;66;03m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;66;03m# object that can implement the operator with knowledge of itself\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1413\u001b[0m   \u001b[38;5;66;03m# original error from the LHS, because it may be more\u001b[39;00m\n\u001b[0;32m   1414\u001b[0m   \u001b[38;5;66;03m# informative.\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(y), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__r\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m op_name):\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_qiskit\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3823\u001b[0m, in \u001b[0;36mmatmul_wrapper\u001b[1;34m(a, b, name)\u001b[0m\n\u001b[0;32m   3821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ops\u001b[38;5;241m.\u001b[39m_numpy_style_type_promotion:\n\u001b[0;32m   3822\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m a\u001b[38;5;241m.\u001b[39m_matmul(b)\n\u001b[1;32m-> 3823\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_qiskit\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_qiskit\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_qiskit\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3667\u001b[0m, in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[0;32m   3664\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gen_math_ops\u001b[38;5;241m.\u001b[39mbatch_mat_mul_v3(\n\u001b[0;32m   3665\u001b[0m         a, b, adj_x\u001b[38;5;241m=\u001b[39madjoint_a, adj_y\u001b[38;5;241m=\u001b[39madjoint_b, Tout\u001b[38;5;241m=\u001b[39moutput_type, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m   3666\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3667\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_math_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_mat_mul_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3668\u001b[0m \u001b[43m        \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madjoint_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madjoint_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3670\u001b[0m \u001b[38;5;66;03m# Neither matmul nor sparse_matmul support adjoint, so we conjugate\u001b[39;00m\n\u001b[0;32m   3671\u001b[0m \u001b[38;5;66;03m# the matrix and use transpose instead. Conj() is a noop for real\u001b[39;00m\n\u001b[0;32m   3672\u001b[0m \u001b[38;5;66;03m# matrices.\u001b[39;00m\n\u001b[0;32m   3673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m adjoint_a:\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_qiskit\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:1570\u001b[0m, in \u001b[0;36mbatch_mat_mul_v2\u001b[1;34m(x, y, adj_x, adj_y, name)\u001b[0m\n\u001b[0;32m   1568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   1569\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1570\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBatchMatMulV2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madj_x\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madj_y\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   1573\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(43)\n",
    "random.seed(43)\n",
    "tf.random.set_seed(43)\n",
    "\n",
    "model = ModelQuantumMap(channel = KrausMap(d = d, \n",
    "                                           rank = 64,\n",
    "                                           spam = spam_model,\n",
    "                                          ),\n",
    "                        loss_function = ProbabilityMSE(),\n",
    "                        optimizer = tf.optimizers.Adam(learning_rate=0.01),\n",
    "                        logger = Logger(loss_function = channel_fidelity_loss),\n",
    "                       )\n",
    "                       \n",
    "\n",
    "model.train(inputs = inputs_map,\n",
    "            targets = targets_map,\n",
    "            inputs_val = None,\n",
    "            targets_val = [kraus_target],\n",
    "            num_iter = 10000,\n",
    "            N = 500,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(43)\n",
    "random.seed(43)\n",
    "tf.random.set_seed(43)\n",
    "\n",
    "model = ModelQuantumMap(channel = KrausMap(d = d, \n",
    "                                           rank = 64,\n",
    "                                           spam = spam_model,\n",
    "                                          ),\n",
    "                        loss_function = ProbabilityMSE(),\n",
    "                        optimizer = tf.optimizers.Adam(learning_rate=0.01),\n",
    "                        logger = Logger(loss_function = channel_fidelity_loss),\n",
    "                       )\n",
    "                       \n",
    "\n",
    "model.train(inputs = inputs_map,\n",
    "            targets = targets_map,\n",
    "            inputs_val = None,\n",
    "            targets_val = [kraus_target],\n",
    "            num_iter = 10000,\n",
    "            N = 500,\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_qiskit",
   "language": "python",
   "name": "env_qiskit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

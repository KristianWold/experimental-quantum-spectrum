{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lindbladian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../src_tf/')\n",
    "\n",
    "import numpy as np\n",
    "import qiskit as qk\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from qiskit.quantum_info import DensityMatrix, random_unitary\n",
    "from qiskit.quantum_info import Operator\n",
    "from scipy.linalg import sqrtm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from loss_functions import *\n",
    "from optimization import *\n",
    "from quantum_channel import *\n",
    "from quantum_tools import *\n",
    "from experimental import *\n",
    "from spam import *\n",
    "\n",
    "#np.set_printoptions(threshold=sys.maxsize)\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "n = 2\n",
    "d = 2**n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelQuantumMap(\n",
    "                       # channel = LindbladMap(d, rank=d**2),\n",
    "                        channel = KrausMap(d, rank=d**2),\n",
    "                        loss_function = Conj3(index = 1, sign =-1),\n",
    "                        optimizer = tf.optimizers.Adam(learning_rate=0.005),\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7783a14f5ceb4ed5b58a63e16a10f20e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:0, train: -0.0001418699213523943\n",
      "Step:1, train: -0.0002077159466784163\n",
      "Step:2, train: -0.00022946448184104647\n",
      "Step:3, train: -0.0002419461213667737\n",
      "Step:4, train: -0.00027960750766922916\n",
      "Step:5, train: -0.00033719193123189247\n",
      "Step:6, train: -0.0004122398173001311\n",
      "Step:7, train: -0.0004964359189398318\n",
      "Step:8, train: -0.000534773728923086\n",
      "Step:9, train: -0.0005707515274779834\n",
      "Step:10, train: -0.0006388650374267328\n",
      "Step:11, train: -0.0007069936235092311\n",
      "Step:12, train: -0.0007091592662494515\n",
      "Step:13, train: -0.0007455670309957648\n",
      "Step:14, train: -0.0007797938391596686\n",
      "Step:15, train: -0.000810824109518607\n",
      "Step:16, train: -0.0008619416872459445\n",
      "Step:17, train: -0.0009297996405620402\n",
      "Step:18, train: -0.0009586206955581254\n",
      "Step:19, train: -0.0009965588603652704\n",
      "Step:20, train: -0.0010139270697791134\n",
      "Step:21, train: -0.0010517809594427475\n",
      "Step:22, train: -0.0010770183639882353\n",
      "Step:23, train: -0.0011008859963854804\n",
      "Step:24, train: -0.0011282249813351687\n",
      "Step:25, train: -0.001176932277799206\n",
      "Step:26, train: -0.001200458986769809\n",
      "Step:27, train: -0.0012535225235357087\n",
      "Step:28, train: -0.001291080701437264\n",
      "Step:29, train: -0.0013367238680149214\n",
      "Step:30, train: -0.0013688021023975947\n",
      "Step:31, train: -0.0014271327128102598\n",
      "Step:32, train: -0.0014584462536531247\n",
      "Step:33, train: -0.0014825604153410035\n",
      "Step:34, train: -0.0015145478469271397\n",
      "Step:35, train: -0.0015698569001940295\n",
      "Step:36, train: -0.001592041686436136\n",
      "Step:37, train: -0.0016457551572760913\n",
      "Step:38, train: -0.0016919638147430758\n",
      "Step:39, train: -0.001726829974500416\n",
      "Step:40, train: -0.0017500233441275024\n",
      "Step:41, train: -0.00179968529317905\n",
      "Step:42, train: -0.00187137338323628\n",
      "Step:43, train: -0.0018963577111319263\n",
      "Step:44, train: -0.001958918717769078\n",
      "Step:45, train: -0.0019933076790089833\n",
      "Step:46, train: -0.0020416766200220928\n",
      "Step:47, train: -0.0020588711078735637\n",
      "Step:48, train: -0.002099382319618583\n",
      "Step:49, train: -0.002148955110854485\n",
      "Step:50, train: -0.0021921227537959513\n",
      "Step:51, train: -0.002245324497617138\n",
      "Step:52, train: -0.002264556598448367\n",
      "Step:53, train: -0.002298260345844148\n",
      "Step:54, train: -0.0023614885599449486\n",
      "Step:55, train: -0.002427261474745949\n",
      "Step:56, train: -0.0024603162082799854\n",
      "Step:57, train: -0.0024928307690612887\n",
      "Step:58, train: -0.0025405940403306604\n",
      "Step:59, train: -0.0025974797911281033\n",
      "Step:60, train: -0.002636708430600606\n",
      "Step:61, train: -0.002694233662390167\n",
      "Step:62, train: -0.00276394530308653\n",
      "Step:63, train: -0.0028092951078520093\n",
      "Step:64, train: -0.0028830023621935746\n",
      "Step:65, train: -0.002907344278850407\n",
      "Step:66, train: -0.002983359070716991\n",
      "Step:67, train: -0.003055083621114199\n",
      "Step:68, train: -0.0030742597600927936\n",
      "Step:69, train: -0.003134908210599821\n",
      "Step:70, train: -0.00313945744355249\n",
      "Step:71, train: -0.0032063914389513296\n",
      "Step:72, train: -0.0032899540955748465\n",
      "Step:73, train: -0.0033167357751979604\n",
      "Step:74, train: -0.003396102275331444\n",
      "Step:75, train: -0.003460436345549546\n",
      "Step:76, train: -0.003538651738330655\n",
      "Step:77, train: -0.0036364647051594524\n",
      "Step:78, train: -0.003700062073985042\n",
      "Step:79, train: -0.0037184796884625997\n",
      "Step:80, train: -0.0037789516027758423\n",
      "Step:81, train: -0.0038731296154024203\n",
      "Step:82, train: -0.003946462726149897\n",
      "Step:83, train: -0.0039900592520111175\n",
      "Step:84, train: -0.004088648812196477\n",
      "Step:85, train: -0.004165097046323329\n",
      "Step:86, train: -0.004216702088797415\n",
      "Step:87, train: -0.004294932084269407\n",
      "Step:88, train: -0.004344863919591297\n",
      "Step:89, train: -0.0044025702069122995\n",
      "Step:90, train: -0.00451043491501542\n",
      "Step:91, train: -0.004571163836780305\n",
      "Step:92, train: -0.004631104139293687\n",
      "Step:93, train: -0.004740615016786106\n",
      "Step:94, train: -0.004844733962185196\n",
      "Step:95, train: -0.004923877231144088\n",
      "Step:96, train: -0.004981282035172674\n",
      "Step:97, train: -0.00507855017306234\n",
      "Step:98, train: -0.005149638113044225\n",
      "Step:99, train: -0.0051954259914864485\n",
      "Step:100, train: -0.005319056835806454\n",
      "Step:101, train: -0.005409890271258896\n",
      "Step:102, train: -0.005500319852732862\n",
      "Step:103, train: -0.005603604406599859\n",
      "Step:104, train: -0.005693484766028796\n",
      "Step:105, train: -0.005754782371642226\n",
      "Step:106, train: -0.005843753424728983\n",
      "Step:107, train: -0.005928551654983521\n",
      "Step:108, train: -0.006068893155486398\n",
      "Step:109, train: -0.0061655893462217145\n",
      "Step:110, train: -0.006259854875841803\n",
      "Step:111, train: -0.006336246679045931\n",
      "Step:112, train: -0.00648572354629201\n",
      "Step:113, train: -0.006561972326282462\n",
      "Step:114, train: -0.006658321167529744\n",
      "Step:115, train: -0.006751662530903383\n",
      "Step:116, train: -0.006900385907406421\n",
      "Step:117, train: -0.007016097792571957\n",
      "Step:118, train: -0.007090400351173105\n",
      "Step:119, train: -0.007113954773772011\n",
      "Step:120, train: -0.007184285027697104\n",
      "Step:121, train: -0.007360819159746508\n",
      "Step:122, train: -0.007497102736818089\n",
      "Step:123, train: -0.007614880915839808\n",
      "Step:124, train: -0.007758303349895402\n",
      "Step:125, train: -0.007799744052806835\n",
      "Step:126, train: -0.007929868300956346\n",
      "Step:127, train: -0.007983117499552116\n",
      "Step:128, train: -0.008163792696007257\n",
      "Step:129, train: -0.008332251010893047\n",
      "Step:130, train: -0.008510665050124714\n",
      "Step:131, train: -0.008561503041499241\n",
      "Step:132, train: -0.008767501019193769\n",
      "Step:133, train: -0.008938236237394068\n",
      "Step:134, train: -0.009106144054915558\n",
      "Step:135, train: -0.0091048578956835\n",
      "Step:136, train: -0.00926185893039243\n",
      "Step:137, train: -0.009545749905640367\n",
      "Step:138, train: -0.009680646762626364\n",
      "Step:139, train: -0.009845849340169468\n",
      "Step:140, train: -0.010071474617982943\n",
      "Step:141, train: -0.010274347189691757\n",
      "Step:142, train: -0.010388319824705802\n",
      "Step:143, train: -0.010552454343003136\n",
      "Step:144, train: -0.010763101165243774\n",
      "Step:145, train: -0.01085048391053629\n",
      "Step:146, train: -0.011041024694001462\n",
      "Step:147, train: -0.011282373851742845\n",
      "Step:148, train: -0.011461819079233533\n",
      "Step:149, train: -0.01154050034183709\n",
      "Step:150, train: -0.011754817051803817\n",
      "Step:151, train: -0.012015556347534\n",
      "Step:152, train: -0.012090094478110117\n",
      "Step:153, train: -0.01231270407611371\n",
      "Step:154, train: -0.012514384716840332\n",
      "Step:155, train: -0.012692251450768657\n",
      "Step:156, train: -0.012993863319270613\n",
      "Step:157, train: -0.013204864341622493\n",
      "Step:158, train: -0.013532853955877455\n",
      "Step:159, train: -0.013778948359281985\n",
      "Step:160, train: -0.013929112391697201\n",
      "Step:161, train: -0.014058941228034727\n",
      "Step:162, train: -0.014308888900640323\n",
      "Step:163, train: -0.014616331618431152\n",
      "Step:164, train: -0.014891607107761076\n",
      "Step:165, train: -0.01513924861846188\n",
      "Step:166, train: -0.015275340116939023\n",
      "Step:167, train: -0.015531342241845643\n",
      "Step:168, train: -0.01597129705013071\n",
      "Step:169, train: -0.016270800107221154\n",
      "Step:170, train: -0.016484074390634953\n",
      "Step:171, train: -0.016778485557531704\n",
      "Step:172, train: -0.01688657707738375\n",
      "Step:173, train: -0.017294399624676382\n",
      "Step:174, train: -0.017517759887589263\n",
      "Step:175, train: -0.017621566241146986\n",
      "Step:176, train: -0.018005130962267826\n",
      "Step:177, train: -0.018311471278681945\n",
      "Step:178, train: -0.01864353954299663\n",
      "Step:179, train: -0.01909060197192187\n",
      "Step:180, train: -0.01938236691042366\n",
      "Step:181, train: -0.019804540244567\n",
      "Step:182, train: -0.020051504822427582\n",
      "Step:183, train: -0.020419317607170653\n",
      "Step:184, train: -0.02067448959551376\n",
      "Step:185, train: -0.021104359972513274\n",
      "Step:186, train: -0.021173936310655797\n",
      "Step:187, train: -0.021387571476042876\n",
      "Step:188, train: -0.02147571566655803\n",
      "Step:189, train: -0.02168878132516597\n",
      "Step:190, train: -0.022017079556673712\n",
      "Step:191, train: -0.022185141222238133\n",
      "Step:192, train: -0.02251457159095545\n",
      "Step:193, train: -0.02268445887726462\n",
      "Step:194, train: -0.02287192279520366\n",
      "Step:195, train: -0.023097456616972944\n",
      "Step:196, train: -0.023269487575287788\n",
      "Step:197, train: -0.02368926168115759\n",
      "Step:198, train: -0.02406502843708583\n",
      "Step:199, train: -0.024283334328704154\n",
      "Step:200, train: -0.024432163863659484\n",
      "Step:201, train: -0.024475548480067204\n",
      "Step:202, train: -0.024705754858002842\n",
      "Step:203, train: -0.025117038622857184\n",
      "Step:204, train: -0.025655169092564125\n",
      "Step:205, train: -0.026005546330518044\n",
      "Step:206, train: -0.02612934656451312\n",
      "Step:207, train: -0.02658029583576499\n",
      "Step:208, train: -0.026844834269236804\n",
      "Step:209, train: -0.02712166893430618\n",
      "Step:210, train: -0.027265473778748373\n",
      "Step:211, train: -0.027637449567868563\n",
      "Step:212, train: -0.028116806714675893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:213, train: -0.028477684797354227\n",
      "Step:214, train: -0.028742956794638532\n",
      "Step:215, train: -0.028953220572798654\n",
      "Step:216, train: -0.029339126054703738\n",
      "Step:217, train: -0.02990565398656004\n",
      "Step:218, train: -0.03008038272272897\n",
      "Step:219, train: -0.030418632593750765\n",
      "Step:220, train: -0.030714262578470364\n",
      "Step:221, train: -0.03106129314280373\n",
      "Step:222, train: -0.0316590306144999\n",
      "Step:223, train: -0.032080619257954184\n",
      "Step:224, train: -0.0323416861501549\n",
      "Step:225, train: -0.0326434500627988\n",
      "Step:226, train: -0.03335410852529727\n",
      "Step:227, train: -0.03377075229283513\n",
      "Step:228, train: -0.03409989626294574\n",
      "Step:229, train: -0.034480983979264815\n",
      "Step:230, train: -0.03498593927660917\n",
      "Step:231, train: -0.03551546303893327\n",
      "Step:232, train: -0.03602851673066498\n",
      "Step:233, train: -0.03641602133720351\n",
      "Step:234, train: -0.03672478407224903\n",
      "Step:235, train: -0.0372200861669417\n",
      "Step:236, train: -0.03788824517029659\n",
      "Step:237, train: -0.03826958911202121\n",
      "Step:238, train: -0.03870887100351776\n",
      "Step:239, train: -0.039175629512331604\n",
      "Step:240, train: -0.039534265814662996\n",
      "Step:241, train: -0.03985609222929136\n",
      "Step:242, train: -0.04024720207661672\n",
      "Step:243, train: -0.04099997722956027\n",
      "Step:244, train: -0.04149447390201445\n",
      "Step:245, train: -0.042108584057362286\n",
      "Step:246, train: -0.042576098208557775\n",
      "Step:247, train: -0.04295992044298917\n",
      "Step:248, train: -0.043658821046522876\n",
      "Step:249, train: -0.04398841332517518\n",
      "Step:250, train: -0.04445986712880668\n",
      "Step:251, train: -0.04527078870215152\n",
      "Step:252, train: -0.0458339672240113\n",
      "Step:253, train: -0.046480952199866615\n",
      "Step:254, train: -0.04707845302922274\n",
      "Step:255, train: -0.04750157547018559\n",
      "Step:256, train: -0.04779962289962779\n",
      "Step:257, train: -0.048165719538440246\n",
      "Step:258, train: -0.04912173398655189\n",
      "Step:259, train: -0.04940043274597946\n",
      "Step:260, train: -0.047829690929348814\n",
      "Step:261, train: -0.05067401803749693\n",
      "Step:262, train: -0.05113574919090183\n",
      "Step:263, train: -0.05148075231516115\n",
      "Step:264, train: -0.051890523912220377\n",
      "Step:265, train: -0.051756595345561325\n",
      "Step:266, train: -0.05263776195411853\n",
      "Step:267, train: -0.052997331475490066\n",
      "Step:268, train: -0.05335320074053059\n",
      "Step:269, train: -0.05377107348933577\n",
      "Step:270, train: -0.05420868400391308\n",
      "Step:271, train: -0.05497038142995739\n",
      "Step:272, train: -0.055452604490809174\n",
      "Step:273, train: -0.056136619910113046\n",
      "Step:274, train: -0.05695030274779904\n",
      "Step:275, train: -0.057786681378017866\n",
      "Step:276, train: -0.05814281787619487\n",
      "Step:277, train: -0.058941445980065885\n",
      "Step:278, train: -0.059210433145832714\n",
      "Step:279, train: -0.05996528155508703\n",
      "Step:280, train: -0.05993494329367777\n",
      "Step:281, train: -0.060384835517047854\n",
      "Step:282, train: -0.06093585039186473\n",
      "Step:283, train: -0.06184432172653167\n",
      "Step:284, train: -0.06296073307648146\n",
      "Step:285, train: -0.06358049086853391\n",
      "Step:286, train: -0.0640860256009656\n",
      "Step:287, train: -0.06487232249250312\n",
      "Step:288, train: -0.06449626669964065\n",
      "Step:289, train: -0.06537171069586678\n",
      "Step:290, train: -0.06749210434835155\n",
      "Step:291, train: -0.06824221625090078\n",
      "Step:292, train: -0.06792139696995002\n",
      "Step:293, train: -0.06891815404861809\n",
      "Step:294, train: -0.06993025182712605\n",
      "Step:295, train: -0.07069285580241697\n",
      "Step:296, train: -0.0711292292721066\n",
      "Step:297, train: -0.07179003749163233\n",
      "Step:298, train: -0.07252259920974313\n",
      "Step:299, train: -0.07330490505633903\n",
      "Step:300, train: -0.07387888075749433\n",
      "Step:301, train: -0.07465285547628445\n",
      "Step:302, train: -0.07568677823487886\n",
      "Step:303, train: -0.07675816017667429\n",
      "Step:304, train: -0.07766490394372\n",
      "Step:305, train: -0.07886629123088773\n",
      "Step:306, train: -0.07868618924765679\n",
      "Step:307, train: -0.08006527848481634\n",
      "Step:308, train: -0.07992450088960801\n",
      "Step:309, train: -0.08084386836889448\n",
      "Step:310, train: -0.0733662243824549\n",
      "Step:311, train: -0.08162175278372388\n",
      "Step:312, train: -0.08173562822583184\n",
      "Step:313, train: -0.08265484093411125\n",
      "Step:314, train: -0.08429605391216537\n",
      "Step:315, train: -0.08501348034753076\n",
      "Step:316, train: -0.0858611107078214\n",
      "Step:317, train: -0.08480199859024523\n",
      "Step:318, train: -0.0862389598167256\n",
      "Step:319, train: -0.0872617747176162\n",
      "Step:320, train: -0.08776618012419292\n",
      "Step:321, train: -0.08946218023513033\n",
      "Step:322, train: -0.08963938165544125\n",
      "Step:323, train: -0.090198404452483\n",
      "Step:324, train: -0.09101221658047934\n",
      "Step:325, train: -0.09204929504046662\n",
      "Step:326, train: -0.09260255459864633\n",
      "Step:327, train: -0.09328004303242565\n",
      "Step:328, train: -0.09421806352879694\n",
      "Step:329, train: -0.09485625539610157\n",
      "Step:330, train: -0.09548170937594663\n",
      "Step:331, train: -0.09644613907542386\n",
      "Step:332, train: -0.09752105454598077\n",
      "Step:333, train: -0.09867462941092542\n",
      "Step:334, train: -0.09993161664224699\n",
      "Step:335, train: -0.09943312070420193\n",
      "Step:336, train: -0.10167949079916988\n",
      "Step:337, train: -0.10268712127526988\n",
      "Step:338, train: -0.10065186995011237\n",
      "Step:339, train: -0.10123392061164113\n",
      "Step:340, train: -0.10414990876867702\n",
      "Step:341, train: -0.10476280966197181\n",
      "Step:342, train: -0.10549753956070454\n",
      "Step:343, train: -0.10578530069334645\n",
      "Step:344, train: -0.10648487909909195\n",
      "Step:345, train: -0.10767062227416918\n",
      "Step:346, train: -0.10797863041016884\n",
      "Step:347, train: -0.10931864018350196\n",
      "Step:348, train: -0.11026364509219154\n",
      "Step:349, train: -0.11093600703881198\n",
      "Step:350, train: -0.11239324769154557\n",
      "Step:351, train: -0.11469604838840913\n",
      "Step:352, train: -0.11600813305225738\n",
      "Step:353, train: -0.1171623669006658\n",
      "Step:354, train: -0.11870061236351727\n",
      "Step:355, train: -0.1200325730053085\n",
      "Step:356, train: -0.12095765234455452\n",
      "Step:357, train: -0.12069565243253536\n",
      "Step:358, train: -0.1222924074301091\n",
      "Step:359, train: -0.12459167905426918\n",
      "Step:360, train: -0.12623632106499763\n",
      "Step:361, train: -0.12789101093372707\n",
      "Step:362, train: -0.12856292174451592\n",
      "Step:363, train: -0.12980010834989605\n",
      "Step:364, train: -0.13143201953965158\n",
      "Step:365, train: -0.13315143863538692\n",
      "Step:366, train: -0.1321980592570164\n",
      "Step:367, train: -0.1342401012970746\n",
      "Step:368, train: -0.13694732204736468\n",
      "Step:369, train: -0.13814492151453006\n",
      "Step:370, train: -0.13954192655624992\n",
      "Step:371, train: -0.1414710707829228\n",
      "Step:372, train: -0.1434945500739929\n",
      "Step:373, train: -0.14568194970687467\n",
      "Step:374, train: -0.14771292301784988\n",
      "Step:375, train: -0.14998971744526157\n",
      "Step:376, train: -0.15236382405747717\n",
      "Step:377, train: -0.15481659248413626\n",
      "Step:378, train: -0.1564774405888015\n",
      "Step:379, train: -0.15855344692806767\n",
      "Step:380, train: -0.16073867116010188\n",
      "Step:381, train: -0.16265234163015826\n",
      "Step:382, train: -0.1654021274681842\n",
      "Step:383, train: -0.16724256671827012\n",
      "Step:384, train: -0.16954002068936802\n",
      "Step:385, train: -0.17274855038083953\n",
      "Step:386, train: -0.1748777887547229\n",
      "Step:387, train: -0.17711175670737092\n",
      "Step:388, train: -0.1796071305934742\n",
      "Step:389, train: -0.18193182747259043\n",
      "Step:390, train: -0.18452511249388936\n",
      "Step:391, train: -0.18678877459089588\n",
      "Step:392, train: -0.18980885992655033\n",
      "Step:393, train: -0.193470407109051\n",
      "Step:394, train: -0.1970922098552313\n",
      "Step:395, train: -0.19798137778142347\n",
      "Step:396, train: -0.2015784725956595\n",
      "Step:397, train: -0.2061009225798184\n",
      "Step:398, train: -0.20893916376275204\n",
      "Step:399, train: -0.2128260393800807\n",
      "Step:400, train: -0.21761249333233884\n",
      "Step:401, train: -0.22107936862771044\n",
      "Step:402, train: -0.22540075420210057\n",
      "Step:403, train: -0.2297267286202763\n",
      "Step:404, train: -0.23402749382855687\n",
      "Step:405, train: -0.2387717218097989\n",
      "Step:406, train: -0.24396770908499152\n",
      "Step:407, train: -0.24922861031111362\n",
      "Step:408, train: -0.2533279114389536\n",
      "Step:409, train: -0.2584071390786913\n",
      "Step:410, train: -0.2636531577623743\n",
      "Step:411, train: -0.26883488942339334\n",
      "Step:412, train: -0.27475822840975805\n",
      "Step:413, train: -0.28139318295133287\n",
      "Step:414, train: -0.2878689874070824\n",
      "Step:415, train: -0.29471990033952994\n",
      "Step:416, train: -0.3005110954107119\n",
      "Step:417, train: -0.3065996920126215\n",
      "Step:418, train: -0.3135566435838071\n",
      "Step:419, train: -0.3214223109165315\n",
      "Step:420, train: -0.32930006005606416\n",
      "Step:421, train: -0.3376200294265316\n",
      "Step:422, train: -0.34593957185802915\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mN\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\ModelNISQ\\notebooks\\experiments\\../../src_tf\\optimization.py:81\u001b[0m, in \u001b[0;36mModelQuantumMap.train\u001b[1;34m(self, inputs, targets, inputs_val, targets_val, num_iter, N)\u001b[0m\n\u001b[0;32m     79\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m loss_function \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_function: \n\u001b[1;32m---> 81\u001b[0m         loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchannel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannel\u001b[38;5;241m.\u001b[39mparameter_list)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannel\u001b[38;5;241m.\u001b[39mparameter_list))\n",
      "File \u001b[1;32m~\\Documents\\ModelNISQ\\notebooks\\experiments\\../../src_tf\\loss_functions.py:221\u001b[0m, in \u001b[0;36mConj3.__call__\u001b[1;34m(self, channel, input, target)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, channel, \u001b[38;5;28minput\u001b[39m, target):\n\u001b[0;32m    220\u001b[0m     d \u001b[38;5;241m=\u001b[39m channel\u001b[38;5;241m.\u001b[39md\n\u001b[1;32m--> 221\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43mchannel_spectrum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msign\u001b[38;5;241m*\u001b[39mtf\u001b[38;5;241m.\u001b[39mabs(z[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39md \u001b[38;5;241m-\u001b[39m tf\u001b[38;5;241m.\u001b[39mabs(tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mreduce_prod(z))\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\Documents\\ModelNISQ\\notebooks\\experiments\\../../src_tf\\quantum_channel.py:89\u001b[0m, in \u001b[0;36mchannel_spectrum\u001b[1;34m(channel, real)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchannel_spectrum\u001b[39m(channel, real\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 89\u001b[0m     eig, _ \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39meig(reshuffle(\u001b[43mchannel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoi\u001b[49m))\n\u001b[0;32m     90\u001b[0m     eig \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(eig, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m real:\n",
      "File \u001b[1;32m~\\Documents\\ModelNISQ\\notebooks\\experiments\\../../src_tf\\quantum_channel.py:201\u001b[0m, in \u001b[0;36mKrausMap.choi\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;129m@property\u001b[39m    \n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchoi\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkraus_to_choi\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\ModelNISQ\\notebooks\\experiments\\../../src_tf\\quantum_channel.py:34\u001b[0m, in \u001b[0;36mkraus_to_choi\u001b[1;34m(kraus_channel, use_reshuffle)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(rank):\n\u001b[0;32m     33\u001b[0m     K \u001b[38;5;241m=\u001b[39m kraus[\u001b[38;5;241m0\u001b[39m, i]\n\u001b[1;32m---> 34\u001b[0m     channel \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkron\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_reshuffle:\n\u001b[0;32m     37\u001b[0m     choi \u001b[38;5;241m=\u001b[39m reshuffle(channel)\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_qiskit\\lib\\site-packages\\tensorflow\\python\\ops\\numpy_ops\\np_math_ops.py:408\u001b[0m, in \u001b[0;36mkron\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m    406\u001b[0m a_shape \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mshape(t_a)\n\u001b[0;32m    407\u001b[0m b_shape \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mshape(t_b)\n\u001b[1;32m--> 408\u001b[0m a_reshaped \u001b[38;5;241m=\u001b[39m np_array_ops\u001b[38;5;241m.\u001b[39mreshape(t_a, \u001b[43m_make_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[0;32m    409\u001b[0m b_reshaped \u001b[38;5;241m=\u001b[39m np_array_ops\u001b[38;5;241m.\u001b[39mreshape(t_b, _make_shape(b_shape, \u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m    410\u001b[0m out_shape \u001b[38;5;241m=\u001b[39m a_shape \u001b[38;5;241m*\u001b[39m b_shape\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_qiskit\\lib\\site-packages\\tensorflow\\python\\ops\\numpy_ops\\np_math_ops.py:399\u001b[0m, in \u001b[0;36mkron.<locals>._make_shape\u001b[1;34m(shape, prepend)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_shape\u001b[39m(shape, prepend):\n\u001b[1;32m--> 399\u001b[0m   ones \u001b[38;5;241m=\u001b[39m \u001b[43marray_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    400\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m prepend:\n\u001b[0;32m    401\u001b[0m     shapes \u001b[38;5;241m=\u001b[39m [ones, shape]\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_qiskit\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_qiskit\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_qiskit\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:3185\u001b[0m, in \u001b[0;36mones_like\u001b[1;34m(tensor, dtype, name, optimize)\u001b[0m\n\u001b[0;32m   3154\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mones_like\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   3155\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39mregister_unary_elementwise_api\n\u001b[0;32m   3156\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[0;32m   3157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mones_like\u001b[39m(tensor, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, optimize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   3158\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a tensor with all elements set to 1.\u001b[39;00m\n\u001b[0;32m   3159\u001b[0m \n\u001b[0;32m   3160\u001b[0m \u001b[38;5;124;03m  See also `tf.ones`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3183\u001b[0m \u001b[38;5;124;03m    A `Tensor` with all elements set to 1.\u001b[39;00m\n\u001b[0;32m   3184\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3185\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mones_like_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_qiskit\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:3231\u001b[0m, in \u001b[0;36mones_like_impl\u001b[1;34m(tensor, dtype, name, optimize)\u001b[0m\n\u001b[0;32m   3229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3230\u001b[0m   dtype \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m-> 3231\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43mones_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m   3233\u001b[0m   ret\u001b[38;5;241m.\u001b[39mset_shape(tensor\u001b[38;5;241m.\u001b[39mget_shape())\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_qiskit\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_qiskit\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_qiskit\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:3288\u001b[0m, in \u001b[0;36mones\u001b[1;34m(shape, dtype, name)\u001b[0m\n\u001b[0;32m   3286\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m shape\u001b[38;5;241m.\u001b[39m_shape_tuple():\n\u001b[0;32m   3287\u001b[0m     shape \u001b[38;5;241m=\u001b[39m reshape(shape, [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# Ensure it's a vector\u001b[39;00m\n\u001b[1;32m-> 3288\u001b[0m   output \u001b[38;5;241m=\u001b[39m \u001b[43mfill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3289\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m output\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype \u001b[38;5;241m==\u001b[39m dtype\n\u001b[0;32m   3290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_qiskit\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_qiskit\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_qiskit\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:243\u001b[0m, in \u001b[0;36mfill\u001b[1;34m(dims, value, name)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfill\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    205\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfill\u001b[39m(dims, value, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m   \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a tensor filled with a scalar value.\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m  See also `tf.ones`, `tf.zeros`, `tf.one_hot`, `tf.eye`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;124;03m  @end_compatibility\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    244\u001b[0m   tensor_util\u001b[38;5;241m.\u001b[39mmaybe_set_static_shape(result, dims)\n\u001b[0;32m    245\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\env_qiskit\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:3500\u001b[0m, in \u001b[0;36mfill\u001b[1;34m(dims, value, name)\u001b[0m\n\u001b[0;32m   3498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   3499\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3500\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3501\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFill\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3503\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(inputs = [],\n",
    "            targets = [],\n",
    "            num_iter = 1000,\n",
    "            N = 0,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.loss_function = [Conj3(index = 1, sign = 1)]\n",
    "model.zero_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1063a5d93f4bec90a668ffd493a947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:0, train: 0.030713805290953137\n",
      "Step:1, train: 0.028699223894213064\n",
      "Step:2, train: 0.02678004630193693\n",
      "Step:3, train: 0.024962899238517564\n",
      "Step:4, train: 0.023251341638317893\n",
      "Step:5, train: 0.021646327481176137\n",
      "Step:6, train: 0.02014680975901247\n",
      "Step:7, train: 0.018750028862025432\n",
      "Step:8, train: 0.01745177296493724\n",
      "Step:9, train: 0.01624673617991047\n",
      "Step:10, train: 0.015128911364634198\n",
      "Step:11, train: 0.014092019432391927\n",
      "Step:12, train: 0.01312985724684231\n",
      "Step:13, train: 0.012236527562145365\n",
      "Step:14, train: 0.011406564196958898\n",
      "Step:15, train: 0.0106349645879232\n",
      "Step:16, train: 0.00991718385842708\n",
      "Step:17, train: 0.009249102735846101\n",
      "Step:18, train: 0.008626987677849236\n",
      "Step:19, train: 0.008047449991388967\n",
      "Step:20, train: 0.0075074000500233605\n",
      "Step:21, train: 0.00700401067240871\n",
      "Step:22, train: 0.006534687076137381\n",
      "Step:23, train: 0.0060970376976881785\n",
      "Step:24, train: 0.005688852428500489\n",
      "Step:25, train: 0.005308083379575189\n",
      "Step:26, train: 0.004952830995845784\n",
      "Step:27, train: 0.004621329932816632\n",
      "Step:28, train: 0.0043119383871786125\n",
      "Step:29, train: 0.00402312869939265\n",
      "Step:30, train: 0.003753479889237004\n",
      "Step:31, train: 0.0035016693489768637\n",
      "Step:32, train: 0.003266467286996281\n",
      "Step:33, train: 0.003046730105904819\n",
      "Step:34, train: 0.0028413958307183466\n",
      "Step:35, train: 0.002649479021940374\n",
      "Step:36, train: 0.0024700657961952595\n",
      "Step:37, train: 0.0023023093977028314\n",
      "Step:38, train: 0.002145427376560957\n",
      "Step:39, train: 0.0019986969241526337\n",
      "Step:40, train: 0.0018614512688793564\n",
      "Step:41, train: 0.001733076714844019\n",
      "Step:42, train: 0.0016130100134534033\n",
      "Step:43, train: 0.001500733960595566\n",
      "Step:44, train: 0.0013957752851221543\n",
      "Step:45, train: 0.0012977006856664285\n",
      "Step:46, train: 0.0012061142584906678\n",
      "Step:47, train: 0.0011206528938895294\n",
      "Step:48, train: 0.0010409830671553313\n",
      "Step:49, train: 0.0009667965548800567\n",
      "Step:50, train: 0.0008978057051592736\n",
      "Step:51, train: 0.0008337393958843265\n",
      "Step:52, train: 0.0007743386157182041\n",
      "Step:53, train: 0.0007193521939009627\n",
      "Step:54, train: 0.0006685341856160352\n",
      "Step:55, train: 0.0006216410747744864\n",
      "Step:56, train: 0.0005784307153850991\n",
      "Step:57, train: 0.0005386623780162794\n",
      "Step:58, train: 0.0005020977592770407\n",
      "Step:59, train: 0.00046850226833840074\n",
      "Step:60, train: 0.0004376473289350824\n",
      "Step:61, train: 0.0004093125750005385\n",
      "Step:62, train: 0.00038328759717597453\n",
      "Step:63, train: 0.00035937375129369427\n",
      "Step:64, train: 0.0003373852302424211\n",
      "Step:65, train: 0.00031714960050424694\n",
      "Step:66, train: 0.00029850811634024636\n",
      "Step:67, train: 0.00028131555141089126\n",
      "Step:68, train: 0.0002654395492664242\n",
      "Step:69, train: 0.000250760049512804\n",
      "Step:70, train: 0.00023716848552494526\n",
      "Step:71, train: 0.00022456674323540087\n",
      "Step:72, train: 0.00021286644651200354\n",
      "Step:73, train: 0.00020198795748999838\n",
      "Step:74, train: 0.00019185953134892396\n",
      "Step:75, train: 0.00018241655121514725\n",
      "Step:76, train: 0.00017360075564993959\n",
      "Step:77, train: 0.000165359636818057\n",
      "Step:78, train: 0.00015764581663049837\n",
      "Step:79, train: 0.00015041643041201335\n",
      "Step:80, train: 0.00014363272608031475\n",
      "Step:81, train: 0.00013725961757850224\n",
      "Step:82, train: 0.0001312652805223698\n",
      "Step:83, train: 0.00012562079883430863\n",
      "Step:84, train: 0.0001202999017818734\n",
      "Step:85, train: 0.00011527863426751205\n",
      "Step:86, train: 0.00011053520480043327\n",
      "Step:87, train: 0.00010604966416958416\n",
      "Step:88, train: 0.00010180380301283694\n",
      "Step:89, train: 9.778099194370692e-05\n",
      "Step:90, train: 9.396592685788242e-05\n",
      "Step:91, train: 9.034461932483473e-05\n",
      "Step:92, train: 8.690416576131901e-05\n",
      "Step:93, train: 8.363274981230876e-05\n",
      "Step:94, train: 8.051946505962271e-05\n",
      "Step:95, train: 7.755426755630052e-05\n",
      "Step:96, train: 7.472787045087755e-05\n",
      "Step:97, train: 7.20317247072991e-05\n",
      "Step:98, train: 6.945790324690538e-05\n",
      "Step:99, train: 6.699909773662161e-05\n",
      "Step:100, train: 6.464848343098148e-05\n",
      "Step:101, train: 6.239977570666548e-05\n",
      "Step:102, train: 6.024711390835152e-05\n",
      "Step:103, train: 5.8185059860699066e-05\n",
      "Step:104, train: 5.6208575525544256e-05\n",
      "Step:105, train: 5.431294216461655e-05\n",
      "Step:106, train: 5.249379062719081e-05\n",
      "Step:107, train: 5.0747014451999805e-05\n",
      "Step:108, train: 4.9068818494828567e-05\n",
      "Step:109, train: 4.7455628331078355e-05\n",
      "Step:110, train: 4.5904104008346464e-05\n",
      "Step:111, train: 4.441114173975708e-05\n",
      "Step:112, train: 4.2973808821055606e-05\n",
      "Step:113, train: 4.158938256335228e-05\n",
      "Step:114, train: 4.0255304389033435e-05\n",
      "Step:115, train: 3.896915091673743e-05\n",
      "Step:116, train: 3.7728688933663964e-05\n",
      "Step:117, train: 3.653176865391325e-05\n",
      "Step:118, train: 3.537640716963993e-05\n",
      "Step:119, train: 3.426072567548476e-05\n",
      "Step:120, train: 3.318294746841297e-05\n",
      "Step:121, train: 3.214141441745789e-05\n",
      "Step:122, train: 3.1134547283054145e-05\n",
      "Step:123, train: 3.016087637201947e-05\n",
      "Step:124, train: 2.9218993470185722e-05\n",
      "Step:125, train: 2.8307569536229893e-05\n",
      "Step:126, train: 2.7425359002719174e-05\n",
      "Step:127, train: 2.65711786206075e-05\n",
      "Step:128, train: 2.574390856322686e-05\n",
      "Step:129, train: 2.4942485345416776e-05\n",
      "Step:130, train: 2.4165911160168294e-05\n",
      "Step:131, train: 2.3413236658802185e-05\n",
      "Step:132, train: 2.2683540685818196e-05\n",
      "Step:133, train: 2.1975986755615713e-05\n",
      "Step:134, train: 2.1289747173976453e-05\n",
      "Step:135, train: 2.0624050185302987e-05\n",
      "Step:136, train: 1.997816058649545e-05\n",
      "Step:137, train: 1.935137218542159e-05\n",
      "Step:138, train: 1.8743024733980326e-05\n",
      "Step:139, train: 1.8152489468542745e-05\n",
      "Step:140, train: 1.7579156659227412e-05\n",
      "Step:141, train: 1.7022448879066008e-05\n",
      "Step:142, train: 1.648181950094543e-05\n",
      "Step:143, train: 1.595674502516692e-05\n",
      "Step:144, train: 1.5446719869725815e-05\n",
      "Step:145, train: 1.4951265852260494e-05\n",
      "Step:146, train: 1.4469932950541304e-05\n",
      "Step:147, train: 1.4002277372008778e-05\n",
      "Step:148, train: 1.3547880417520298e-05\n",
      "Step:149, train: 1.310634911127184e-05\n",
      "Step:150, train: 1.2677300187196016e-05\n",
      "Step:151, train: 1.2260361079366567e-05\n",
      "Step:152, train: 1.1855178931040243e-05\n",
      "Step:153, train: 1.1461420301086358e-05\n",
      "Step:154, train: 1.1078763198142038e-05\n",
      "Step:155, train: 1.0706895865492692e-05\n",
      "Step:156, train: 1.0345514496798531e-05\n",
      "Step:157, train: 9.994331919094135e-06\n",
      "Step:158, train: 9.653077352249974e-06\n",
      "Step:159, train: 9.321479635214827e-06\n",
      "Step:160, train: 8.999288685830207e-06\n",
      "Step:161, train: 8.686251797085303e-06\n",
      "Step:162, train: 8.382136507790454e-06\n",
      "Step:163, train: 8.08671196546151e-06\n",
      "Step:164, train: 7.799752606543007e-06\n",
      "Step:165, train: 7.5210538587919885e-06\n",
      "Step:166, train: 7.250399503416652e-06\n",
      "Step:167, train: 6.987596473839499e-06\n",
      "Step:168, train: 6.732448926274089e-06\n",
      "Step:169, train: 6.48476605310461e-06\n",
      "Step:170, train: 6.2443695286029785e-06\n",
      "Step:171, train: 6.0110856751695995e-06\n",
      "Step:172, train: 5.78474091066481e-06\n",
      "Step:173, train: 5.565169346823678e-06\n",
      "Step:174, train: 5.352208595238545e-06\n",
      "Step:175, train: 5.14570399908416e-06\n",
      "Step:176, train: 4.945502235718191e-06\n",
      "Step:177, train: 4.751455462473808e-06\n",
      "Step:178, train: 4.5634194548303005e-06\n",
      "Step:179, train: 4.381249109694085e-06\n",
      "Step:180, train: 4.204810704794921e-06\n",
      "Step:181, train: 4.033970410967853e-06\n",
      "Step:182, train: 3.868593556682219e-06\n",
      "Step:183, train: 3.7085527423513186e-06\n",
      "Step:184, train: 3.5537215896453136e-06\n",
      "Step:185, train: 3.403977696975431e-06\n",
      "Step:186, train: 3.259196953730578e-06\n",
      "Step:187, train: 3.1192634691007002e-06\n",
      "Step:188, train: 2.9840603079321323e-06\n",
      "Step:189, train: 2.85347489975187e-06\n",
      "Step:190, train: 2.7273921272539026e-06\n",
      "Step:191, train: 2.605708095877323e-06\n",
      "Step:192, train: 2.4883114036463682e-06\n",
      "Step:193, train: 2.375094646161942e-06\n",
      "Step:194, train: 2.265950714265397e-06\n",
      "Step:195, train: 2.1607794557338535e-06\n",
      "Step:196, train: 2.0594786307328564e-06\n",
      "Step:197, train: 1.9619489319635385e-06\n",
      "Step:198, train: 1.8680939669510605e-06\n",
      "Step:199, train: 1.7778142406806233e-06\n",
      "Step:200, train: 1.6910152468003576e-06\n",
      "Step:201, train: 1.6076005467769307e-06\n",
      "Step:202, train: 1.5274784909909283e-06\n",
      "Step:203, train: 1.4505573885392054e-06\n",
      "Step:204, train: 1.3767473123254622e-06\n",
      "Step:205, train: 1.3059560552704208e-06\n",
      "Step:206, train: 1.2381014600856874e-06\n",
      "Step:207, train: 1.173093773644298e-06\n",
      "Step:208, train: 1.1108490711509049e-06\n",
      "Step:209, train: 1.051282973691829e-06\n",
      "Step:210, train: 9.943125778677109e-07\n",
      "Step:211, train: 9.398545139765425e-07\n",
      "Step:212, train: 8.87831909974976e-07\n",
      "Step:213, train: 8.381638312667276e-07\n",
      "Step:214, train: 7.907735223221989e-07\n",
      "Step:215, train: 1.286795107756627e-06\n",
      "Step:216, train: 1.178010348901123e-06\n",
      "Step:217, train: 7.90997990232629e-07\n",
      "Step:218, train: 8.292536912039909e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:219, train: 8.605781996605048e-07\n",
      "Step:220, train: 8.853031601082331e-07\n",
      "Step:221, train: 9.038150691932643e-07\n",
      "Step:222, train: 9.165446190067548e-07\n",
      "Step:223, train: 9.239409585380534e-07\n",
      "Step:224, train: 9.264631408256592e-07\n",
      "Step:225, train: 9.245646092958362e-07\n",
      "Step:226, train: 9.186916131948694e-07\n",
      "Step:227, train: 9.092731917829219e-07\n",
      "Step:228, train: 8.967200847352295e-07\n",
      "Step:229, train: 8.814217789732307e-07\n",
      "Step:230, train: 8.637431594862668e-07\n",
      "Step:231, train: 8.440271806431791e-07\n",
      "Step:232, train: 8.225891932764927e-07\n",
      "Step:233, train: 7.997208169566883e-07\n",
      "Step:234, train: 7.756910699395151e-07\n",
      "Step:235, train: 7.507458994213094e-07\n",
      "Step:236, train: 7.251083061718589e-07\n",
      "Step:237, train: 6.989802546778814e-07\n",
      "Step:238, train: 6.725433052246984e-07\n",
      "Step:239, train: 6.459611075475691e-07\n",
      "Step:240, train: 9.16099524902623e-07\n",
      "Step:241, train: 6.390759680943775e-07\n",
      "Step:242, train: 6.539740624637857e-07\n",
      "Step:243, train: 6.643852663141969e-07\n",
      "Step:244, train: 6.706430544452204e-07\n",
      "Step:245, train: 6.73093972207132e-07\n",
      "Step:246, train: 6.720858757344272e-07\n",
      "Step:247, train: 6.679658150498919e-07\n",
      "Step:248, train: 6.610687383197075e-07\n",
      "Step:249, train: 6.517181243466958e-07\n",
      "Step:250, train: 6.402184206264717e-07\n",
      "Step:251, train: 6.268617920721607e-07\n",
      "Step:252, train: 6.119173555903982e-07\n",
      "Step:253, train: 5.956368687729747e-07\n",
      "Step:254, train: 5.78254466756485e-07\n",
      "Step:255, train: 7.918943427752886e-07\n",
      "Step:256, train: 5.878264826890622e-07\n",
      "Step:257, train: 6.105026721524957e-07\n",
      "Step:258, train: 6.28238070925262e-07\n",
      "Step:259, train: 6.413169037935155e-07\n",
      "Step:260, train: 6.500554573080429e-07\n",
      "Step:261, train: 6.547892394102586e-07\n",
      "Step:262, train: 6.558645273852922e-07\n",
      "Step:263, train: 6.53629983546997e-07\n",
      "Step:264, train: 6.484255759086807e-07\n",
      "Step:265, train: 6.405830745932754e-07\n",
      "Step:266, train: 6.304189046451144e-07\n",
      "Step:267, train: 6.182332517478289e-07\n",
      "Step:268, train: 6.04310291616171e-07\n",
      "Step:269, train: 5.889135108971168e-07\n",
      "Step:270, train: 5.722883879840075e-07\n",
      "Step:271, train: 5.54661407819781e-07\n",
      "Step:272, train: 5.362390261117396e-07\n",
      "Step:273, train: 5.17210754238746e-07\n",
      "Step:274, train: 6.037648601806565e-07\n",
      "Step:275, train: 5.456993311935435e-07\n",
      "Step:276, train: 5.877605034258792e-07\n",
      "Step:277, train: 6.238331824622992e-07\n",
      "Step:278, train: 6.539805427276836e-07\n",
      "Step:279, train: 6.783845975185457e-07\n",
      "Step:280, train: 6.973070668328277e-07\n",
      "Step:281, train: 7.110720360601955e-07\n",
      "Step:282, train: 7.200405745370818e-07\n",
      "Step:283, train: 7.245895125272402e-07\n",
      "Step:284, train: 7.251084242427516e-07\n",
      "Step:285, train: 7.219882586165242e-07\n",
      "Step:286, train: 7.156082657520693e-07\n",
      "Step:287, train: 7.063401056083484e-07\n",
      "Step:288, train: 6.945347081337814e-07\n",
      "Step:289, train: 6.805295605695188e-07\n",
      "Step:290, train: 6.646369778774744e-07\n",
      "Step:291, train: 6.471505775251013e-07\n",
      "Step:292, train: 6.283437982351368e-07\n",
      "Step:293, train: 6.084642221411193e-07\n",
      "Step:294, train: 5.877427149442789e-07\n",
      "Step:295, train: 5.663860988250045e-07\n",
      "Step:296, train: 5.445852677441428e-07\n",
      "Step:297, train: 5.225086186850909e-07\n",
      "Step:298, train: 5.003091365690912e-07\n",
      "Step:299, train: 4.781224223944217e-07\n",
      "Step:300, train: 4.5606785598603114e-07\n",
      "Step:301, train: 4.342497617459015e-07\n",
      "Step:302, train: 4.7135822253932977e-07\n",
      "Step:303, train: 4.728235090140143e-07\n",
      "Step:304, train: 5.274955869652269e-07\n",
      "Step:305, train: 5.762076227129367e-07\n",
      "Step:306, train: 6.186793554374387e-07\n",
      "Step:307, train: 6.548468647032588e-07\n",
      "Step:308, train: 6.848040954514059e-07\n",
      "Step:309, train: 7.087652349446434e-07\n",
      "Step:310, train: 7.270251205133239e-07\n",
      "Step:311, train: 7.399343016270143e-07\n",
      "Step:312, train: 7.478811849740693e-07\n",
      "Step:313, train: 7.512718860404442e-07\n",
      "Step:314, train: 7.505211462447522e-07\n",
      "Step:315, train: 7.460407189081728e-07\n",
      "Step:316, train: 7.382347725831639e-07\n",
      "Step:317, train: 7.274909887762239e-07\n",
      "Step:318, train: 7.1418101106642e-07\n",
      "Step:319, train: 6.986567666244296e-07\n",
      "Step:320, train: 6.812445987024947e-07\n",
      "Step:321, train: 6.622531696923844e-07\n",
      "Step:322, train: 6.419640221183812e-07\n",
      "Step:323, train: 6.206366833554322e-07\n",
      "Step:324, train: 5.985087731682227e-07\n",
      "Step:325, train: 5.757949885704335e-07\n",
      "Step:326, train: 5.526919091244667e-07\n",
      "Step:327, train: 5.293733442300487e-07\n",
      "Step:328, train: 5.059951799884634e-07\n",
      "Step:329, train: 4.826948505041262e-07\n",
      "Step:330, train: 4.595932338929162e-07\n",
      "Step:331, train: 4.367973939133625e-07\n",
      "Step:332, train: 4.143987962775691e-07\n",
      "Step:333, train: 3.924749402247905e-07\n",
      "Step:334, train: 3.71093274639184e-07\n",
      "Step:335, train: 3.503086784368572e-07\n",
      "Step:336, train: 3.301664950765181e-07\n",
      "Step:337, train: 5.912014290439317e-07\n",
      "Step:338, train: 5.473536381308505e-07\n",
      "Step:339, train: 3.334470005367221e-07\n",
      "Step:340, train: 3.514836620894071e-07\n",
      "Step:341, train: 3.661198099172103e-07\n",
      "Step:342, train: 3.7748250579335377e-07\n",
      "Step:343, train: 3.857459492533459e-07\n",
      "Step:344, train: 3.911131226035037e-07\n",
      "Step:345, train: 3.9380682197146416e-07\n",
      "Step:346, train: 3.9405966061568915e-07\n",
      "Step:347, train: 3.9210740856199043e-07\n",
      "Step:348, train: 3.881848141263607e-07\n",
      "Step:349, train: 3.825211058031427e-07\n",
      "Step:350, train: 3.7533554910031027e-07\n",
      "Step:351, train: 3.668389799443318e-07\n",
      "Step:352, train: 3.5722861512004345e-07\n",
      "Step:353, train: 3.4668973043542074e-07\n",
      "Step:354, train: 3.3539244406552235e-07\n",
      "Step:355, train: 3.234948477201479e-07\n",
      "Step:356, train: 3.1114008454602884e-07\n",
      "Step:357, train: 2.9845875088244047e-07\n",
      "Step:358, train: 3.1074342015648834e-07\n",
      "Step:359, train: 3.66080746527297e-07\n",
      "Step:360, train: 4.441869976038417e-07\n",
      "Step:361, train: 5.177837608040112e-07\n",
      "Step:362, train: 5.854507586190266e-07\n",
      "Step:363, train: 6.462888619308467e-07\n",
      "Step:364, train: 6.997998977033765e-07\n",
      "Step:365, train: 7.457855110072659e-07\n",
      "Step:366, train: 7.842728317988704e-07\n",
      "Step:367, train: 8.154572665747861e-07\n",
      "Step:368, train: 8.396519053958711e-07\n",
      "Step:369, train: 8.572530826871163e-07\n",
      "Step:370, train: 8.687107957756256e-07\n",
      "Step:371, train: 8.745102507190984e-07\n",
      "Step:372, train: 8.751503292021768e-07\n",
      "Step:373, train: 8.711301235470452e-07\n",
      "Step:374, train: 8.629469618424557e-07\n",
      "Step:375, train: 8.510783254151484e-07\n",
      "Step:376, train: 8.359839718718685e-07\n",
      "Step:377, train: 8.180970600113701e-07\n",
      "Step:378, train: 7.97830562714919e-07\n",
      "Step:379, train: 7.755633701433783e-07\n",
      "Step:380, train: 7.516503585674911e-07\n",
      "Step:381, train: 7.264184205328576e-07\n",
      "Step:382, train: 7.001635057078785e-07\n",
      "Step:383, train: 6.731568008450825e-07\n",
      "Step:384, train: 6.456425429414194e-07\n",
      "Step:385, train: 6.178384582761657e-07\n",
      "Step:386, train: 5.899412361142223e-07\n",
      "Step:387, train: 5.62124354841681e-07\n",
      "Step:388, train: 5.345409050220353e-07\n",
      "Step:389, train: 5.073225152600981e-07\n",
      "Step:390, train: 4.805851298419725e-07\n",
      "Step:391, train: 4.5442734726066093e-07\n",
      "Step:392, train: 4.2893288347613564e-07\n",
      "Step:393, train: 4.041691854287956e-07\n",
      "Step:394, train: 3.801934915856073e-07\n",
      "Step:395, train: 3.570502540776337e-07\n",
      "Step:396, train: 3.347723497410028e-07\n",
      "Step:397, train: 3.13385995010994e-07\n",
      "Step:398, train: 2.92906189719108e-07\n",
      "Step:399, train: 2.7334303434834244e-07\n",
      "Step:400, train: 2.546972658817581e-07\n",
      "Step:401, train: 2.3696617005397994e-07\n",
      "Step:402, train: 2.2014060588362846e-07\n",
      "Step:403, train: 2.761354466845523e-07\n",
      "Step:404, train: 2.118626981619156e-07\n",
      "Step:405, train: 2.175834856363759e-07\n",
      "Step:406, train: 2.2147982516511615e-07\n",
      "Step:407, train: 2.236801246003413e-07\n",
      "Step:408, train: 2.2432370098504052e-07\n",
      "Step:409, train: 2.2355564274055717e-07\n",
      "Step:410, train: 2.2152296541839306e-07\n",
      "Step:411, train: 2.183705450934071e-07\n",
      "Step:412, train: 2.1423975279641835e-07\n",
      "Step:413, train: 2.0926575457970887e-07\n",
      "Step:414, train: 2.0357618823240794e-07\n",
      "Step:415, train: 1.972916493865554e-07\n",
      "Step:416, train: 2.521820096299861e-07\n",
      "Step:417, train: 2.065621332900427e-07\n",
      "Step:418, train: 2.2023687114532835e-07\n",
      "Step:419, train: 2.3153738200047807e-07\n",
      "Step:420, train: 2.4051495230252485e-07\n",
      "Step:421, train: 2.472614660716095e-07\n",
      "Step:422, train: 2.5190386410539595e-07\n",
      "Step:423, train: 2.5458642126121336e-07\n",
      "Step:424, train: 2.554683047307372e-07\n",
      "Step:425, train: 2.547155921868023e-07\n",
      "Step:426, train: 2.5249599434838263e-07\n",
      "Step:427, train: 2.489777039222659e-07\n",
      "Step:428, train: 2.4432262529957205e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:429, train: 2.386872951411324e-07\n",
      "Step:430, train: 2.3221866561367886e-07\n",
      "Step:431, train: 2.2505675138025286e-07\n",
      "Step:432, train: 2.1733085263476447e-07\n",
      "Step:433, train: 2.0916066854762598e-07\n",
      "Step:434, train: 2.0065472951419992e-07\n",
      "Step:435, train: 1.919118999820072e-07\n",
      "Step:436, train: 1.8302208238395936e-07\n",
      "Step:437, train: 1.7406495278458124e-07\n",
      "Step:438, train: 3.071534892434456e-07\n",
      "Step:439, train: 2.508188371799382e-07\n",
      "Step:440, train: 1.8718125841044604e-07\n",
      "Step:441, train: 2.036301699773594e-07\n",
      "Step:442, train: 2.1769386120709272e-07\n",
      "Step:443, train: 2.2935269004823362e-07\n",
      "Step:444, train: 2.386480087662483e-07\n",
      "Step:445, train: 2.4566764241546556e-07\n",
      "Step:446, train: 2.505338819760762e-07\n",
      "Step:447, train: 2.5339311003395054e-07\n",
      "Step:448, train: 2.5440526766153797e-07\n",
      "Step:449, train: 2.5373957676051053e-07\n",
      "Step:450, train: 2.5156800386721793e-07\n",
      "Step:451, train: 2.480620775603205e-07\n",
      "Step:452, train: 2.433879425323428e-07\n",
      "Step:453, train: 2.3770663710173372e-07\n",
      "Step:454, train: 2.3117109533390915e-07\n",
      "Step:455, train: 2.2392489982031202e-07\n",
      "Step:456, train: 2.1610132901105588e-07\n",
      "Step:457, train: 2.078234550888685e-07\n",
      "Step:458, train: 1.992042550228787e-07\n",
      "Step:459, train: 1.9034592513617664e-07\n",
      "Step:460, train: 1.8134064895688598e-07\n",
      "Step:461, train: 1.7227101653099937e-07\n",
      "Step:462, train: 1.6320994264688077e-07\n",
      "Step:463, train: 1.5422026148732948e-07\n",
      "Step:464, train: 2.65444638238173e-07\n",
      "Step:465, train: 2.208170547751261e-07\n",
      "Step:466, train: 1.643842365615081e-07\n",
      "Step:467, train: 1.7881531879855214e-07\n",
      "Step:468, train: 1.9111804500655763e-07\n",
      "Step:469, train: 2.0127337196655872e-07\n",
      "Step:470, train: 2.0931818803253095e-07\n",
      "Step:471, train: 2.1533228589683993e-07\n",
      "Step:472, train: 2.1942674650679334e-07\n",
      "Step:473, train: 2.217331925628482e-07\n",
      "Step:474, train: 2.223971007304856e-07\n",
      "Step:475, train: 2.215710840875968e-07\n",
      "Step:476, train: 2.1941083760222602e-07\n",
      "Step:477, train: 2.160713118266703e-07\n",
      "Step:478, train: 2.117043340308352e-07\n",
      "Step:479, train: 2.0645468100926007e-07\n",
      "Step:480, train: 2.004599043129995e-07\n",
      "Step:481, train: 1.9384996662952665e-07\n",
      "Step:482, train: 1.86746040236928e-07\n",
      "Step:483, train: 1.7925740411162585e-07\n",
      "Step:484, train: 1.7148548078370723e-07\n",
      "Step:485, train: 1.6352255444169361e-07\n",
      "Step:486, train: 1.5545113656101525e-07\n",
      "Step:487, train: 1.473441409089536e-07\n",
      "Step:488, train: 1.3926592791672128e-07\n",
      "Step:489, train: 2.0185207398674084e-07\n",
      "Step:490, train: 1.3614626791422942e-07\n",
      "Step:491, train: 1.3968930915843668e-07\n",
      "Step:492, train: 1.419792135873384e-07\n",
      "Step:493, train: 1.431063998380581e-07\n",
      "Step:494, train: 1.431705137295763e-07\n",
      "Step:495, train: 1.4227384342366347e-07\n",
      "Step:496, train: 1.4052204011432987e-07\n",
      "Step:497, train: 1.380188130451452e-07\n",
      "Step:498, train: 1.348653189734303e-07\n",
      "Step:499, train: 1.3115918478888863e-07\n",
      "Step:500, train: 1.5538825963044056e-07\n",
      "Step:501, train: 1.4485010617734627e-07\n",
      "Step:502, train: 1.608706131694496e-07\n",
      "Step:503, train: 1.7486519938981187e-07\n",
      "Step:504, train: 1.8674265423100972e-07\n",
      "Step:505, train: 1.9648577330591905e-07\n",
      "Step:506, train: 2.0413351019303499e-07\n",
      "Step:507, train: 2.0976803647892341e-07\n",
      "Step:508, train: 2.1350285057115584e-07\n",
      "Step:509, train: 2.1547063983290557e-07\n",
      "Step:510, train: 2.1581968283705675e-07\n",
      "Step:511, train: 2.1470431287974277e-07\n",
      "Step:512, train: 2.1228086616343309e-07\n",
      "Step:513, train: 2.0870553190415408e-07\n",
      "Step:514, train: 2.0413021237161775e-07\n",
      "Step:515, train: 1.98701266564689e-07\n",
      "Step:516, train: 1.9255754186108792e-07\n",
      "Step:517, train: 1.8582821822201478e-07\n",
      "Step:518, train: 1.7863486257319647e-07\n",
      "Step:519, train: 1.710864385032625e-07\n",
      "Step:520, train: 1.6328449836079596e-07\n",
      "Step:521, train: 1.5531947078377883e-07\n",
      "Step:522, train: 1.4727316125970456e-07\n",
      "Step:523, train: 1.3921779230342037e-07\n",
      "Step:524, train: 1.3121667721675784e-07\n",
      "Step:525, train: 1.233244436766791e-07\n",
      "Step:526, train: 1.1558823265552568e-07\n",
      "Step:527, train: 1.973956985202301e-07\n",
      "Step:528, train: 1.6914129089513914e-07\n",
      "Step:529, train: 1.2180626122702764e-07\n",
      "Step:530, train: 1.3237415704649015e-07\n",
      "Step:531, train: 1.413081020125379e-07\n",
      "Step:532, train: 1.4859446108133048e-07\n",
      "Step:533, train: 1.542643521364059e-07\n",
      "Step:534, train: 1.5838057356561343e-07\n",
      "Step:535, train: 1.6103342725063244e-07\n",
      "Step:536, train: 1.6232605623635008e-07\n",
      "Step:537, train: 1.6237512780697682e-07\n",
      "Step:538, train: 1.6130210574832019e-07\n",
      "Step:539, train: 1.5923041256064895e-07\n",
      "Step:540, train: 1.5628345876518785e-07\n",
      "Step:541, train: 1.5257870003117055e-07\n",
      "Step:542, train: 1.482323385084863e-07\n",
      "Step:543, train: 1.4335240607063147e-07\n",
      "Step:544, train: 1.380394701285443e-07\n",
      "Step:545, train: 1.3238843600410223e-07\n",
      "Step:546, train: 1.2648552224095358e-07\n",
      "Step:547, train: 1.204089381187646e-07\n",
      "Step:548, train: 1.1422868025697012e-07\n",
      "Step:549, train: 1.0800775545604607e-07\n",
      "Step:550, train: 1.0180086546694614e-07\n",
      "Step:551, train: 1.9185104718707927e-07\n",
      "Step:552, train: 1.6825689206501412e-07\n",
      "Step:553, train: 1.0692955842012571e-07\n",
      "Step:554, train: 1.1527717452965358e-07\n",
      "Step:555, train: 1.2221168275518386e-07\n",
      "Step:556, train: 1.2773785288886496e-07\n",
      "Step:557, train: 1.3189598427752688e-07\n",
      "Step:558, train: 1.3475171190953784e-07\n",
      "Step:559, train: 1.3638769972626782e-07\n",
      "Step:560, train: 1.3690096097602042e-07\n",
      "Step:561, train: 1.3639381243890574e-07\n",
      "Step:562, train: 1.3497320657243186e-07\n",
      "Step:563, train: 1.3274694079193463e-07\n",
      "Step:564, train: 1.2982108035439375e-07\n",
      "Step:565, train: 1.262965223702252e-07\n",
      "Step:566, train: 1.2227175907938623e-07\n",
      "Step:567, train: 1.1783754361620531e-07\n",
      "Step:568, train: 1.1307975422504731e-07\n",
      "Step:569, train: 1.080769984439686e-07\n",
      "Step:570, train: 1.0290071388889352e-07\n",
      "Step:571, train: 9.761492508162267e-08\n",
      "Step:572, train: 9.227799160569892e-08\n",
      "Step:573, train: 1.7505971451562366e-07\n",
      "Step:574, train: 1.4961398077643528e-07\n",
      "Step:575, train: 9.830923566412157e-08\n",
      "Step:576, train: 1.0662818580503359e-07\n",
      "Step:577, train: 1.136011832597733e-07\n",
      "Step:578, train: 1.1921904421720757e-07\n",
      "Step:579, train: 1.2351201096962973e-07\n",
      "Step:580, train: 1.2653585673564806e-07\n",
      "Step:581, train: 1.2836621053059898e-07\n",
      "Step:582, train: 1.290926141005211e-07\n",
      "Step:583, train: 1.2881334243939194e-07\n",
      "Step:584, train: 1.276312726573836e-07\n",
      "Step:585, train: 1.2564940981224392e-07\n",
      "Step:586, train: 1.2297139233797085e-07\n",
      "Step:587, train: 1.196967282041386e-07\n",
      "Step:588, train: 1.1592194481151744e-07\n",
      "Step:589, train: 1.1173656238180454e-07\n",
      "Step:590, train: 1.0722552027420024e-07\n",
      "Step:591, train: 1.0246579724419856e-07\n",
      "Step:592, train: 9.752903384260044e-08\n",
      "Step:593, train: 9.247844321869846e-08\n",
      "Step:594, train: 8.737231149420734e-08\n",
      "Step:595, train: 1.221693855996775e-07\n",
      "Step:596, train: 8.665263417281263e-08\n",
      "Step:597, train: 9.004534446819407e-08\n",
      "Step:598, train: 9.247586692764554e-08\n",
      "Step:599, train: 9.399771668457593e-08\n",
      "Step:600, train: 9.467571692534785e-08\n",
      "Step:601, train: 9.458314969166735e-08\n",
      "Step:602, train: 9.379643194062684e-08\n",
      "Step:603, train: 9.239487614727624e-08\n",
      "Step:604, train: 9.045660203128929e-08\n",
      "Step:605, train: 8.805813520260497e-08\n",
      "Step:606, train: 8.527314727132751e-08\n",
      "Step:607, train: 8.217135176029364e-08\n",
      "Step:608, train: 1.0522078565015973e-07\n",
      "Step:609, train: 8.692052889262969e-08\n",
      "Step:610, train: 9.386718327098813e-08\n",
      "Step:611, train: 9.961821628135187e-08\n",
      "Step:612, train: 1.0417502331362142e-07\n",
      "Step:613, train: 1.0756938785998144e-07\n",
      "Step:614, train: 1.0985622459656097e-07\n",
      "Step:615, train: 1.1110707867656494e-07\n",
      "Step:616, train: 1.1140473470904007e-07\n",
      "Step:617, train: 1.1083807523109167e-07\n",
      "Step:618, train: 1.094998222008954e-07\n",
      "Step:619, train: 1.0748360148605642e-07\n",
      "Step:620, train: 1.048816593194735e-07\n",
      "Step:621, train: 1.017823369161072e-07\n",
      "Step:622, train: 9.827132930997125e-08\n",
      "Step:623, train: 9.442744898504573e-08\n",
      "Step:624, train: 9.032503125732127e-08\n",
      "Step:625, train: 8.60317548260681e-08\n",
      "Step:626, train: 8.160976830453969e-08\n",
      "Step:627, train: 7.711458589422298e-08\n",
      "Step:628, train: 1.0279913807056915e-07\n",
      "Step:629, train: 7.754829339038109e-08\n",
      "Step:630, train: 8.153434727110283e-08\n",
      "Step:631, train: 8.456970382627482e-08\n",
      "Step:632, train: 8.669170894577334e-08\n",
      "Step:633, train: 8.795414540099919e-08\n",
      "Step:634, train: 8.84210001386586e-08\n",
      "Step:635, train: 8.816330685347317e-08\n",
      "Step:636, train: 8.725614470278123e-08\n",
      "Step:637, train: 8.577537027093682e-08\n",
      "Step:638, train: 8.379718605629585e-08\n",
      "Step:639, train: 8.13950309628188e-08\n",
      "Step:640, train: 7.863976107895448e-08\n",
      "Step:641, train: 7.559796981371089e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:642, train: 7.233175931187e-08\n",
      "Step:643, train: 9.166819538843469e-08\n",
      "Step:644, train: 7.597029369357113e-08\n",
      "Step:645, train: 8.201122913717295e-08\n",
      "Step:646, train: 8.69870796370248e-08\n",
      "Step:647, train: 9.089940445717606e-08\n",
      "Step:648, train: 9.377770730922923e-08\n",
      "Step:649, train: 9.567196186380408e-08\n",
      "Step:650, train: 9.664706046473577e-08\n",
      "Step:651, train: 9.677792540849356e-08\n",
      "Step:652, train: 9.61451867286254e-08\n",
      "Step:653, train: 9.483301385151138e-08\n",
      "Step:654, train: 9.292658833766579e-08\n",
      "Step:655, train: 9.05087840065619e-08\n",
      "Step:656, train: 8.765977920348935e-08\n",
      "Step:657, train: 8.44559579697349e-08\n",
      "Step:658, train: 8.096923279522069e-08\n",
      "Step:659, train: 7.726578133149238e-08\n",
      "Step:660, train: 7.340686909365837e-08\n",
      "Step:661, train: 6.944724869878422e-08\n",
      "Step:662, train: 6.543594031406204e-08\n",
      "Step:663, train: 1.1855598704608595e-07\n",
      "Step:664, train: 9.50476888084453e-08\n",
      "Step:665, train: 7.185884497010421e-08\n",
      "Step:666, train: 7.969038027023309e-08\n",
      "Step:667, train: 8.642213610052395e-08\n",
      "Step:668, train: 9.200654693662907e-08\n",
      "Step:669, train: 9.643728203481358e-08\n",
      "Step:670, train: 9.974028609819638e-08\n",
      "Step:671, train: 1.0196576200754213e-07\n",
      "Step:672, train: 1.031813406567972e-07\n",
      "Step:673, train: 1.0346637013577729e-07\n",
      "Step:674, train: 1.0290834054120567e-07\n",
      "Step:675, train: 1.0159810196280803e-07\n",
      "Step:676, train: 9.96276658939965e-08\n",
      "Step:677, train: 9.708790697413345e-08\n",
      "Step:678, train: 9.406778792222652e-08\n",
      "Step:679, train: 9.065090033935911e-08\n",
      "Step:680, train: 8.691682974361725e-08\n",
      "Step:681, train: 8.29385609633805e-08\n",
      "Step:682, train: 7.878375658842835e-08\n",
      "Step:683, train: 7.451344920741096e-08\n",
      "Step:684, train: 7.018203654565165e-08\n",
      "Step:685, train: 6.583861138922146e-08\n",
      "Step:686, train: 6.152540289988016e-08\n",
      "Step:687, train: 9.110776058224734e-08\n",
      "Step:688, train: 5.960149126931092e-08\n",
      "Step:689, train: 6.124040387305187e-08\n",
      "Step:690, train: 6.22324739739496e-08\n",
      "Step:691, train: 6.262460316565206e-08\n",
      "Step:692, train: 6.246849557311252e-08\n",
      "Step:693, train: 6.182153610921515e-08\n",
      "Step:694, train: 6.074081711366727e-08\n",
      "Step:695, train: 5.9284590059470944e-08\n",
      "Step:696, train: 5.750921418406676e-08\n",
      "Step:697, train: 8.439780051756593e-08\n",
      "Step:698, train: 6.007528724137778e-08\n",
      "Step:699, train: 6.386937145162869e-08\n",
      "Step:700, train: 6.684831339958181e-08\n",
      "Step:701, train: 6.90317221004651e-08\n",
      "Step:702, train: 7.045618958714575e-08\n",
      "Step:703, train: 7.117134360898601e-08\n",
      "Step:704, train: 7.123513386940527e-08\n",
      "Step:705, train: 7.070985963519879e-08\n",
      "Step:706, train: 6.966219800438895e-08\n",
      "Step:707, train: 6.815805028564496e-08\n",
      "Step:708, train: 6.626308085890443e-08\n",
      "Step:709, train: 6.40404341401552e-08\n",
      "Step:710, train: 6.15510056544052e-08\n",
      "Step:711, train: 5.885096114621764e-08\n",
      "Step:712, train: 5.599232444100687e-08\n",
      "Step:713, train: 6.979716352547382e-08\n",
      "Step:714, train: 5.8985364633473156e-08\n",
      "Step:715, train: 6.41092479623126e-08\n",
      "Step:716, train: 6.835250431384023e-08\n",
      "Step:717, train: 7.170708746759729e-08\n",
      "Step:718, train: 7.419125645334158e-08\n",
      "Step:719, train: 7.584255259335198e-08\n",
      "Step:720, train: 7.671324600563421e-08\n",
      "Step:721, train: 7.686462955447033e-08\n",
      "Step:722, train: 7.636598417546786e-08\n",
      "Step:723, train: 7.528833937894825e-08\n",
      "Step:724, train: 7.370385846356287e-08\n",
      "Step:725, train: 7.168498412042807e-08\n",
      "Step:726, train: 6.930167374445994e-08\n",
      "Step:727, train: 6.662000550538433e-08\n",
      "Step:728, train: 6.370259314364342e-08\n",
      "Step:729, train: 6.06072353150976e-08\n",
      "Step:730, train: 5.738652568019035e-08\n",
      "Step:731, train: 5.408885867281651e-08\n",
      "Step:732, train: 5.075674286738909e-08\n",
      "Step:733, train: 9.159837380238736e-08\n",
      "Step:734, train: 7.269761653565447e-08\n",
      "Step:735, train: 5.614951532345089e-08\n",
      "Step:736, train: 6.275592064623122e-08\n",
      "Step:737, train: 6.845860521862495e-08\n",
      "Step:738, train: 7.32045103905625e-08\n",
      "Step:739, train: 7.697927681537943e-08\n",
      "Step:740, train: 7.97988345966166e-08\n",
      "Step:741, train: 8.170147558674557e-08\n",
      "Step:742, train: 8.274261217219523e-08\n",
      "Step:743, train: 8.298882400276243e-08\n",
      "Step:744, train: 8.251420855304861e-08\n",
      "Step:745, train: 8.139684429826457e-08\n",
      "Step:746, train: 7.971673458528518e-08\n",
      "Step:747, train: 7.755338483547523e-08\n",
      "Step:748, train: 7.498321855890193e-08\n",
      "Step:749, train: 7.208071680855027e-08\n",
      "Step:750, train: 6.891448943575712e-08\n",
      "Step:751, train: 6.554899822785446e-08\n",
      "Step:752, train: 6.20423760450727e-08\n",
      "Step:753, train: 5.8448550730794905e-08\n",
      "Step:754, train: 5.481472068260953e-08\n",
      "Step:755, train: 5.118285306275616e-08\n",
      "Step:756, train: 4.7589455307533383e-08\n",
      "Step:757, train: 7.587319192002548e-08\n",
      "Step:758, train: 4.545892584192969e-08\n",
      "Step:759, train: 4.633432423532198e-08\n",
      "Step:760, train: 4.672688326599494e-08\n",
      "Step:761, train: 4.6676714439861877e-08\n",
      "Step:762, train: 4.6228073841253154e-08\n",
      "Step:763, train: 4.5427628935760114e-08\n",
      "Step:764, train: 5.227679043899483e-08\n",
      "Step:765, train: 5.5291555561559706e-08\n",
      "Step:766, train: 6.565667838356696e-08\n",
      "Step:767, train: 7.51252262004711e-08\n",
      "Step:768, train: 8.350041822366799e-08\n",
      "Step:769, train: 9.066387505525273e-08\n",
      "Step:770, train: 9.655936068425558e-08\n",
      "Step:771, train: 1.0117828888591509e-07\n",
      "Step:772, train: 1.0454953983643855e-07\n",
      "Step:773, train: 1.0672981345446313e-07\n",
      "Step:774, train: 1.0779644728854344e-07\n",
      "Step:775, train: 1.0784110614652248e-07\n",
      "Step:776, train: 1.0696330812585481e-07\n",
      "Step:777, train: 1.0526740477648095e-07\n",
      "Step:778, train: 1.0285902641951453e-07\n",
      "Step:779, train: 9.984303778601036e-08\n",
      "Step:780, train: 9.631993223512704e-08\n",
      "Step:781, train: 9.23858330813572e-08\n",
      "Step:782, train: 8.81302106455236e-08\n",
      "Step:783, train: 8.363662390080544e-08\n",
      "Step:784, train: 7.898099270851874e-08\n",
      "Step:785, train: 7.423157589375749e-08\n",
      "Step:786, train: 6.944906027794803e-08\n",
      "Step:787, train: 6.468705716952418e-08\n",
      "Step:788, train: 5.999141605382933e-08\n",
      "Step:789, train: 5.540166774584508e-08\n",
      "Step:790, train: 5.0950481930813645e-08\n",
      "Step:791, train: 4.666486634948658e-08\n",
      "Step:792, train: 4.256568713328824e-08\n",
      "Step:793, train: 6.197566217231991e-08\n",
      "Step:794, train: 3.970060490504932e-08\n",
      "Step:795, train: 4.028359616487252e-08\n",
      "Step:796, train: 4.0451723474456113e-08\n",
      "Step:797, train: 4.0242689871287255e-08\n",
      "Step:798, train: 3.9697443257770946e-08\n",
      "Step:799, train: 3.885776080931884e-08\n",
      "Step:800, train: 5.975312182994974e-08\n",
      "Step:801, train: 4.1320543900156405e-08\n",
      "Step:802, train: 4.427310048240526e-08\n",
      "Step:803, train: 4.66106314973151e-08\n",
      "Step:804, train: 4.8341573764309853e-08\n",
      "Step:805, train: 4.9489159391504155e-08\n",
      "Step:806, train: 5.0088281906903385e-08\n",
      "Step:807, train: 5.018221766344951e-08\n",
      "Step:808, train: 4.981883519820153e-08\n",
      "Step:809, train: 4.904863919882596e-08\n",
      "Step:810, train: 4.792436181548347e-08\n",
      "Step:811, train: 4.649777828493196e-08\n",
      "Step:812, train: 4.481941651844363e-08\n",
      "Step:813, train: 4.293731262760308e-08\n",
      "Step:814, train: 4.0896834832031027e-08\n",
      "Step:815, train: 3.873953973888297e-08\n",
      "Step:816, train: 4.4827013662970473e-08\n",
      "Step:817, train: 4.2882978891791525e-08\n",
      "Step:818, train: 4.864278277151011e-08\n",
      "Step:819, train: 5.3671674314422496e-08\n",
      "Step:820, train: 5.790416891105152e-08\n",
      "Step:821, train: 6.131261565136661e-08\n",
      "Step:822, train: 6.390054297713556e-08\n",
      "Step:823, train: 6.569295977765492e-08\n",
      "Step:824, train: 6.67318019165684e-08\n",
      "Step:825, train: 6.707194302777512e-08\n",
      "Step:826, train: 6.677579177167665e-08\n",
      "Step:827, train: 6.591085231224933e-08\n",
      "Step:828, train: 6.454742146345594e-08\n",
      "Step:829, train: 6.275569030650386e-08\n",
      "Step:830, train: 6.06038477558523e-08\n",
      "Step:831, train: 5.8158014885914276e-08\n",
      "Step:832, train: 5.5480208858395905e-08\n",
      "Step:833, train: 5.262822117398603e-08\n",
      "Step:834, train: 4.965510492673415e-08\n",
      "Step:835, train: 4.6609043332180714e-08\n",
      "Step:836, train: 4.353262500284262e-08\n",
      "Step:837, train: 4.046308665444917e-08\n",
      "Step:838, train: 3.743336612920041e-08\n",
      "Step:839, train: 3.447084796217117e-08\n",
      "Step:840, train: 6.803870443061705e-08\n",
      "Step:841, train: 6.292066324546831e-08\n",
      "Step:842, train: 3.54639727240384e-08\n",
      "Step:843, train: 3.8435371604331726e-08\n",
      "Step:844, train: 4.084464390756117e-08\n",
      "Step:845, train: 4.2689360190827565e-08\n",
      "Step:846, train: 4.398407101530566e-08\n",
      "Step:847, train: 4.475572262189382e-08\n",
      "Step:848, train: 4.5040898606290626e-08\n",
      "Step:849, train: 4.488182361271887e-08\n",
      "Step:850, train: 4.432520528539204e-08\n",
      "Step:851, train: 4.341972251336954e-08\n",
      "Step:852, train: 4.2213457542957316e-08\n",
      "Step:853, train: 4.075499590095474e-08\n",
      "Step:854, train: 3.909063129783623e-08\n",
      "Step:855, train: 3.726397935950847e-08\n",
      "Step:856, train: 3.531532956013959e-08\n",
      "Step:857, train: 3.328272789850463e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:858, train: 4.722138286645633e-08\n",
      "Step:859, train: 3.353955260114587e-08\n",
      "Step:860, train: 3.5394415166302785e-08\n",
      "Step:861, train: 3.676771407421229e-08\n",
      "Step:862, train: 3.767698754034253e-08\n",
      "Step:863, train: 3.8148902976930044e-08\n",
      "Step:864, train: 3.821744548798054e-08\n",
      "Step:865, train: 3.7921098337456534e-08\n",
      "Step:866, train: 3.730074399922431e-08\n",
      "Step:867, train: 3.639847152055358e-08\n",
      "Step:868, train: 3.525665262562082e-08\n",
      "Step:869, train: 3.391609174470846e-08\n",
      "Step:870, train: 3.241644184007955e-08\n",
      "Step:871, train: 3.07942466227404e-08\n",
      "Step:872, train: 5.524906776212834e-08\n",
      "Step:873, train: 3.055907046320729e-08\n",
      "Step:874, train: 3.1623340424886146e-08\n",
      "Step:875, train: 3.229294579197414e-08\n",
      "Step:876, train: 3.259304997212268e-08\n",
      "Step:877, train: 3.255403604048631e-08\n",
      "Step:878, train: 3.2210114578636216e-08\n",
      "Step:879, train: 3.1597372547201324e-08\n",
      "Step:880, train: 3.0752298635818346e-08\n",
      "Step:881, train: 2.971125635154978e-08\n",
      "Step:882, train: 5.0421232294753384e-08\n",
      "Step:883, train: 3.0620664580458965e-08\n",
      "Step:884, train: 3.228378307617282e-08\n",
      "Step:885, train: 3.3503164384876536e-08\n",
      "Step:886, train: 3.4295554364591364e-08\n",
      "Step:887, train: 3.468643300281112e-08\n",
      "Step:888, train: 3.470721726213877e-08\n",
      "Step:889, train: 3.439449468145545e-08\n",
      "Step:890, train: 3.378610859623615e-08\n",
      "Step:891, train: 3.292181274699731e-08\n",
      "Step:892, train: 3.184085877756816e-08\n",
      "Step:893, train: 3.058085018099706e-08\n",
      "Step:894, train: 2.9178511263203364e-08\n",
      "Step:895, train: 4.575623646471381e-08\n",
      "Step:896, train: 2.9691779229315014e-08\n",
      "Step:897, train: 3.1279247988613506e-08\n",
      "Step:898, train: 3.243524296348752e-08\n",
      "Step:899, train: 3.317623703475938e-08\n",
      "Step:900, train: 3.352795350055542e-08\n",
      "Step:901, train: 3.3520947100581204e-08\n",
      "Step:902, train: 3.319114275315747e-08\n",
      "Step:903, train: 3.257607413414045e-08\n",
      "Step:904, train: 3.171453951397882e-08\n",
      "Step:905, train: 3.0644430839256984e-08\n",
      "Step:906, train: 2.9403413574906505e-08\n",
      "Step:907, train: 2.8026613619773884e-08\n",
      "Step:908, train: 4.524535029985646e-08\n",
      "Step:909, train: 2.8378759889051682e-08\n",
      "Step:910, train: 2.979440764649393e-08\n",
      "Step:911, train: 3.0802057430312426e-08\n",
      "Step:912, train: 3.14192026960466e-08\n",
      "Step:913, train: 3.167142218908908e-08\n",
      "Step:914, train: 3.1589461725253046e-08\n",
      "Step:915, train: 3.120767378450652e-08\n",
      "Step:916, train: 3.056269144762076e-08\n",
      "Step:917, train: 2.9691147927826088e-08\n",
      "Step:918, train: 2.8629978837196018e-08\n",
      "Step:919, train: 2.741381371469735e-08\n",
      "Step:920, train: 3.775681421574965e-08\n",
      "Step:921, train: 2.8917351374016556e-08\n",
      "Step:922, train: 3.1301763286292046e-08\n",
      "Step:923, train: 3.3210902536792804e-08\n",
      "Step:924, train: 3.464323881414797e-08\n",
      "Step:925, train: 3.561241528166588e-08\n",
      "Step:926, train: 3.6143137039621656e-08\n",
      "Step:927, train: 3.6267105221183695e-08\n",
      "Step:928, train: 3.602209168380092e-08\n",
      "Step:929, train: 3.544923304113803e-08\n",
      "Step:930, train: 3.459054489188421e-08\n",
      "Step:931, train: 3.34891542607264e-08\n",
      "Step:932, train: 3.218627919329896e-08\n",
      "Step:933, train: 3.072194136754656e-08\n",
      "Step:934, train: 2.9133728612115593e-08\n",
      "Step:935, train: 2.745683228648569e-08\n",
      "Step:936, train: 2.5722623820815048e-08\n",
      "Step:937, train: 4.6718899098497736e-08\n",
      "Step:938, train: 3.2174163722333766e-08\n",
      "Step:939, train: 3.13350579698429e-08\n",
      "Step:940, train: 3.7360084620071434e-08\n",
      "Step:941, train: 4.2831565828948615e-08\n",
      "Step:942, train: 4.762310814212726e-08\n",
      "Step:943, train: 5.1659145100381196e-08\n",
      "Step:944, train: 5.490415782799393e-08\n",
      "Step:945, train: 5.735440249434752e-08\n",
      "Step:946, train: 5.90307231082319e-08\n",
      "Step:947, train: 5.997295372667346e-08\n",
      "Step:948, train: 6.023333319159714e-08\n",
      "Step:949, train: 5.98743458102912e-08\n",
      "Step:950, train: 5.89640118976637e-08\n",
      "Step:951, train: 5.7571906238348e-08\n",
      "Step:952, train: 5.576923198399385e-08\n",
      "Step:953, train: 5.3625699425253506e-08\n",
      "Step:954, train: 5.120771231109025e-08\n",
      "Step:955, train: 4.8578761023751056e-08\n",
      "Step:956, train: 4.579710760476692e-08\n",
      "Step:957, train: 4.29157752645554e-08\n",
      "Step:958, train: 3.998268375638553e-08\n",
      "Step:959, train: 3.7040306885646404e-08\n",
      "Step:960, train: 3.41250869889845e-08\n",
      "Step:961, train: 3.1269107826304024e-08\n",
      "Step:962, train: 2.8498406745519644e-08\n",
      "Step:963, train: 2.5834827749630194e-08\n",
      "Step:964, train: 2.3295379473694407e-08\n",
      "Step:965, train: 5.1487296035429547e-08\n",
      "Step:966, train: 5.183396239879273e-08\n",
      "Step:967, train: 2.7597492255747166e-08\n",
      "Step:968, train: 3.094699557091422e-08\n",
      "Step:969, train: 3.9138867307667504e-08\n",
      "Step:970, train: 4.688453026097531e-08\n",
      "Step:971, train: 5.393491686263381e-08\n",
      "Step:972, train: 6.012224749032396e-08\n",
      "Step:973, train: 6.534399040275805e-08\n",
      "Step:974, train: 6.955126888653046e-08\n",
      "Step:975, train: 7.273703088213542e-08\n",
      "Step:976, train: 7.492606309787322e-08\n",
      "Step:977, train: 7.616825577372752e-08\n",
      "Step:978, train: 7.653044514572722e-08\n",
      "Step:979, train: 7.609240939145647e-08\n",
      "Step:980, train: 7.494128594888655e-08\n",
      "Step:981, train: 7.316797316831846e-08\n",
      "Step:982, train: 7.086395611437024e-08\n",
      "Step:983, train: 6.811921545369492e-08\n",
      "Step:984, train: 6.502027056580424e-08\n",
      "Step:985, train: 6.164878682074723e-08\n",
      "Step:986, train: 5.807996132610745e-08\n",
      "Step:987, train: 5.438331079499207e-08\n",
      "Step:988, train: 5.0620439235510394e-08\n",
      "Step:989, train: 4.684645445291936e-08\n",
      "Step:990, train: 4.3108855559684606e-08\n",
      "Step:991, train: 3.9449264997759273e-08\n",
      "Step:992, train: 3.590163616039749e-08\n",
      "Step:993, train: 3.2493628838554856e-08\n",
      "Step:994, train: 2.9247313574857393e-08\n",
      "Step:995, train: 2.6179776407073316e-08\n",
      "Step:996, train: 2.3302515178019847e-08\n",
      "Step:997, train: 2.0622865476269995e-08\n",
      "Step:998, train: 4.783826353271629e-08\n",
      "Step:999, train: 5.10964455473193e-08\n",
      "5.10964455473193e-08\n"
     ]
    }
   ],
   "source": [
    "model.train(inputs = [],\n",
    "            targets = [],\n",
    "            num_iter = 1000,\n",
    "            N = 0,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting General Lindbladian to General Kraus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "d = 2**n\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "channel_target = KrausMap(d=d, rank=d**2, trainable=False)\n",
    "channel_model = LindbladMap(d=d, rank=d**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelQuantumMap(\n",
    "                        channel =channel_model,\n",
    "                        loss_function = channel_mse_loss,\n",
    "                        optimizer = tf.optimizers.Adam(learning_rate=0.01),\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3182b5eea7944b69888ac180e865a256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:0, train: 1.0126534226086128\n",
      "Step:1, train: 0.9844042464589062\n",
      "Step:2, train: 0.9588133817304019\n",
      "Step:3, train: 0.9365532489062811\n",
      "Step:4, train: 0.9180033382391217\n",
      "Step:5, train: 0.90277409335958\n",
      "Step:6, train: 0.8900186243815834\n",
      "Step:7, train: 0.8789752419070118\n",
      "Step:8, train: 0.8691530209672034\n",
      "Step:9, train: 0.8602809569577109\n",
      "Step:10, train: 0.8522146784377708\n",
      "Step:11, train: 0.8448695050345141\n",
      "Step:12, train: 0.8381809128667785\n",
      "Step:13, train: 0.8320844461060957\n",
      "Step:14, train: 0.8265096245907764\n",
      "Step:15, train: 0.8213839255317674\n",
      "Step:16, train: 0.8166423176452874\n",
      "Step:17, train: 0.8122365504099218\n",
      "Step:18, train: 0.8081394332242903\n",
      "Step:19, train: 0.8043428190811499\n",
      "Step:20, train: 0.8008507878868987\n",
      "Step:21, train: 0.7976704726219104\n",
      "Step:22, train: 0.7948027590282815\n",
      "Step:23, train: 0.7922350390046051\n",
      "Step:24, train: 0.789937767315096\n",
      "Step:25, train: 0.7878658755240193\n",
      "Step:26, train: 0.7859649315732367\n",
      "Step:27, train: 0.7841801715457983\n",
      "Step:28, train: 0.7824654072551673\n",
      "Step:29, train: 0.7807888458972689\n",
      "Step:30, train: 0.7791341069457465\n",
      "Step:31, train: 0.7774966737086692\n",
      "Step:32, train: 0.7758776572590441\n",
      "Step:33, train: 0.774277642681321\n",
      "Step:34, train: 0.7726929830078897\n",
      "Step:35, train: 0.7711154082526214\n",
      "Step:36, train: 0.7695340951072397\n",
      "Step:37, train: 0.7679383733090032\n",
      "Step:38, train: 0.76631948456814\n",
      "Step:39, train: 0.7646709293483458\n",
      "Step:40, train: 0.7629878267970247\n",
      "Step:41, train: 0.7612661061966799\n",
      "Step:42, train: 0.759502109330402\n",
      "Step:43, train: 0.7576926996314094\n",
      "Step:44, train: 0.7558356183313302\n",
      "Step:45, train: 0.7539297236785436\n",
      "Step:46, train: 0.7519749226624893\n",
      "Step:47, train: 0.7499717263580741\n",
      "Step:48, train: 0.7479206773199285\n",
      "Step:49, train: 0.7458218197386928\n",
      "Step:50, train: 0.7436744090090721\n",
      "Step:51, train: 0.7414769524604812\n",
      "Step:52, train: 0.7392275477091066\n",
      "Step:53, train: 0.7369243309816447\n",
      "Step:54, train: 0.7345658863664297\n",
      "Step:55, train: 0.732151406009607\n",
      "Step:56, train: 0.729680589294331\n",
      "Step:57, train: 0.7271533942962397\n",
      "Step:58, train: 0.7246472721267103\n",
      "Step:59, train: 0.7222966912728326\n",
      "Step:60, train: 0.7198748339461667\n",
      "Step:61, train: 0.7173821398781342\n",
      "Step:62, train: 0.7148204777509302\n",
      "Step:63, train: 0.7121938271282682\n",
      "Step:64, train: 0.7095082908837032\n",
      "Step:65, train: 0.7067715091216236\n",
      "Step:66, train: 0.7039919370686156\n",
      "Step:67, train: 0.7011782580198502\n",
      "Step:68, train: 0.698339055429692\n",
      "Step:69, train: 0.695505072959417\n",
      "Step:70, train: 0.6928439815754831\n",
      "Step:71, train: 0.6901581805577786\n",
      "Step:72, train: 0.6878269154310833\n",
      "Step:73, train: 0.6854583788082229\n",
      "Step:74, train: 0.6830469906456761\n",
      "Step:75, train: 0.6809627546258803\n",
      "Step:76, train: 0.6790269908176236\n",
      "Step:77, train: 0.6770807864261261\n",
      "Step:78, train: 0.6750549410025277\n",
      "Step:79, train: 0.6729580853620906\n",
      "Step:80, train: 0.6707950784523782\n",
      "Step:81, train: 0.6685986835813329\n",
      "Step:82, train: 0.6664230785271181\n",
      "Step:83, train: 0.6641841239730677\n",
      "Step:84, train: 0.6618925364841926\n",
      "Step:85, train: 0.6596253241439273\n",
      "Step:86, train: 0.6573397575935425\n",
      "Step:87, train: 0.6550859091558818\n",
      "Step:88, train: 0.6528859181843305\n",
      "Step:89, train: 0.6507021143433862\n",
      "Step:90, train: 0.6486211164537827\n",
      "Step:91, train: 0.6465802888015243\n",
      "Step:92, train: 0.6444511845193259\n",
      "Step:93, train: 0.6422690107521223\n",
      "Step:94, train: 0.6400663256149507\n",
      "Step:95, train: 0.6377827606230182\n",
      "Step:96, train: 0.6354244209486828\n",
      "Step:97, train: 0.6330398062313861\n",
      "Step:98, train: 0.6307279479890524\n",
      "Step:99, train: 0.6283438811784945\n",
      "Step:100, train: 0.6259361422589234\n",
      "Step:101, train: 0.623591432669606\n",
      "Step:102, train: 0.6211528667347848\n",
      "Step:103, train: 0.618642852118563\n",
      "Step:104, train: 0.6160821283003141\n",
      "Step:105, train: 0.613423055947337\n",
      "Step:106, train: 0.6106900065996355\n",
      "Step:107, train: 0.6081360780265307\n",
      "Step:108, train: 0.6055045011725295\n",
      "Step:109, train: 0.6027546517975357\n",
      "Step:110, train: 0.5998920351350308\n",
      "Step:111, train: 0.5969990109120084\n",
      "Step:112, train: 0.5941244877735876\n",
      "Step:113, train: 0.5912818361450056\n",
      "Step:114, train: 0.5883321485782176\n",
      "Step:115, train: 0.5852956521180601\n",
      "Step:116, train: 0.5822075948433687\n",
      "Step:117, train: 0.5790426775964791\n",
      "Step:118, train: 0.5758572393280665\n",
      "Step:119, train: 0.5727811090903705\n",
      "Step:120, train: 0.5696465289379675\n",
      "Step:121, train: 0.5664622865714146\n",
      "Step:122, train: 0.5632721393645281\n",
      "Step:123, train: 0.560012898021877\n",
      "Step:124, train: 0.5566989265737214\n",
      "Step:125, train: 0.5535311402964269\n",
      "Step:126, train: 0.5503812326399857\n",
      "Step:127, train: 0.5472034962585466\n",
      "Step:128, train: 0.5440223398654229\n",
      "Step:129, train: 0.5408170904302956\n",
      "Step:130, train: 0.5376180018911652\n",
      "Step:131, train: 0.5345620449532635\n",
      "Step:132, train: 0.5315167389538409\n",
      "Step:133, train: 0.5289740665148985\n",
      "Step:134, train: 0.5263717089193503\n",
      "Step:135, train: 0.5237521233508282\n",
      "Step:136, train: 0.5210508198077436\n",
      "Step:137, train: 0.5184648375438632\n",
      "Step:138, train: 0.5157904812531625\n",
      "Step:139, train: 0.513189357263966\n",
      "Step:140, train: 0.5104952006523671\n",
      "Step:141, train: 0.5076995525578282\n",
      "Step:142, train: 0.5050548321878996\n",
      "Step:143, train: 0.5026732044788\n",
      "Step:144, train: 0.5004366326312588\n",
      "Step:145, train: 0.4982043081312084\n",
      "Step:146, train: 0.4959039209592358\n",
      "Step:147, train: 0.49353344422020046\n",
      "Step:148, train: 0.49130109728234994\n",
      "Step:149, train: 0.4894067864545654\n",
      "Step:150, train: 0.48765591933705754\n",
      "Step:151, train: 0.4859477109267083\n",
      "Step:152, train: 0.4834762286243729\n",
      "Step:153, train: 0.48101905691030383\n",
      "Step:154, train: 0.47928492505071657\n",
      "Step:155, train: 0.4770379818822864\n",
      "Step:156, train: 0.4756016042209337\n",
      "Step:157, train: 0.473579131322832\n",
      "Step:158, train: 0.4723757482410409\n",
      "Step:159, train: 0.47077793816566416\n",
      "Step:160, train: 0.469246397636364\n",
      "Step:161, train: 0.4674941869929429\n",
      "Step:162, train: 0.4657256823521316\n",
      "Step:163, train: 0.464240417777878\n",
      "Step:164, train: 0.46256476874026975\n",
      "Step:165, train: 0.4610663433664325\n",
      "Step:166, train: 0.4596262675086137\n",
      "Step:167, train: 0.45831626748438703\n",
      "Step:168, train: 0.457126105727264\n",
      "Step:169, train: 0.45588551839102087\n",
      "Step:170, train: 0.45467288353527224\n",
      "Step:171, train: 0.45345763331792144\n",
      "Step:172, train: 0.4521363970068445\n",
      "Step:173, train: 0.4511517340828636\n",
      "Step:174, train: 0.4501495201820076\n",
      "Step:175, train: 0.4490098237058578\n",
      "Step:176, train: 0.44798027775232374\n",
      "Step:177, train: 0.44700775201103293\n",
      "Step:178, train: 0.44596314231386314\n",
      "Step:179, train: 0.4449700118973174\n",
      "Step:180, train: 0.4439829055569947\n",
      "Step:181, train: 0.4430499338537113\n",
      "Step:182, train: 0.4421097115217404\n",
      "Step:183, train: 0.4414080719125519\n",
      "Step:184, train: 0.44061049397149976\n",
      "Step:185, train: 0.43980766813248023\n",
      "Step:186, train: 0.4389867275550523\n",
      "Step:187, train: 0.43823358581278726\n",
      "Step:188, train: 0.4375007018072026\n",
      "Step:189, train: 0.4367896509296557\n",
      "Step:190, train: 0.4360570984983358\n",
      "Step:191, train: 0.4353733237711358\n",
      "Step:192, train: 0.4346604079098742\n",
      "Step:193, train: 0.4340917905207171\n",
      "Step:194, train: 0.43355800636981706\n",
      "Step:195, train: 0.4330545677969878\n",
      "Step:196, train: 0.4324563394267623\n",
      "Step:197, train: 0.4317697552467725\n",
      "Step:198, train: 0.43127015599780916\n",
      "Step:199, train: 0.4309003014684366\n",
      "Step:200, train: 0.4303341614767917\n",
      "Step:201, train: 0.42969613481645436\n",
      "Step:202, train: 0.42924566289989285\n",
      "Step:203, train: 0.4288762684633971\n",
      "Step:204, train: 0.42835680306178736\n",
      "Step:205, train: 0.4278003951040057\n",
      "Step:206, train: 0.42729527089113073\n",
      "Step:207, train: 0.4268572310345461\n",
      "Step:208, train: 0.4264253897888909\n",
      "Step:209, train: 0.42592998102449586\n",
      "Step:210, train: 0.4255629973986743\n",
      "Step:211, train: 0.4251215006979071\n",
      "Step:212, train: 0.42460620874778154\n",
      "Step:213, train: 0.42425630951636817\n",
      "Step:214, train: 0.42383496629052997\n",
      "Step:215, train: 0.4233430310933311\n",
      "Step:216, train: 0.4230166520870642\n",
      "Step:217, train: 0.4226205489628081\n",
      "Step:218, train: 0.4222015904488396\n",
      "Step:219, train: 0.42180774856457914\n",
      "Step:220, train: 0.4214454810901065\n",
      "Step:221, train: 0.42104082400628345\n",
      "Step:222, train: 0.420640677956297\n",
      "Step:223, train: 0.42038933267373335\n",
      "Step:224, train: 0.4200089892516339\n",
      "Step:225, train: 0.4197021756800693\n",
      "Step:226, train: 0.4193694006283294\n",
      "Step:227, train: 0.41889257074317954\n",
      "Step:228, train: 0.4185033849478951\n",
      "Step:229, train: 0.4181905757223245\n",
      "Step:230, train: 0.4178883889350504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:231, train: 0.417572169859164\n",
      "Step:232, train: 0.4171926443033998\n",
      "Step:233, train: 0.41683206999587014\n",
      "Step:234, train: 0.41667042418907885\n",
      "Step:235, train: 0.4164073538503671\n",
      "Step:236, train: 0.41605780802510095\n",
      "Step:237, train: 0.41568790970945146\n",
      "Step:238, train: 0.41556986716845545\n",
      "Step:239, train: 0.41537094319927537\n",
      "Step:240, train: 0.4150562339818574\n",
      "Step:241, train: 0.41470847361814134\n",
      "Step:242, train: 0.4142607984178385\n",
      "Step:243, train: 0.4141188036578436\n",
      "Step:244, train: 0.41386354017184834\n",
      "Step:245, train: 0.41357627124952984\n",
      "Step:246, train: 0.41340121151853043\n",
      "Step:247, train: 0.4130580637108946\n",
      "Step:248, train: 0.4128228331626406\n",
      "Step:249, train: 0.41269286860344123\n",
      "Step:250, train: 0.4124365776576283\n",
      "Step:251, train: 0.4120936997717535\n",
      "Step:252, train: 0.41180770911029896\n",
      "Step:253, train: 0.41159483359333826\n",
      "Step:254, train: 0.4114262385482001\n",
      "Step:255, train: 0.4111684789169252\n",
      "Step:256, train: 0.4109251155925787\n",
      "Step:257, train: 0.41062226542771924\n",
      "Step:258, train: 0.41040898590207164\n",
      "Step:259, train: 0.41022768166591916\n",
      "Step:260, train: 0.4100155494486566\n",
      "Step:261, train: 0.4098188538114836\n",
      "Step:262, train: 0.40953193517852426\n",
      "Step:263, train: 0.4093287055161826\n",
      "Step:264, train: 0.4092117752234879\n",
      "Step:265, train: 0.4090442263642643\n",
      "Step:266, train: 0.4087939742266262\n",
      "Step:267, train: 0.4085594724242152\n",
      "Step:268, train: 0.40841570064643407\n",
      "Step:269, train: 0.4084904674371711\n",
      "Step:270, train: 0.4084679515369799\n",
      "Step:271, train: 0.40810929285031516\n",
      "Step:272, train: 0.4075368129841834\n",
      "Step:273, train: 0.4075294412708965\n",
      "Step:274, train: 0.4076416095590905\n",
      "Step:275, train: 0.40735833167991153\n",
      "Step:276, train: 0.4069088137045821\n",
      "Step:277, train: 0.40674219240404996\n",
      "Step:278, train: 0.40677344340406074\n",
      "Step:279, train: 0.40660696813493513\n",
      "Step:280, train: 0.40630894891894465\n",
      "Step:281, train: 0.40618312839555437\n",
      "Step:282, train: 0.40606423479934173\n",
      "Step:283, train: 0.4059082320840781\n",
      "Step:284, train: 0.4056828349228017\n",
      "Step:285, train: 0.40564366600240825\n",
      "Step:286, train: 0.4054953124598797\n",
      "Step:287, train: 0.4051841487116384\n",
      "Step:288, train: 0.40506137740998216\n",
      "Step:289, train: 0.40501565603178974\n",
      "Step:290, train: 0.4048536422208783\n",
      "Step:291, train: 0.4047274564630579\n",
      "Step:292, train: 0.4045593038303785\n",
      "Step:293, train: 0.40448426753484296\n",
      "Step:294, train: 0.4043308913174439\n",
      "Step:295, train: 0.4042716905589942\n",
      "Step:296, train: 0.4040684725286041\n",
      "Step:297, train: 0.4038910945517973\n",
      "Step:298, train: 0.4037428359732571\n",
      "Step:299, train: 0.4036436160250956\n",
      "Step:300, train: 0.4036220016867978\n",
      "Step:301, train: 0.4034449722796762\n",
      "Step:302, train: 0.40325964470302883\n",
      "Step:303, train: 0.40318041671085136\n",
      "Step:304, train: 0.403169762364076\n",
      "Step:305, train: 0.4030769215926793\n",
      "Step:306, train: 0.402940573905371\n",
      "Step:307, train: 0.40270403474628214\n",
      "Step:308, train: 0.4025257290666734\n",
      "Step:309, train: 0.4025286065874745\n",
      "Step:310, train: 0.40247895358089314\n",
      "Step:311, train: 0.4023513379639784\n",
      "Step:312, train: 0.40216412819029107\n",
      "Step:313, train: 0.4020855989004489\n",
      "Step:314, train: 0.40203294015921487\n",
      "Step:315, train: 0.4020322974696128\n",
      "Step:316, train: 0.40188644912235616\n",
      "Step:317, train: 0.4017080549462114\n",
      "Step:318, train: 0.4015998442454288\n",
      "Step:319, train: 0.4016234168744536\n",
      "Step:320, train: 0.4015176497890963\n",
      "Step:321, train: 0.40139294552671406\n",
      "Step:322, train: 0.40131924095970195\n",
      "Step:323, train: 0.4012576573663521\n",
      "Step:324, train: 0.401219047869931\n",
      "Step:325, train: 0.4010038916499602\n",
      "Step:326, train: 0.4008422433907226\n",
      "Step:327, train: 0.40072710163329384\n",
      "Step:328, train: 0.40071483662075413\n",
      "Step:329, train: 0.40072842328680247\n",
      "Step:330, train: 0.40069018641611726\n",
      "Step:331, train: 0.40051515738821775\n",
      "Step:332, train: 0.40022829427180073\n",
      "Step:333, train: 0.4001295718388482\n",
      "Step:334, train: 0.40020272799170237\n",
      "Step:335, train: 0.4001775485905016\n",
      "Step:336, train: 0.40001244037451555\n",
      "Step:337, train: 0.399817000230193\n",
      "Step:338, train: 0.399868449795978\n",
      "Step:339, train: 0.39987679215843874\n",
      "Step:340, train: 0.3997444450625992\n",
      "Step:341, train: 0.3996612597445297\n",
      "Step:342, train: 0.3995557865284801\n",
      "Step:343, train: 0.3995125916346275\n",
      "Step:344, train: 0.3994019562281836\n",
      "Step:345, train: 0.3992889307132049\n",
      "Step:346, train: 0.39928441538861054\n",
      "Step:347, train: 0.3991840078857527\n",
      "Step:348, train: 0.3992313994696741\n",
      "Step:349, train: 0.3991701606906283\n",
      "Step:350, train: 0.39905074673746277\n",
      "Step:351, train: 0.3989038306685288\n",
      "Step:352, train: 0.39880970289749956\n",
      "Step:353, train: 0.3987000965139272\n",
      "Step:354, train: 0.39863773044195117\n",
      "Step:355, train: 0.3986156377616833\n",
      "Step:356, train: 0.39852359881659616\n",
      "Step:357, train: 0.3983839093555587\n",
      "Step:358, train: 0.3984140380486423\n",
      "Step:359, train: 0.3984394171330925\n",
      "Step:360, train: 0.3983312194401398\n",
      "Step:361, train: 0.3982946544779691\n",
      "Step:362, train: 0.3981497630755375\n",
      "Step:363, train: 0.39815664808501117\n",
      "Step:364, train: 0.3981091884740368\n",
      "Step:365, train: 0.39807262368466656\n",
      "Step:366, train: 0.39798466805607025\n",
      "Step:367, train: 0.39788366421737176\n",
      "Step:368, train: 0.3978818338512247\n",
      "Step:369, train: 0.39783936736651154\n",
      "Step:370, train: 0.39779880067573536\n",
      "Step:371, train: 0.39770251852726\n",
      "Step:372, train: 0.3976447406202904\n",
      "Step:373, train: 0.39763515410858763\n",
      "Step:374, train: 0.3975665616144085\n",
      "Step:375, train: 0.3976141430448964\n",
      "Step:376, train: 0.39755372725925886\n",
      "Step:377, train: 0.39738993619712626\n",
      "Step:378, train: 0.39735773074745684\n",
      "Step:379, train: 0.3973272747307406\n",
      "Step:380, train: 0.39728047396330524\n",
      "Step:381, train: 0.3972309879707236\n",
      "Step:382, train: 0.39719806194465246\n",
      "Step:383, train: 0.39719036668919916\n",
      "Step:384, train: 0.3971164554085991\n",
      "Step:385, train: 0.39695816940962686\n",
      "Step:386, train: 0.39697166697323505\n",
      "Step:387, train: 0.39692327511701786\n",
      "Step:388, train: 0.39687960268373274\n",
      "Step:389, train: 0.3968464563516506\n",
      "Step:390, train: 0.39686262411168843\n",
      "Step:391, train: 0.39683715627029015\n",
      "Step:392, train: 0.39670947725358174\n",
      "Step:393, train: 0.396661455321788\n",
      "Step:394, train: 0.3966357437814715\n",
      "Step:395, train: 0.396612148517538\n",
      "Step:396, train: 0.3964972207253953\n",
      "Step:397, train: 0.3963231018664446\n",
      "Step:398, train: 0.39642353347105486\n",
      "Step:399, train: 0.3965349913592684\n",
      "Step:400, train: 0.39641414947392406\n",
      "Step:401, train: 0.3963865659578838\n",
      "Step:402, train: 0.396422551090944\n",
      "Step:403, train: 0.3963812164970282\n",
      "Step:404, train: 0.39623449077866185\n",
      "Step:405, train: 0.39619116248287767\n",
      "Step:406, train: 0.3961779961912312\n",
      "Step:407, train: 0.3961985547351369\n",
      "Step:408, train: 0.3961968357853035\n",
      "Step:409, train: 0.3961129871006316\n",
      "Step:410, train: 0.3960584149614509\n",
      "Step:411, train: 0.39596878055413787\n",
      "Step:412, train: 0.3958787215949291\n",
      "Step:413, train: 0.3958559725942322\n",
      "Step:414, train: 0.3958537805378478\n",
      "Step:415, train: 0.39582959994509836\n",
      "Step:416, train: 0.3957813523057617\n",
      "Step:417, train: 0.39565005210101895\n",
      "Step:418, train: 0.3957175200099623\n",
      "Step:419, train: 0.39575904969277775\n",
      "Step:420, train: 0.3956703176687434\n",
      "Step:421, train: 0.3956133845789709\n",
      "Step:422, train: 0.3956038751562576\n",
      "Step:423, train: 0.3956043675262839\n",
      "Step:424, train: 0.39552792284161065\n",
      "Step:425, train: 0.3955442092053538\n",
      "Step:426, train: 0.3955053172683212\n",
      "Step:427, train: 0.39541111373198823\n",
      "Step:428, train: 0.39545725722421654\n",
      "Step:429, train: 0.39542412023193435\n",
      "Step:430, train: 0.3954213022970884\n",
      "Step:431, train: 0.3953507796205028\n",
      "Step:432, train: 0.3953054923014763\n",
      "Step:433, train: 0.3952912970903606\n",
      "Step:434, train: 0.39531749939276417\n",
      "Step:435, train: 0.3952533780814146\n",
      "Step:436, train: 0.39521541720396297\n",
      "Step:437, train: 0.3951454179155227\n",
      "Step:438, train: 0.39517289134163713\n",
      "Step:439, train: 0.39527525776225525\n",
      "Step:440, train: 0.39526177722355504\n",
      "Step:441, train: 0.39518700253824135\n",
      "Step:442, train: 0.395139477756186\n",
      "Step:443, train: 0.3951483034217306\n",
      "Step:444, train: 0.3951400205088401\n",
      "Step:445, train: 0.3952010371457141\n",
      "Step:446, train: 0.395207628711796\n",
      "Step:447, train: 0.39503496620565176\n",
      "Step:448, train: 0.39492673315183396\n",
      "Step:449, train: 0.39489510475718825\n",
      "Step:450, train: 0.3949288175759509\n",
      "Step:451, train: 0.39485968308814334\n",
      "Step:452, train: 0.39480109508762296\n",
      "Step:453, train: 0.3948334648239785\n",
      "Step:454, train: 0.3948204155105405\n",
      "Step:455, train: 0.3948255247865884\n",
      "Step:456, train: 0.39472777316845886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:457, train: 0.39461381424215447\n",
      "Step:458, train: 0.39473861477707506\n",
      "Step:459, train: 0.3948012991206069\n",
      "Step:460, train: 0.394710820750188\n",
      "Step:461, train: 0.39461342810529815\n",
      "Step:462, train: 0.3945263089190326\n",
      "Step:463, train: 0.3945723790461285\n",
      "Step:464, train: 0.3946127170897149\n",
      "Step:465, train: 0.39458253262047954\n",
      "Step:466, train: 0.3945712825606912\n",
      "Step:467, train: 0.3944921986190223\n",
      "Step:468, train: 0.3944480645206556\n",
      "Step:469, train: 0.3944100112300686\n",
      "Step:470, train: 0.3944273552880259\n",
      "Step:471, train: 0.3943829513075061\n",
      "Step:472, train: 0.39426850637733135\n",
      "Step:473, train: 0.39430276605613956\n",
      "Step:474, train: 0.39442702422303\n",
      "Step:475, train: 0.394413108207893\n",
      "Step:476, train: 0.39426991778551956\n",
      "Step:477, train: 0.39419872228771363\n",
      "Step:478, train: 0.3942643896693795\n",
      "Step:479, train: 0.39432279751662336\n",
      "Step:480, train: 0.3942339841313925\n",
      "Step:481, train: 0.3941367617817344\n",
      "Step:482, train: 0.3941365541279984\n",
      "Step:483, train: 0.3941990708911828\n",
      "Step:484, train: 0.3941536439207465\n",
      "Step:485, train: 0.39418963099608784\n",
      "Step:486, train: 0.39421648050527897\n",
      "Step:487, train: 0.39412765157667146\n",
      "Step:488, train: 0.39412452208861554\n",
      "Step:489, train: 0.39413403471740094\n",
      "Step:490, train: 0.39411206389651265\n",
      "Step:491, train: 0.39410419528943164\n",
      "Step:492, train: 0.394019042239633\n",
      "Step:493, train: 0.3939914263945793\n",
      "Step:494, train: 0.3940503759697144\n",
      "Step:495, train: 0.3940946101519179\n",
      "Step:496, train: 0.3940102851160121\n",
      "Step:497, train: 0.3938388033152471\n",
      "Step:498, train: 0.39393244636695307\n",
      "Step:499, train: 0.3939832059365995\n",
      "Step:500, train: 0.3939679337549033\n",
      "Step:501, train: 0.3938967063576122\n",
      "Step:502, train: 0.39387466883956557\n",
      "Step:503, train: 0.3939447680240404\n",
      "Step:504, train: 0.3938866576900874\n",
      "Step:505, train: 0.3938573117952391\n",
      "Step:506, train: 0.39388490045069396\n",
      "Step:507, train: 0.39380291835834713\n",
      "Step:508, train: 0.3938157213748698\n",
      "Step:509, train: 0.39385675199684844\n",
      "Step:510, train: 0.39386012656955555\n",
      "Step:511, train: 0.3938615390188791\n",
      "Step:512, train: 0.3937737381335469\n",
      "Step:513, train: 0.3936973724471642\n",
      "Step:514, train: 0.3937406489200154\n",
      "Step:515, train: 0.39379679528091943\n",
      "Step:516, train: 0.39369422245087354\n",
      "Step:517, train: 0.393583840314465\n",
      "Step:518, train: 0.39371028982004563\n",
      "Step:519, train: 0.39381012548375316\n",
      "Step:520, train: 0.3937743971514502\n",
      "Step:521, train: 0.3937606805298912\n",
      "Step:522, train: 0.3937982197859301\n",
      "Step:523, train: 0.3938997995023643\n",
      "Step:524, train: 0.3939190024845108\n",
      "Step:525, train: 0.3938581859502145\n",
      "Step:526, train: 0.3937546715829503\n",
      "Step:527, train: 0.3936864602725971\n",
      "Step:528, train: 0.39361024977229675\n",
      "Step:529, train: 0.393584539945534\n",
      "Step:530, train: 0.39366154563278605\n",
      "Step:531, train: 0.3936677153553497\n",
      "Step:532, train: 0.39352271806123307\n",
      "Step:533, train: 0.3935158834364998\n",
      "Step:534, train: 0.39351768145515\n",
      "Step:535, train: 0.39358687617198873\n",
      "Step:536, train: 0.39354469295126765\n",
      "Step:537, train: 0.39344886675252044\n",
      "Step:538, train: 0.39346911227306364\n",
      "Step:539, train: 0.3935745416494296\n",
      "Step:540, train: 0.39356969279558557\n",
      "Step:541, train: 0.39348302402240737\n",
      "Step:542, train: 0.3934196173720412\n",
      "Step:543, train: 0.3935047455472852\n",
      "Step:544, train: 0.3935559290185866\n",
      "Step:545, train: 0.3935482808288474\n",
      "Step:546, train: 0.3935017345571385\n",
      "Step:547, train: 0.39348446812844323\n",
      "Step:548, train: 0.393455884590311\n",
      "Step:549, train: 0.3934061354583474\n",
      "Step:550, train: 0.393458005005011\n",
      "Step:551, train: 0.3934638280624815\n",
      "Step:552, train: 0.393305407938428\n",
      "Step:553, train: 0.39335804462035073\n",
      "Step:554, train: 0.3934981033621423\n",
      "Step:555, train: 0.39350544474476246\n",
      "Step:556, train: 0.3933878207572946\n",
      "Step:557, train: 0.393277635646763\n",
      "Step:558, train: 0.39328544843943386\n",
      "Step:559, train: 0.3933580876482679\n",
      "Step:560, train: 0.39340112132579286\n",
      "Step:561, train: 0.39332226541577764\n",
      "Step:562, train: 0.39326316343788004\n",
      "Step:563, train: 0.3933757203762085\n",
      "Step:564, train: 0.3934222457555747\n",
      "Step:565, train: 0.3933473818267064\n",
      "Step:566, train: 0.3933005899404518\n",
      "Step:567, train: 0.39328319459810246\n",
      "Step:568, train: 0.3932783870720147\n",
      "Step:569, train: 0.3932703677346598\n",
      "Step:570, train: 0.3932910437032565\n",
      "Step:571, train: 0.3933135683757721\n",
      "Step:572, train: 0.3932586036076715\n",
      "Step:573, train: 0.39325114294111274\n",
      "Step:574, train: 0.39329749105458167\n",
      "Step:575, train: 0.39336808323692984\n",
      "Step:576, train: 0.39329531520483757\n",
      "Step:577, train: 0.39318510718410793\n",
      "Step:578, train: 0.3932208768604366\n",
      "Step:579, train: 0.3933049819203519\n",
      "Step:580, train: 0.39325503078432283\n",
      "Step:581, train: 0.39322844136480467\n",
      "Step:582, train: 0.39316569802015044\n",
      "Step:583, train: 0.3931902475391962\n",
      "Step:584, train: 0.3932429624984094\n",
      "Step:585, train: 0.3932674517073488\n",
      "Step:586, train: 0.3932273848833874\n",
      "Step:587, train: 0.393164932821914\n",
      "Step:588, train: 0.39319526585733056\n",
      "Step:589, train: 0.39321526239191945\n",
      "Step:590, train: 0.39321655809731176\n",
      "Step:591, train: 0.3932304015585647\n",
      "Step:592, train: 0.3931513251605113\n",
      "Step:593, train: 0.39313598775453373\n",
      "Step:594, train: 0.3932186992854391\n",
      "Step:595, train: 0.3932464206026149\n",
      "Step:596, train: 0.3931650147440157\n",
      "Step:597, train: 0.3931126754883839\n",
      "Step:598, train: 0.3931929492935544\n",
      "Step:599, train: 0.3932955831676448\n",
      "Step:600, train: 0.39325122070082386\n",
      "Step:601, train: 0.39315912050295726\n",
      "Step:602, train: 0.39314530779943063\n",
      "Step:603, train: 0.3932725222281314\n",
      "Step:604, train: 0.39330861336400946\n",
      "Step:605, train: 0.3932812611611384\n",
      "Step:606, train: 0.39328560193020073\n",
      "Step:607, train: 0.39325179717687603\n",
      "Step:608, train: 0.393173592377366\n",
      "Step:609, train: 0.39319652417796436\n",
      "Step:610, train: 0.39322373756336854\n",
      "Step:611, train: 0.3932115270634132\n",
      "Step:612, train: 0.39308636890870535\n",
      "Step:613, train: 0.39307678656331635\n",
      "Step:614, train: 0.39320178327159516\n",
      "Step:615, train: 0.39326044000844074\n",
      "Step:616, train: 0.39323549765740073\n",
      "Step:617, train: 0.3930865449500245\n",
      "Step:618, train: 0.393074262256603\n",
      "Step:619, train: 0.39319529358654604\n",
      "Step:620, train: 0.3931791624851737\n",
      "Step:621, train: 0.3930437160751258\n",
      "Step:622, train: 0.393015066315126\n",
      "Step:623, train: 0.39315847256686165\n",
      "Step:624, train: 0.3932073246141936\n",
      "Step:625, train: 0.3931839723695243\n",
      "Step:626, train: 0.39312236566778413\n",
      "Step:627, train: 0.3930623294477728\n",
      "Step:628, train: 0.3930467877658098\n",
      "Step:629, train: 0.3930739260391455\n",
      "Step:630, train: 0.39313282210390005\n",
      "Step:631, train: 0.3931720002783589\n",
      "Step:632, train: 0.3930675953514836\n",
      "Step:633, train: 0.3930216367456268\n",
      "Step:634, train: 0.39309495253593923\n",
      "Step:635, train: 0.3931420599562821\n",
      "Step:636, train: 0.39309593368097817\n",
      "Step:637, train: 0.39291960463595277\n",
      "Step:638, train: 0.3930009712422384\n",
      "Step:639, train: 0.3931378741985132\n",
      "Step:640, train: 0.39311559129792245\n",
      "Step:641, train: 0.39303506176605263\n",
      "Step:642, train: 0.3929882146989965\n",
      "Step:643, train: 0.3931099436311727\n",
      "Step:644, train: 0.39313559003995224\n",
      "Step:645, train: 0.39303628769124\n",
      "Step:646, train: 0.39303458641255656\n",
      "Step:647, train: 0.3930657206994951\n",
      "Step:648, train: 0.39305225086458695\n",
      "Step:649, train: 0.39299756658471946\n",
      "Step:650, train: 0.39302688297356353\n",
      "Step:651, train: 0.393023969605521\n",
      "Step:652, train: 0.39292457156830185\n",
      "Step:653, train: 0.39293695254691974\n",
      "Step:654, train: 0.3930399480537198\n",
      "Step:655, train: 0.3930505035071398\n",
      "Step:656, train: 0.3929526582505146\n",
      "Step:657, train: 0.3928917785275309\n",
      "Step:658, train: 0.3930045758714139\n",
      "Step:659, train: 0.39308708513424034\n",
      "Step:660, train: 0.3929843479116439\n",
      "Step:661, train: 0.39289951113145005\n",
      "Step:662, train: 0.3929451429282014\n",
      "Step:663, train: 0.39301908221198445\n",
      "Step:664, train: 0.3929809807424891\n",
      "Step:665, train: 0.39292048413405467\n",
      "Step:666, train: 0.3929349111889095\n",
      "Step:667, train: 0.3929233382005106\n",
      "Step:668, train: 0.3929194207230857\n",
      "Step:669, train: 0.3929530408567486\n",
      "Step:670, train: 0.3930340109377795\n",
      "Step:671, train: 0.39305447142957867\n",
      "Step:672, train: 0.39289894002089\n",
      "Step:673, train: 0.39282129069266936\n",
      "Step:674, train: 0.3929550953888693\n",
      "Step:675, train: 0.392992309034092\n",
      "Step:676, train: 0.3929196183748703\n",
      "Step:677, train: 0.39284039793717807\n",
      "Step:678, train: 0.3929448285208664\n",
      "Step:679, train: 0.3929971355655783\n",
      "Step:680, train: 0.39294806432803026\n",
      "Step:681, train: 0.39288092757951454\n",
      "Step:682, train: 0.39287936015888736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:683, train: 0.39296206709025244\n",
      "Step:684, train: 0.3929710809613569\n",
      "Step:685, train: 0.39288824462720684\n",
      "Step:686, train: 0.3928645720422961\n",
      "Step:687, train: 0.39278816580126896\n",
      "Step:688, train: 0.3928196648080733\n",
      "Step:689, train: 0.3928379712563629\n",
      "Step:690, train: 0.3928483308318473\n",
      "Step:691, train: 0.39289288663286603\n",
      "Step:692, train: 0.3928325849653418\n",
      "Step:693, train: 0.3928173903658397\n",
      "Step:694, train: 0.39285633346134774\n",
      "Step:695, train: 0.3929490685153546\n",
      "Step:696, train: 0.392898854445832\n",
      "Step:697, train: 0.3927675989815894\n",
      "Step:698, train: 0.39276677721944087\n",
      "Step:699, train: 0.3928308901875917\n",
      "Step:700, train: 0.39287117324288223\n",
      "Step:701, train: 0.3927681460900415\n",
      "Step:702, train: 0.3927657983711341\n",
      "Step:703, train: 0.39288740372431497\n",
      "Step:704, train: 0.39290636976296545\n",
      "Step:705, train: 0.39280047449395317\n",
      "Step:706, train: 0.39276450395803364\n",
      "Step:707, train: 0.39279354842969383\n",
      "Step:708, train: 0.3927901691924817\n",
      "Step:709, train: 0.3928182585783274\n",
      "Step:710, train: 0.3928328607664797\n",
      "Step:711, train: 0.3927972516402093\n",
      "Step:712, train: 0.3926895667784886\n",
      "Step:713, train: 0.3927112492001449\n",
      "Step:714, train: 0.3927626251222869\n",
      "Step:715, train: 0.39285157247517755\n",
      "Step:716, train: 0.39280192861871965\n",
      "Step:717, train: 0.39265820857410894\n",
      "Step:718, train: 0.39268797908593867\n",
      "Step:719, train: 0.3927646766645333\n",
      "Step:720, train: 0.3927296907930305\n",
      "Step:721, train: 0.39268131442336657\n",
      "Step:722, train: 0.3927336891994171\n",
      "Step:723, train: 0.3928149992983913\n",
      "Step:724, train: 0.3927676752512072\n",
      "Step:725, train: 0.39272149169442505\n",
      "Step:726, train: 0.3927898283450026\n",
      "Step:727, train: 0.3927900309278783\n",
      "Step:728, train: 0.3927573035597519\n",
      "Step:729, train: 0.3927525633836594\n",
      "Step:730, train: 0.39282354918350326\n",
      "Step:731, train: 0.39286901874955527\n",
      "Step:732, train: 0.39276881245065476\n",
      "Step:733, train: 0.3927088100112388\n",
      "Step:734, train: 0.3927651363168636\n",
      "Step:735, train: 0.39275426833237903\n",
      "Step:736, train: 0.3927203276911423\n",
      "Step:737, train: 0.3926093796299233\n",
      "Step:738, train: 0.3926985328672852\n",
      "Step:739, train: 0.39273752808763773\n",
      "Step:740, train: 0.39271986676487136\n",
      "Step:741, train: 0.3926892620690457\n",
      "Step:742, train: 0.3926729774988205\n",
      "Step:743, train: 0.3927277159482129\n",
      "Step:744, train: 0.3927148803877969\n",
      "Step:745, train: 0.3927158965228486\n",
      "Step:746, train: 0.3927416786099283\n",
      "Step:747, train: 0.3926891289544281\n",
      "Step:748, train: 0.39266091342293863\n",
      "Step:749, train: 0.3926332960353458\n",
      "Step:750, train: 0.39275113228745673\n",
      "Step:751, train: 0.392685342932689\n",
      "Step:752, train: 0.39262935457800296\n",
      "Step:753, train: 0.3926712503664567\n",
      "Step:754, train: 0.3927099831500209\n",
      "Step:755, train: 0.39269979349126166\n",
      "Step:756, train: 0.392637647088141\n",
      "Step:757, train: 0.3925890363545206\n",
      "Step:758, train: 0.3927009373992601\n",
      "Step:759, train: 0.39278733776569474\n",
      "Step:760, train: 0.3926911407241058\n",
      "Step:761, train: 0.39261874824419984\n",
      "Step:762, train: 0.3925884323440868\n",
      "Step:763, train: 0.3927097310011317\n",
      "Step:764, train: 0.39265078251616536\n",
      "Step:765, train: 0.3926061467913269\n",
      "Step:766, train: 0.392645096608967\n",
      "Step:767, train: 0.3926816919391079\n",
      "Step:768, train: 0.3926391404724932\n",
      "Step:769, train: 0.3925410523309403\n",
      "Step:770, train: 0.39260196447653817\n",
      "Step:771, train: 0.39261145912313056\n",
      "Step:772, train: 0.3925046476767766\n",
      "Step:773, train: 0.39255393892153934\n",
      "Step:774, train: 0.39264439420273056\n",
      "Step:775, train: 0.39261395867402227\n",
      "Step:776, train: 0.39259562675737214\n",
      "Step:777, train: 0.39253519562359745\n",
      "Step:778, train: 0.39257777432842655\n",
      "Step:779, train: 0.39264717799257964\n",
      "Step:780, train: 0.3927056303220238\n",
      "Step:781, train: 0.39263649292075686\n",
      "Step:782, train: 0.392562587732068\n",
      "Step:783, train: 0.3926404610028502\n",
      "Step:784, train: 0.3926022503218576\n",
      "Step:785, train: 0.39258647384521267\n",
      "Step:786, train: 0.39258982832750655\n",
      "Step:787, train: 0.39253071243060844\n",
      "Step:788, train: 0.39253892470362883\n",
      "Step:789, train: 0.39248144049056366\n",
      "Step:790, train: 0.392560918909869\n",
      "Step:791, train: 0.3925894975667972\n",
      "Step:792, train: 0.3925108497162674\n",
      "Step:793, train: 0.3924427879186443\n",
      "Step:794, train: 0.3926006192222764\n",
      "Step:795, train: 0.3926624355591821\n",
      "Step:796, train: 0.39257818260831767\n",
      "Step:797, train: 0.39243866366826896\n",
      "Step:798, train: 0.39251041169844464\n",
      "Step:799, train: 0.39257248157283536\n",
      "Step:800, train: 0.39255548936543694\n",
      "Step:801, train: 0.39249251794545736\n",
      "Step:802, train: 0.3924696252920089\n",
      "Step:803, train: 0.3925453411777341\n",
      "Step:804, train: 0.3926275576652623\n",
      "Step:805, train: 0.3926726841216739\n",
      "Step:806, train: 0.3927549142112884\n",
      "Step:807, train: 0.3927493294949517\n",
      "Step:808, train: 0.39275387657379707\n",
      "Step:809, train: 0.3927719212454623\n",
      "Step:810, train: 0.3927327095227138\n",
      "Step:811, train: 0.3925844926893043\n",
      "Step:812, train: 0.39243855945445494\n",
      "Step:813, train: 0.39258310392041973\n",
      "Step:814, train: 0.39276556978578886\n",
      "Step:815, train: 0.3927569327970678\n",
      "Step:816, train: 0.3925894345728884\n",
      "Step:817, train: 0.3924358668836532\n",
      "Step:818, train: 0.3924667085024664\n",
      "Step:819, train: 0.3925609256899648\n",
      "Step:820, train: 0.3925593567845729\n",
      "Step:821, train: 0.3925079938678016\n",
      "Step:822, train: 0.39251089139538187\n",
      "Step:823, train: 0.39257675680731163\n",
      "Step:824, train: 0.39256820109735724\n",
      "Step:825, train: 0.39253609170838333\n",
      "Step:826, train: 0.3924966176703404\n",
      "Step:827, train: 0.39242032758418255\n",
      "Step:828, train: 0.3924090386617525\n",
      "Step:829, train: 0.3923926671970832\n",
      "Step:830, train: 0.39239488239193776\n",
      "Step:831, train: 0.3924940181773282\n",
      "Step:832, train: 0.3924260090288218\n",
      "Step:833, train: 0.3924211123451254\n",
      "Step:834, train: 0.3925374614256062\n",
      "Step:835, train: 0.39261602119117023\n",
      "Step:836, train: 0.3925655938775291\n",
      "Step:837, train: 0.39239077598002803\n",
      "Step:838, train: 0.3924298702586639\n",
      "Step:839, train: 0.39251225740302836\n",
      "Step:840, train: 0.39249700549873046\n",
      "Step:841, train: 0.39236785071189983\n",
      "Step:842, train: 0.39229422076608655\n",
      "Step:843, train: 0.3924944834802224\n",
      "Step:844, train: 0.39250592900759107\n",
      "Step:845, train: 0.3924670207162597\n",
      "Step:846, train: 0.3924563588965671\n",
      "Step:847, train: 0.3923830408388079\n",
      "Step:848, train: 0.39238788727132057\n",
      "Step:849, train: 0.39240349159026006\n",
      "Step:850, train: 0.39240879552969393\n",
      "Step:851, train: 0.39239599596337893\n",
      "Step:852, train: 0.39231019946093804\n",
      "Step:853, train: 0.39231085679262545\n",
      "Step:854, train: 0.39243351445164715\n",
      "Step:855, train: 0.3924637219728498\n",
      "Step:856, train: 0.39236125692255763\n",
      "Step:857, train: 0.39226730225953343\n",
      "Step:858, train: 0.39236217465019985\n",
      "Step:859, train: 0.392404928921786\n",
      "Step:860, train: 0.3923957835833099\n",
      "Step:861, train: 0.39231465601632576\n",
      "Step:862, train: 0.3922872034136865\n",
      "Step:863, train: 0.39239705835131494\n",
      "Step:864, train: 0.39238607830354366\n",
      "Step:865, train: 0.39230705654079034\n",
      "Step:866, train: 0.392355529954144\n",
      "Step:867, train: 0.3923827097428497\n",
      "Step:868, train: 0.3923453558372779\n",
      "Step:869, train: 0.39232091265060554\n",
      "Step:870, train: 0.3923677657316911\n",
      "Step:871, train: 0.3923781138738457\n",
      "Step:872, train: 0.3923049985923524\n",
      "Step:873, train: 0.3922923260937329\n",
      "Step:874, train: 0.39233741437343167\n",
      "Step:875, train: 0.3924101098626036\n",
      "Step:876, train: 0.3923890364147318\n",
      "Step:877, train: 0.3922391671437515\n",
      "Step:878, train: 0.39229770856333523\n",
      "Step:879, train: 0.3924386211978787\n",
      "Step:880, train: 0.39240260439497465\n",
      "Step:881, train: 0.3923340117888687\n",
      "Step:882, train: 0.39230311111779737\n",
      "Step:883, train: 0.3923582453941578\n",
      "Step:884, train: 0.39241040195678834\n",
      "Step:885, train: 0.3923847361580867\n",
      "Step:886, train: 0.39233718772360626\n",
      "Step:887, train: 0.3922847047016984\n",
      "Step:888, train: 0.3923314279373469\n",
      "Step:889, train: 0.3923270672092425\n",
      "Step:890, train: 0.3923394338040367\n",
      "Step:891, train: 0.39239577827590766\n",
      "Step:892, train: 0.3923113940872515\n",
      "Step:893, train: 0.39230200301500373\n",
      "Step:894, train: 0.3923723796371664\n",
      "Step:895, train: 0.3923703463251531\n",
      "Step:896, train: 0.39234938946319864\n",
      "Step:897, train: 0.39223138827772225\n",
      "Step:898, train: 0.39224723255902744\n",
      "Step:899, train: 0.3923488656649462\n",
      "Step:900, train: 0.3923534922594558\n",
      "Step:901, train: 0.3922198726531449\n",
      "Step:902, train: 0.39223395242705994\n",
      "Step:903, train: 0.39234767880704474\n",
      "Step:904, train: 0.3923185065571455\n",
      "Step:905, train: 0.39224266416666687\n",
      "Step:906, train: 0.3922984924285966\n",
      "Step:907, train: 0.3922879225610132\n",
      "Step:908, train: 0.3922880370912089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:909, train: 0.39225599680932965\n",
      "Step:910, train: 0.39229525760422773\n",
      "Step:911, train: 0.39232065632291147\n",
      "Step:912, train: 0.3922501162987817\n",
      "Step:913, train: 0.3922204557792027\n",
      "Step:914, train: 0.39232264146877893\n",
      "Step:915, train: 0.39240277256809164\n",
      "Step:916, train: 0.39235179400063047\n",
      "Step:917, train: 0.3922509008518579\n",
      "Step:918, train: 0.3923450233306588\n",
      "Step:919, train: 0.39252526973059804\n",
      "Step:920, train: 0.3925569005482225\n",
      "Step:921, train: 0.3924960276162399\n",
      "Step:922, train: 0.3923920017303967\n",
      "Step:923, train: 0.39246109112836397\n",
      "Step:924, train: 0.3924410474804729\n",
      "Step:925, train: 0.3923172520731035\n",
      "Step:926, train: 0.39230498062473673\n",
      "Step:927, train: 0.3923183758641007\n",
      "Step:928, train: 0.3923098193197806\n",
      "Step:929, train: 0.3922833034807733\n",
      "Step:930, train: 0.3923248939572738\n",
      "Step:931, train: 0.39235882700063646\n",
      "Step:932, train: 0.3922824941102854\n",
      "Step:933, train: 0.3922543496703558\n",
      "Step:934, train: 0.3922759431248518\n",
      "Step:935, train: 0.392299546183562\n",
      "Step:936, train: 0.3923169466984178\n",
      "Step:937, train: 0.3922132164393499\n",
      "Step:938, train: 0.3922356891975891\n",
      "Step:939, train: 0.39232843452551314\n",
      "Step:940, train: 0.39228865356488946\n",
      "Step:941, train: 0.3921665813526747\n",
      "Step:942, train: 0.392154742706915\n",
      "Step:943, train: 0.3922319648416911\n",
      "Step:944, train: 0.39228778789783425\n",
      "Step:945, train: 0.3922731612512267\n",
      "Step:946, train: 0.392266228561488\n",
      "Step:947, train: 0.3922093623345089\n",
      "Step:948, train: 0.39219395018332515\n",
      "Step:949, train: 0.3921746551624235\n",
      "Step:950, train: 0.39226788237089083\n",
      "Step:951, train: 0.39227702140340576\n",
      "Step:952, train: 0.3921304190838617\n",
      "Step:953, train: 0.3921462917980847\n",
      "Step:954, train: 0.3922505937508951\n",
      "Step:955, train: 0.3922551494576629\n",
      "Step:956, train: 0.39220419618637004\n",
      "Step:957, train: 0.39211552363403074\n",
      "Step:958, train: 0.3921981040819708\n",
      "Step:959, train: 0.3922441722343256\n",
      "Step:960, train: 0.3922218013014307\n",
      "Step:961, train: 0.39216670268901044\n",
      "Step:962, train: 0.3921745651499791\n",
      "Step:963, train: 0.3922523023235448\n",
      "Step:964, train: 0.39222558769144256\n",
      "Step:965, train: 0.39218090314839804\n",
      "Step:966, train: 0.39221120179539765\n",
      "Step:967, train: 0.39216194311640784\n",
      "Step:968, train: 0.3921383169374847\n",
      "Step:969, train: 0.39219150027971034\n",
      "Step:970, train: 0.39223557777727813\n",
      "Step:971, train: 0.3922054559339292\n",
      "Step:972, train: 0.39213214446114025\n",
      "Step:973, train: 0.3921429595971901\n",
      "Step:974, train: 0.3922168664710579\n",
      "Step:975, train: 0.39226587501780874\n",
      "Step:976, train: 0.3921974362523105\n",
      "Step:977, train: 0.39211252481540915\n",
      "Step:978, train: 0.3921727382462225\n",
      "Step:979, train: 0.39221910303670016\n",
      "Step:980, train: 0.3921639264837695\n",
      "Step:981, train: 0.39216033406926326\n",
      "Step:982, train: 0.3921421533780745\n",
      "Step:983, train: 0.39219328466904485\n",
      "Step:984, train: 0.39219437251655\n",
      "Step:985, train: 0.3921795845561813\n",
      "Step:986, train: 0.39215757832378917\n",
      "Step:987, train: 0.3921459123766696\n",
      "Step:988, train: 0.3921353340300129\n",
      "Step:989, train: 0.39215061030026954\n",
      "Step:990, train: 0.39220385464040075\n",
      "Step:991, train: 0.3921679178684024\n",
      "Step:992, train: 0.392091137353178\n",
      "Step:993, train: 0.39215578305060894\n",
      "Step:994, train: 0.39220277286025446\n",
      "Step:995, train: 0.3922149730821798\n",
      "Step:996, train: 0.3921876103099741\n",
      "Step:997, train: 0.39208853590268616\n",
      "Step:998, train: 0.3921253267477178\n",
      "Step:999, train: 0.3922019026092872\n",
      "0.3922019026092872\n"
     ]
    }
   ],
   "source": [
    "model.train(inputs = [],\n",
    "            targets = [channel_target],\n",
    "            num_iter = 1000,\n",
    "            N = 0,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "d = 2**n\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "channel_model = KrausMap(d=d, rank=d**2)\n",
    "channel_target = LindbladMap(d=d, rank=d**2, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelQuantumMap(\n",
    "                        channel =channel_model,\n",
    "                        loss_function = channel_mse_loss,\n",
    "                        optimizer = tf.optimizers.Adam(learning_rate=0.01),\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198169bca8f043c09836779781f364bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:0, train: 1.0126534226086128\n",
      "Step:1, train: 0.9819963671213354\n",
      "Step:2, train: 0.9520102070109544\n",
      "Step:3, train: 0.92272207295173\n",
      "Step:4, train: 0.8941527819258797\n",
      "Step:5, train: 0.866316148628545\n",
      "Step:6, train: 0.8392209939226806\n",
      "Step:7, train: 0.8128716780526031\n",
      "Step:8, train: 0.7872670600249952\n",
      "Step:9, train: 0.7624012510066807\n",
      "Step:10, train: 0.7382643793364578\n",
      "Step:11, train: 0.7148434984812297\n",
      "Step:12, train: 0.6921231578250121\n",
      "Step:13, train: 0.6700859271661228\n",
      "Step:14, train: 0.6487131805974511\n",
      "Step:15, train: 0.6279855688895871\n",
      "Step:16, train: 0.6078835056690476\n",
      "Step:17, train: 0.5883873540482158\n",
      "Step:18, train: 0.5694776443638936\n",
      "Step:19, train: 0.5511353233282077\n",
      "Step:20, train: 0.5333420528943017\n",
      "Step:21, train: 0.5160805753104061\n",
      "Step:22, train: 0.4993349812268111\n",
      "Step:23, train: 0.4830907456995725\n",
      "Step:24, train: 0.46733476570889537\n",
      "Step:25, train: 0.45205516229146575\n",
      "Step:26, train: 0.4372411656251476\n",
      "Step:27, train: 0.422882871328604\n",
      "Step:28, train: 0.4089710135534737\n",
      "Step:29, train: 0.3954967650275001\n",
      "Step:30, train: 0.382451636350992\n",
      "Step:31, train: 0.3698272871523337\n",
      "Step:32, train: 0.3576154625682401\n",
      "Step:33, train: 0.34580785153349225\n",
      "Step:34, train: 0.33439605895949953\n",
      "Step:35, train: 0.323371502640435\n",
      "Step:36, train: 0.3127253933833357\n",
      "Step:37, train: 0.30244867320008484\n",
      "Step:38, train: 0.2925320185632365\n",
      "Step:39, train: 0.2829658255747216\n",
      "Step:40, train: 0.27374019422983226\n",
      "Step:41, train: 0.26484495714928646\n",
      "Step:42, train: 0.25626969480972794\n",
      "Step:43, train: 0.2480037673891719\n",
      "Step:44, train: 0.24003637277295248\n",
      "Step:45, train: 0.2323565758901652\n",
      "Step:46, train: 0.22495342700579707\n",
      "Step:47, train: 0.21781600027487244\n",
      "Step:48, train: 0.21093349526828026\n",
      "Step:49, train: 0.20429532682902202\n",
      "Step:50, train: 0.19789118332191707\n",
      "Step:51, train: 0.1917110884235882\n",
      "Step:52, train: 0.18574546983920526\n",
      "Step:53, train: 0.17998519055280676\n",
      "Step:54, train: 0.1744216111062688\n",
      "Step:55, train: 0.16904660245186437\n",
      "Step:56, train: 0.16385259761708676\n",
      "Step:57, train: 0.1588325965895569\n",
      "Step:58, train: 0.15398018072834055\n",
      "Step:59, train: 0.1492895302519319\n",
      "Step:60, train: 0.1447553997667413\n",
      "Step:61, train: 0.14037311138574504\n",
      "Step:62, train: 0.13613853447697105\n",
      "Step:63, train: 0.13204803165646684\n",
      "Step:64, train: 0.12809842852062378\n",
      "Step:65, train: 0.12428695655315136\n",
      "Step:66, train: 0.1206112126308409\n",
      "Step:67, train: 0.11706908383016466\n",
      "Step:68, train: 0.11365869821315513\n",
      "Step:69, train: 0.11037835804467223\n",
      "Step:70, train: 0.10722647062562002\n",
      "Step:71, train: 0.10420149777277672\n",
      "Step:72, train: 0.10130188195923995\n",
      "Step:73, train: 0.098526001027446\n",
      "Step:74, train: 0.09587211482287011\n",
      "Step:75, train: 0.0933383245072979\n",
      "Step:76, train: 0.09092252773185652\n",
      "Step:77, train: 0.08862240036325361\n",
      "Step:78, train: 0.08643537601201072\n",
      "Step:79, train: 0.08435863444250774\n",
      "Step:80, train: 0.082389104552482\n",
      "Step:81, train: 0.08052347291978824\n",
      "Step:82, train: 0.07875819815966772\n",
      "Step:83, train: 0.07708953673174909\n",
      "Step:84, train: 0.075513572754573\n",
      "Step:85, train: 0.0740262493237902\n",
      "Step:86, train: 0.07262340321363693\n",
      "Step:87, train: 0.07130080556531859\n",
      "Step:88, train: 0.07005419599317997\n",
      "Step:89, train: 0.06887931564764221\n",
      "Step:90, train: 0.06777194666082861\n",
      "Step:91, train: 0.06672793650368791\n",
      "Step:92, train: 0.06574322610176314\n",
      "Step:93, train: 0.06481386977743421\n",
      "Step:94, train: 0.06393605366596214\n",
      "Step:95, train: 0.0631061066943347\n",
      "Step:96, train: 0.06232050842068057\n",
      "Step:97, train: 0.06157589670157112\n",
      "Step:98, train: 0.06086906203914852\n",
      "Step:99, train: 0.06019695255356043\n",
      "Step:100, train: 0.059556664455101695\n",
      "Step:101, train: 0.05894543895280525\n",
      "Step:102, train: 0.05836065356631161\n",
      "Step:103, train: 0.057799814664983344\n",
      "Step:104, train: 0.05726054889898404\n",
      "Step:105, train: 0.05674059364420978\n",
      "Step:106, train: 0.05623779182237001\n",
      "Step:107, train: 0.05575008213541337\n",
      "Step:108, train: 0.05527548997449819\n",
      "Step:109, train: 0.05481212392849201\n",
      "Step:110, train: 0.054358167474379784\n",
      "Step:111, train: 0.053911873363998275\n",
      "Step:112, train: 0.0534715579195\n",
      "Step:113, train: 0.05303559684208522\n",
      "Step:114, train: 0.05260242071240494\n",
      "Step:115, train: 0.05217050865252061\n",
      "Step:116, train: 0.051738386312864336\n",
      "Step:117, train: 0.05130462224785637\n",
      "Step:118, train: 0.05086782426269814\n",
      "Step:119, train: 0.050426635686427794\n",
      "Step:120, train: 0.04997973323096925\n",
      "Step:121, train: 0.04952582409482777\n",
      "Step:122, train: 0.04906364558565469\n",
      "Step:123, train: 0.04859196260831429\n",
      "Step:124, train: 0.04810956585727867\n",
      "Step:125, train: 0.047615272625381615\n",
      "Step:126, train: 0.04710792656619542\n",
      "Step:127, train: 0.046586399792330674\n",
      "Step:128, train: 0.046049592441114715\n",
      "Step:129, train: 0.04549643384990937\n",
      "Step:130, train: 0.044925889726109586\n",
      "Step:131, train: 0.04433696130760391\n",
      "Step:132, train: 0.043728693425710854\n",
      "Step:133, train: 0.04310017777941356\n",
      "Step:134, train: 0.04245055910414178\n",
      "Step:135, train: 0.04177904513305997\n",
      "Step:136, train: 0.041084911319689534\n",
      "Step:137, train: 0.040367512076579945\n",
      "Step:138, train: 0.03962628953749106\n",
      "Step:139, train: 0.038860786571761105\n",
      "Step:140, train: 0.03807065594476315\n",
      "Step:141, train: 0.037255673891532476\n",
      "Step:142, train: 0.03641575388512232\n",
      "Step:143, train: 0.035550956856422206\n",
      "Step:144, train: 0.034661508113210615\n",
      "Step:145, train: 0.03374780928163276\n",
      "Step:146, train: 0.03281044944524883\n",
      "Step:147, train: 0.031850220821804345\n",
      "Step:148, train: 0.03086812794087372\n",
      "Step:149, train: 0.02986539741101077\n",
      "Step:150, train: 0.028843485114585787\n",
      "Step:151, train: 0.027804087513000023\n",
      "Step:152, train: 0.02674913574649051\n",
      "Step:153, train: 0.025680800959732422\n",
      "Step:154, train: 0.02460148932549202\n",
      "Step:155, train: 0.023513834630378316\n",
      "Step:156, train: 0.022420686152655613\n",
      "Step:157, train: 0.02132509014142288\n",
      "Step:158, train: 0.020230270099560806\n",
      "Step:159, train: 0.019139599819241924\n",
      "Step:160, train: 0.018056573351666078\n",
      "Step:161, train: 0.016984766219583326\n",
      "Step:162, train: 0.015927799808786957\n",
      "Step:163, train: 0.014889295831965915\n",
      "Step:164, train: 0.013872830207375939\n",
      "Step:165, train: 0.012881884184056346\n",
      "Step:166, train: 0.011919794668399104\n",
      "Step:167, train: 0.010989707016722713\n",
      "Step:168, train: 0.010094527387158426\n",
      "Step:169, train: 0.009236873548646565\n",
      "Step:170, train: 0.008419037029640216\n",
      "Step:171, train: 0.007642949435615204\n",
      "Step:172, train: 0.006910150658843438\n",
      "Step:173, train: 0.006221766989169658\n",
      "Step:174, train: 0.0055784988683906574\n",
      "Step:175, train: 0.00498061913854303\n",
      "Step:176, train: 0.004427972443449979\n",
      "Step:177, train: 0.0039199946290588445\n",
      "Step:178, train: 0.0034557346925335767\n",
      "Step:179, train: 0.0030338817292679394\n",
      "Step:180, train: 0.0026528083373524927\n",
      "Step:181, train: 0.002310610027452412\n",
      "Step:182, train: 0.0020051540729368895\n",
      "Step:183, train: 0.001734128682566535\n",
      "Step:184, train: 0.001495093844153914\n",
      "Step:185, train: 0.0012855320346730759\n",
      "Step:186, train: 0.0011028953023799074\n",
      "Step:187, train: 0.0009446489259406058\n",
      "Step:188, train: 0.0008083124561010641\n",
      "Step:189, train: 0.0006914929189679152\n",
      "Step:190, train: 0.0005919134644604253\n",
      "Step:191, train: 0.0005074364087188259\n",
      "Step:192, train: 0.00043607918037593166\n",
      "Step:193, train: 0.00037602539611981435\n",
      "Step:194, train: 0.0003256304317679707\n",
      "Step:195, train: 0.00028342221029157297\n",
      "Step:196, train: 0.0002480974344420021\n",
      "Step:197, train: 0.00021851602972131886\n",
      "Step:198, train: 0.00019369110505014492\n",
      "Step:199, train: 0.00017277805471611635\n",
      "Step:200, train: 0.00015506230559970448\n",
      "Step:201, train: 0.0001399459684517041\n",
      "Step:202, train: 0.0001269347175190555\n",
      "Step:203, train: 0.00011562448585834641\n",
      "Step:204, train: 0.0001056888101918115\n",
      "Step:205, train: 9.686749287976439e-05\n",
      "Step:206, train: 8.895522367461016e-05\n",
      "Step:207, train: 8.179228518704959e-05\n",
      "Step:208, train: 7.525561538747584e-05\n",
      "Step:209, train: 6.925143766159074e-05\n",
      "Step:210, train: 6.370878373367672e-05\n",
      "Step:211, train: 5.8574263439154184e-05\n",
      "Step:212, train: 5.380765973291552e-05\n",
      "Step:213, train: 4.937807102255275e-05\n",
      "Step:214, train: 4.5261437464518304e-05\n",
      "Step:215, train: 4.143822116435135e-05\n",
      "Step:216, train: 3.7891822311484456e-05\n",
      "Step:217, train: 3.46074217442999e-05\n",
      "Step:218, train: 3.1571034304245886e-05\n",
      "Step:219, train: 2.876929382193752e-05\n",
      "Step:220, train: 2.618894348788528e-05\n",
      "Step:221, train: 2.3816748209647393e-05\n",
      "Step:222, train: 2.1639573669438698e-05\n",
      "Step:223, train: 1.9644327616867266e-05\n",
      "Step:224, train: 1.7818159775746796e-05\n",
      "Step:225, train: 1.6148580388618867e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:226, train: 1.462349123755075e-05\n",
      "Step:227, train: 1.323141128532786e-05\n",
      "Step:228, train: 1.1961521418645438e-05\n",
      "Step:229, train: 1.080374296385784e-05\n",
      "Step:230, train: 9.748710606479772e-06\n",
      "Step:231, train: 8.787807076839058e-06\n",
      "Step:232, train: 7.91319808086676e-06\n",
      "Step:233, train: 7.1177611715639915e-06\n",
      "Step:234, train: 6.394992548465753e-06\n",
      "Step:235, train: 5.73899023235273e-06\n",
      "Step:236, train: 5.144417619772859e-06\n",
      "Step:237, train: 4.606350887749771e-06\n",
      "Step:238, train: 4.120287879954342e-06\n",
      "Step:239, train: 3.6820590206357447e-06\n",
      "Step:240, train: 3.2878078875088114e-06\n",
      "Step:241, train: 2.9338956819850945e-06\n",
      "Step:242, train: 2.616917961078015e-06\n",
      "Step:243, train: 2.3336218625994112e-06\n",
      "Step:244, train: 2.0809736919932702e-06\n",
      "Step:245, train: 1.856096068414186e-06\n",
      "Step:246, train: 1.6562649856615876e-06\n",
      "Step:247, train: 1.478924112885573e-06\n",
      "Step:248, train: 1.3217028737981525e-06\n",
      "Step:249, train: 1.1823871209229677e-06\n",
      "Step:250, train: 1.0589503316251479e-06\n",
      "Step:251, train: 9.495306536207732e-07\n",
      "Step:252, train: 8.524555888142451e-07\n",
      "Step:253, train: 7.662131123793425e-07\n",
      "Step:254, train: 6.894653017405114e-07\n",
      "Step:255, train: 6.210416394992575e-07\n",
      "Step:256, train: 5.599133959622809e-07\n",
      "Step:257, train: 5.051850614685639e-07\n",
      "Step:258, train: 4.5608391439749494e-07\n",
      "Step:259, train: 4.1194929153385644e-07\n",
      "Step:260, train: 3.722102494450423e-07\n",
      "Step:261, train: 3.3638150381217987e-07\n",
      "Step:262, train: 3.0405098969293273e-07\n",
      "Step:263, train: 2.748559092370722e-07\n",
      "Step:264, train: 2.4848392895265236e-07\n",
      "Step:265, train: 2.246553890770034e-07\n",
      "Step:266, train: 2.0313881918191397e-07\n",
      "Step:267, train: 1.8370327826134602e-07\n",
      "Step:268, train: 1.6615531029091263e-07\n",
      "Step:269, train: 1.5031617151199898e-07\n",
      "Step:270, train: 1.3602139437757187e-07\n",
      "Step:271, train: 1.231191186265842e-07\n",
      "Step:272, train: 1.1146639295942439e-07\n",
      "Step:273, train: 1.0093986622000817e-07\n",
      "Step:274, train: 9.142148505219423e-08\n",
      "Step:275, train: 8.28071550324655e-08\n",
      "Step:276, train: 7.500028502614902e-08\n",
      "Step:277, train: 6.79151553378304e-08\n",
      "Step:278, train: 6.147630895575426e-08\n",
      "Step:279, train: 5.562032098118583e-08\n",
      "Step:280, train: 5.028635254522178e-08\n",
      "Step:281, train: 4.5421242237633794e-08\n",
      "Step:282, train: 4.0982552875881917e-08\n",
      "Step:283, train: 3.6932672152271826e-08\n",
      "Step:284, train: 3.32382898157878e-08\n",
      "Step:285, train: 2.9868137101450685e-08\n",
      "Step:286, train: 2.6797592582169035e-08\n",
      "Step:287, train: 2.4004603382430794e-08\n",
      "Step:288, train: 2.146918446033798e-08\n",
      "Step:289, train: 1.9171255005627014e-08\n",
      "Step:290, train: 1.7094288141822465e-08\n",
      "Step:291, train: 1.522212277702423e-08\n",
      "Step:292, train: 1.3540200705056076e-08\n",
      "Step:293, train: 1.2034823946852026e-08\n",
      "Step:294, train: 1.0690616198393466e-08\n",
      "Step:295, train: 9.495177773744887e-09\n",
      "Step:296, train: 8.436883108249134e-09\n",
      "Step:297, train: 7.502531857361788e-09\n",
      "Step:298, train: 6.679570331037183e-09\n",
      "Step:299, train: 5.957250374911048e-09\n",
      "Step:300, train: 5.323970252756612e-09\n",
      "Step:301, train: 4.769801113467546e-09\n",
      "Step:302, train: 4.284929176259421e-09\n",
      "Step:303, train: 3.8613844919434535e-09\n",
      "Step:304, train: 3.489340920036859e-09\n",
      "Step:305, train: 3.163475759156916e-09\n",
      "Step:306, train: 2.8760474468424306e-09\n",
      "Step:307, train: 2.6205442680451012e-09\n",
      "Step:308, train: 2.3930834910652314e-09\n",
      "Step:309, train: 2.188554942953122e-09\n",
      "Step:310, train: 2.003630979480593e-09\n",
      "Step:311, train: 1.8352690084894892e-09\n",
      "Step:312, train: 1.6809545381837612e-09\n",
      "Step:313, train: 1.5385881284386558e-09\n",
      "Step:314, train: 1.4069423347714772e-09\n",
      "Step:315, train: 1.2849420253254624e-09\n",
      "Step:316, train: 1.1712900792105313e-09\n",
      "Step:317, train: 1.0652469171344426e-09\n",
      "Step:318, train: 9.668337908835887e-10\n",
      "Step:319, train: 8.754204362493034e-10\n",
      "Step:320, train: 7.909375841002245e-10\n",
      "Step:321, train: 7.127952310902759e-10\n",
      "Step:322, train: 6.408482014159741e-10\n",
      "Step:323, train: 5.750800839330405e-10\n",
      "Step:324, train: 5.148835668637548e-10\n",
      "Step:325, train: 4.603229073907185e-10\n",
      "Step:326, train: 4.109810300612428e-10\n",
      "Step:327, train: 3.663576989023636e-10\n",
      "Step:328, train: 3.2640308078724764e-10\n",
      "Step:329, train: 2.905514935376679e-10\n",
      "Step:330, train: 2.584545951063754e-10\n",
      "Step:331, train: 2.298077602111091e-10\n",
      "Step:332, train: 2.0443731173919039e-10\n",
      "Step:333, train: 1.8196116692155455e-10\n",
      "Step:334, train: 1.6201538218507854e-10\n",
      "Step:335, train: 1.4439909358831166e-10\n",
      "Step:336, train: 1.2874374355936885e-10\n",
      "Step:337, train: 1.1484243899667942e-10\n",
      "Step:338, train: 1.0256665480012801e-10\n",
      "Step:339, train: 9.172082632149811e-11\n",
      "Step:340, train: 8.206071258397114e-11\n",
      "Step:341, train: 7.340129613307919e-11\n",
      "Step:342, train: 6.576166072423699e-11\n",
      "Step:343, train: 5.901233868155035e-11\n",
      "Step:344, train: 5.3031144128323124e-11\n",
      "Step:345, train: 4.7726720313681616e-11\n",
      "Step:346, train: 4.297391812194711e-11\n",
      "Step:347, train: 3.874612126115975e-11\n",
      "Step:348, train: 3.495610601847985e-11\n",
      "Step:349, train: 3.155902449257522e-11\n",
      "Step:350, train: 2.8552872035182962e-11\n",
      "Step:351, train: 2.5884969698350675e-11\n",
      "Step:352, train: 2.3459656707406912e-11\n",
      "Step:353, train: 2.12946292736879e-11\n",
      "Step:354, train: 1.9324964138283486e-11\n",
      "Step:355, train: 1.7546069460506167e-11\n",
      "Step:356, train: 1.5929562252856275e-11\n",
      "Step:357, train: 1.4446993294017848e-11\n",
      "Step:358, train: 1.3103894070720063e-11\n",
      "Step:359, train: 1.1875791144646177e-11\n",
      "Step:360, train: 1.0771916017640037e-11\n",
      "Step:361, train: 9.772028683164739e-12\n",
      "Step:362, train: 8.852596471420842e-12\n",
      "Step:363, train: 8.005718163330486e-12\n",
      "Step:364, train: 7.215345682030279e-12\n",
      "Step:365, train: 6.482943821589604e-12\n",
      "Step:366, train: 5.833977847544491e-12\n",
      "Step:367, train: 5.263616914993336e-12\n",
      "Step:368, train: 4.749602636106657e-12\n",
      "Step:369, train: 4.280427820246592e-12\n",
      "Step:370, train: 3.84916447080902e-12\n",
      "Step:371, train: 3.4666978418301755e-12\n",
      "Step:372, train: 3.127887302805572e-12\n",
      "Step:373, train: 2.80798211416779e-12\n",
      "Step:374, train: 2.5298718836877106e-12\n",
      "Step:375, train: 2.2857430007339847e-12\n",
      "Step:376, train: 2.072360016491372e-12\n",
      "Step:377, train: 1.884020749804507e-12\n",
      "Step:378, train: 1.7040226972822032e-12\n",
      "Step:379, train: 1.5416451232759084e-12\n",
      "Step:380, train: 1.3980850397105143e-12\n",
      "Step:381, train: 1.2711325880211746e-12\n",
      "Step:382, train: 1.1524463414109795e-12\n",
      "Step:383, train: 1.0398483724399515e-12\n",
      "Step:384, train: 9.407759084210967e-13\n",
      "Step:385, train: 8.492993455023802e-13\n",
      "Step:386, train: 7.682134140085349e-13\n",
      "Step:387, train: 6.944953237158716e-13\n",
      "Step:388, train: 6.271681068299246e-13\n",
      "Step:389, train: 5.679654809419303e-13\n",
      "Step:390, train: 5.145929514600732e-13\n",
      "Step:391, train: 4.650402047642878e-13\n",
      "Step:392, train: 4.164896100059818e-13\n",
      "Step:393, train: 3.755412730792767e-13\n",
      "Step:394, train: 3.380327670220376e-13\n",
      "Step:395, train: 3.0293053020762864e-13\n",
      "Step:396, train: 2.7133234764962244e-13\n",
      "Step:397, train: 2.461454398936118e-13\n",
      "Step:398, train: 2.2511474222142036e-13\n",
      "Step:399, train: 2.0597840419015598e-13\n",
      "Step:400, train: 1.871727342071537e-13\n",
      "Step:401, train: 1.7025032382723792e-13\n",
      "Step:402, train: 1.5580381818442764e-13\n",
      "Step:403, train: 1.431851973417862e-13\n",
      "Step:404, train: 1.3299814354260479e-13\n",
      "Step:405, train: 1.2345841395990022e-13\n",
      "Step:406, train: 1.148466115566776e-13\n",
      "Step:407, train: 1.0768733227629435e-13\n",
      "Step:408, train: 1.0083697455040229e-13\n",
      "Step:409, train: 9.43036596297085e-14\n",
      "Step:410, train: 8.84633706490387e-14\n",
      "Step:411, train: 8.385353506083515e-14\n",
      "Step:412, train: 8.005010378642585e-14\n",
      "Step:413, train: 7.629680004815867e-14\n",
      "Step:414, train: 7.276486253628283e-14\n",
      "Step:415, train: 6.990893963307256e-14\n",
      "Step:416, train: 6.732925756994908e-14\n",
      "Step:417, train: 6.497678459953654e-14\n",
      "Step:418, train: 6.273310563218883e-14\n",
      "Step:419, train: 6.026954644032009e-14\n",
      "Step:420, train: 5.808377571458133e-14\n",
      "Step:421, train: 5.5898283672522646e-14\n",
      "Step:422, train: 5.418540188831368e-14\n",
      "Step:423, train: 5.2712254597372394e-14\n",
      "Step:424, train: 5.15370684580425e-14\n",
      "Step:425, train: 5.0544897953029953e-14\n",
      "Step:426, train: 4.9630312604248956e-14\n",
      "Step:427, train: 4.869679349078682e-14\n",
      "Step:428, train: 4.788503367295211e-14\n",
      "Step:429, train: 4.7177246532443307e-14\n",
      "Step:430, train: 4.659268297690832e-14\n",
      "Step:431, train: 4.610317092497523e-14\n",
      "Step:432, train: 4.552547118239332e-14\n",
      "Step:433, train: 4.503311722125083e-14\n",
      "Step:434, train: 4.4419701259452665e-14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:435, train: 4.404449061329921e-14\n",
      "Step:436, train: 4.370780718577636e-14\n",
      "Step:437, train: 4.330198417700801e-14\n",
      "Step:438, train: 4.307822213747963e-14\n",
      "Step:439, train: 4.2852361987733446e-14\n",
      "Step:440, train: 4.263998850660799e-14\n",
      "Step:441, train: 4.228153054315829e-14\n",
      "Step:442, train: 4.2119132757353453e-14\n",
      "Step:443, train: 4.1853902524210704e-14\n",
      "Step:444, train: 4.167607990204376e-14\n",
      "Step:445, train: 4.1535444206655675e-14\n",
      "Step:446, train: 4.1430785597016936e-14\n",
      "Step:447, train: 4.127099983103963e-14\n",
      "Step:448, train: 4.094362687415259e-14\n",
      "Step:449, train: 4.07142574341104e-14\n",
      "Step:450, train: 4.058798719821503e-14\n",
      "Step:451, train: 4.0498389449077426e-14\n",
      "Step:452, train: 4.020309742985942e-14\n",
      "Step:453, train: 4.0085752513088345e-14\n",
      "Step:454, train: 3.9994026892607735e-14\n",
      "Step:455, train: 3.988810809613928e-14\n",
      "Step:456, train: 3.9842575724648884e-14\n",
      "Step:457, train: 3.9815820688030777e-14\n",
      "Step:458, train: 3.978867499812325e-14\n",
      "Step:459, train: 3.976270754059006e-14\n",
      "Step:460, train: 3.9738037895909175e-14\n",
      "Step:461, train: 3.959597111124243e-14\n",
      "Step:462, train: 3.9563118253823914e-14\n",
      "Step:463, train: 3.951023090848485e-14\n",
      "Step:464, train: 3.9472816140848e-14\n",
      "Step:465, train: 3.9422474268453525e-14\n",
      "Step:466, train: 3.940396213101881e-14\n",
      "Step:467, train: 3.938893659418168e-14\n",
      "Step:468, train: 3.937352290157519e-14\n",
      "Step:469, train: 3.928917472407109e-14\n",
      "Step:470, train: 3.9259204047462415e-14\n",
      "Step:471, train: 3.9222242863363475e-14\n",
      "Step:472, train: 3.920881544543379e-14\n",
      "Step:473, train: 3.90869371863311e-14\n",
      "Step:474, train: 3.9046568439932096e-14\n",
      "Step:475, train: 3.896532965385739e-14\n",
      "Step:476, train: 3.895956839224544e-14\n",
      "Step:477, train: 3.889723040555494e-14\n",
      "Step:478, train: 3.887788273142116e-14\n",
      "Step:479, train: 3.887122872539186e-14\n",
      "Step:480, train: 3.8865105990924786e-14\n",
      "Step:481, train: 3.8860547128531727e-14\n",
      "Step:482, train: 3.88432403960445e-14\n",
      "Step:483, train: 3.881587705791276e-14\n",
      "Step:484, train: 3.8811401328371626e-14\n",
      "Step:485, train: 3.880734759919439e-14\n",
      "Step:486, train: 3.87293439379435e-14\n",
      "Step:487, train: 3.872570571364568e-14\n",
      "Step:488, train: 3.872220066307353e-14\n",
      "Step:489, train: 3.8718958083140597e-14\n",
      "Step:490, train: 3.8715890673350445e-14\n",
      "Step:491, train: 3.8669929235409405e-14\n",
      "Step:492, train: 3.8652515638075185e-14\n",
      "Step:493, train: 3.864996386535707e-14\n",
      "Step:494, train: 3.8634342787341334e-14\n",
      "Step:495, train: 3.863224952869299e-14\n",
      "Step:496, train: 3.8628262904025894e-14\n",
      "Step:497, train: 3.862258855795639e-14\n",
      "Step:498, train: 3.8620698184240633e-14\n",
      "Step:499, train: 3.861853396687991e-14\n",
      "Step:500, train: 3.857375006968468e-14\n",
      "Step:501, train: 3.8565009218939234e-14\n",
      "Step:502, train: 3.8563424570362746e-14\n",
      "Step:503, train: 3.856191203449186e-14\n",
      "Step:504, train: 3.8560541920364724e-14\n",
      "Step:505, train: 3.854996526269294e-14\n",
      "Step:506, train: 3.85484642573799e-14\n",
      "Step:507, train: 3.851048375849677e-14\n",
      "Step:508, train: 3.8509146724583263e-14\n",
      "Step:509, train: 3.850734408717015e-14\n",
      "Step:510, train: 3.849342794278958e-14\n",
      "Step:511, train: 3.849226616321328e-14\n",
      "Step:512, train: 3.849166638712826e-14\n",
      "Step:513, train: 3.8444720746879173e-14\n",
      "Step:514, train: 3.844412425709604e-14\n",
      "Step:515, train: 3.844351932531946e-14\n",
      "Step:516, train: 3.8410112704449976e-14\n",
      "Step:517, train: 3.840951949345018e-14\n",
      "Step:518, train: 3.839807196642954e-14\n",
      "Step:519, train: 3.8193931728626615e-14\n",
      "Step:520, train: 3.774578049546787e-14\n",
      "Step:521, train: 3.7749452600114935e-14\n",
      "Step:522, train: 3.7746258776546877e-14\n",
      "Step:523, train: 3.759320619299137e-14\n",
      "Step:524, train: 3.755008211279782e-14\n",
      "Step:525, train: 3.752932366304147e-14\n",
      "Step:526, train: 3.75274877660268e-14\n",
      "Step:527, train: 3.751200974799709e-14\n",
      "Step:528, train: 3.749149756368841e-14\n",
      "Step:529, train: 3.747597357832243e-14\n",
      "Step:530, train: 3.7474819230012794e-14\n",
      "Step:531, train: 3.74737975834576e-14\n",
      "Step:532, train: 3.747105300008104e-14\n",
      "Step:533, train: 3.7473933088065777e-14\n",
      "Step:534, train: 3.747328385638663e-14\n",
      "Step:535, train: 3.747262536783306e-14\n",
      "Step:536, train: 3.747209980731559e-14\n",
      "Step:537, train: 3.745515959533286e-14\n",
      "Step:538, train: 3.7477524008130233e-14\n",
      "Step:539, train: 3.7466177244170106e-14\n",
      "Step:540, train: 3.7442021565747904e-14\n",
      "Step:541, train: 3.7377655684296244e-14\n",
      "Step:542, train: 3.737668346958163e-14\n",
      "Step:543, train: 3.7375617716022167e-14\n",
      "Step:544, train: 3.735826263410816e-14\n",
      "Step:545, train: 3.7352993919731456e-14\n",
      "Step:546, train: 3.735217605488518e-14\n",
      "Step:547, train: 3.735116772807587e-14\n",
      "Step:548, train: 3.734121780479923e-14\n",
      "Step:549, train: 3.734055757350691e-14\n",
      "Step:550, train: 3.733967711896243e-14\n",
      "Step:551, train: 3.730350026917066e-14\n",
      "Step:552, train: 3.7283042950056163e-14\n",
      "Step:553, train: 3.728197909240446e-14\n",
      "Step:554, train: 3.728070644458885e-14\n",
      "Step:555, train: 3.727936350654097e-14\n",
      "Step:556, train: 3.642447868463284e-14\n",
      "Step:557, train: 3.6423394124438496e-14\n",
      "Step:558, train: 3.6419716796466047e-14\n",
      "Step:559, train: 3.6417885799457383e-14\n",
      "Step:560, train: 3.63494229222981e-14\n",
      "Step:561, train: 3.617669021087787e-14\n",
      "Step:562, train: 3.6111008043306765e-14\n",
      "Step:563, train: 3.608005306132687e-14\n",
      "Step:564, train: 3.6054435144690543e-14\n",
      "Step:565, train: 3.603177382215726e-14\n",
      "Step:566, train: 3.602609227765276e-14\n",
      "Step:567, train: 3.602368492496579e-14\n",
      "Step:568, train: 3.6020035681648455e-14\n",
      "Step:569, train: 3.597215243884398e-14\n",
      "Step:570, train: 3.597002171008977e-14\n",
      "Step:571, train: 3.596814050783244e-14\n",
      "Step:572, train: 3.579309086939688e-14\n",
      "Step:573, train: 3.559713180024774e-14\n",
      "Step:574, train: 3.559485697058644e-14\n",
      "Step:575, train: 3.5593777142130115e-14\n",
      "Step:576, train: 3.555929462150922e-14\n",
      "Step:577, train: 3.5555213846240854e-14\n",
      "Step:578, train: 3.555350078399696e-14\n",
      "Step:579, train: 3.555207031582859e-14\n",
      "Step:580, train: 3.5550571141393487e-14\n",
      "Step:581, train: 3.554982528894817e-14\n",
      "Step:582, train: 3.5549133143686794e-14\n",
      "Step:583, train: 3.554283182969289e-14\n",
      "Step:584, train: 3.5511652679008084e-14\n",
      "Step:585, train: 3.550371664906968e-14\n",
      "Step:586, train: 3.549949640072951e-14\n",
      "Step:587, train: 3.5496709187372753e-14\n",
      "Step:588, train: 3.54960278827566e-14\n",
      "Step:589, train: 3.545547942079956e-14\n",
      "Step:590, train: 3.54550427045172e-14\n",
      "Step:591, train: 3.5454690461097155e-14\n",
      "Step:592, train: 3.540270190181259e-14\n",
      "Step:593, train: 3.540217758077834e-14\n",
      "Step:594, train: 3.540177993906885e-14\n",
      "Step:595, train: 3.537137934587175e-14\n",
      "Step:596, train: 3.532739075575292e-14\n",
      "Step:597, train: 3.532701671802226e-14\n",
      "Step:598, train: 3.532665625301312e-14\n",
      "Step:599, train: 3.5326307943139835e-14\n",
      "Step:600, train: 3.532597336452679e-14\n",
      "Step:601, train: 3.532520879637527e-14\n",
      "Step:602, train: 3.532499362278394e-14\n",
      "Step:603, train: 3.532430408775343e-14\n",
      "Step:604, train: 3.5323851888440675e-14\n",
      "Step:605, train: 3.532343106541441e-14\n",
      "Step:606, train: 3.5103511225328906e-14\n",
      "Step:607, train: 3.510269615053824e-14\n",
      "Step:608, train: 3.5081604453560824e-14\n",
      "Step:609, train: 3.5081268724381724e-14\n",
      "Step:610, train: 3.5068484612231614e-14\n",
      "Step:611, train: 3.503003968939072e-14\n",
      "Step:612, train: 3.502927787510499e-14\n",
      "Step:613, train: 3.5028640018321524e-14\n",
      "Step:614, train: 3.50281269940877e-14\n",
      "Step:615, train: 3.500424592467008e-14\n",
      "Step:616, train: 3.5002147172004444e-14\n",
      "Step:617, train: 3.493722326739083e-14\n",
      "Step:618, train: 3.493630370974134e-14\n",
      "Step:619, train: 3.4918839075701887e-14\n",
      "Step:620, train: 3.489479195865355e-14\n",
      "Step:621, train: 3.4889142955970486e-14\n",
      "Step:622, train: 3.487764746123657e-14\n",
      "Step:623, train: 3.487713724716773e-14\n",
      "Step:624, train: 3.4784613717105234e-14\n",
      "Step:625, train: 3.4779716538449896e-14\n",
      "Step:626, train: 3.4771035853153047e-14\n",
      "Step:627, train: 3.470065777487057e-14\n",
      "Step:628, train: 3.4700004058707955e-14\n",
      "Step:629, train: 3.469952736453573e-14\n",
      "Step:630, train: 3.469890863316058e-14\n",
      "Step:631, train: 3.468265315536626e-14\n",
      "Step:632, train: 3.4680085041219106e-14\n",
      "Step:633, train: 3.467190130984107e-14\n",
      "Step:634, train: 3.4668845557252806e-14\n",
      "Step:635, train: 3.466680030104642e-14\n",
      "Step:636, train: 3.4666631921572344e-14\n",
      "Step:637, train: 3.4665070935046483e-14\n",
      "Step:638, train: 3.466053141375489e-14\n",
      "Step:639, train: 3.4617954990795777e-14\n",
      "Step:640, train: 3.4602609677100106e-14\n",
      "Step:641, train: 3.4606274596779787e-14\n",
      "Step:642, train: 3.4606118987882656e-14\n",
      "Step:643, train: 3.4605970306986796e-14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:644, train: 3.4605947683676774e-14\n",
      "Step:645, train: 3.460180587398605e-14\n",
      "Step:646, train: 3.460177500757536e-14\n",
      "Step:647, train: 3.460174559531762e-14\n",
      "Step:648, train: 3.46017176492458e-14\n",
      "Step:649, train: 3.4601691084048135e-14\n",
      "Step:650, train: 3.458588683155459e-14\n",
      "Step:651, train: 3.458355697273842e-14\n",
      "Step:652, train: 3.443804304715714e-14\n",
      "Step:653, train: 3.439863599015339e-14\n",
      "Step:654, train: 3.437208136865816e-14\n",
      "Step:655, train: 3.4363647444484975e-14\n",
      "Step:656, train: 3.435070263628201e-14\n",
      "Step:657, train: 3.434691382089991e-14\n",
      "Step:658, train: 3.430316675163644e-14\n",
      "Step:659, train: 3.4249807011875565e-14\n",
      "Step:660, train: 3.423800500978417e-14\n",
      "Step:661, train: 3.423748019273719e-14\n",
      "Step:662, train: 3.4185260425570136e-14\n",
      "Step:663, train: 3.41752549388044e-14\n",
      "Step:664, train: 3.406729656920606e-14\n",
      "Step:665, train: 3.406076482778783e-14\n",
      "Step:666, train: 3.405410708851522e-14\n",
      "Step:667, train: 3.4031359942700125e-14\n",
      "Step:668, train: 3.4007667439445174e-14\n",
      "Step:669, train: 3.4001307020561917e-14\n",
      "Step:670, train: 3.3973947232707235e-14\n",
      "Step:671, train: 3.397383463723557e-14\n",
      "Step:672, train: 3.396670685481887e-14\n",
      "Step:673, train: 3.3959328820734984e-14\n",
      "Step:674, train: 3.394515326164423e-14\n",
      "Step:675, train: 3.3924247026342496e-14\n",
      "Step:676, train: 3.3916884659291096e-14\n",
      "Step:677, train: 3.390465679500595e-14\n",
      "Step:678, train: 3.3886700383764424e-14\n",
      "Step:679, train: 3.3884680877269916e-14\n",
      "Step:680, train: 3.3882900629272115e-14\n",
      "Step:681, train: 3.3821681385910725e-14\n",
      "Step:682, train: 3.3821361074114355e-14\n",
      "Step:683, train: 3.380126317710913e-14\n",
      "Step:684, train: 3.377150742001393e-14\n",
      "Step:685, train: 3.3761268716045704e-14\n",
      "Step:686, train: 3.3747402283135857e-14\n",
      "Step:687, train: 3.362123460569025e-14\n",
      "Step:688, train: 3.361540413179299e-14\n",
      "Step:689, train: 3.3401717920060813e-14\n",
      "Step:690, train: 3.338413519122187e-14\n",
      "Step:691, train: 3.3382658117051314e-14\n",
      "Step:692, train: 3.337937704085418e-14\n",
      "Step:693, train: 3.335086354655738e-14\n",
      "Step:694, train: 3.335040249893753e-14\n",
      "Step:695, train: 3.335828988565671e-14\n",
      "Step:696, train: 3.335723322088486e-14\n",
      "Step:697, train: 3.335370077248218e-14\n",
      "Step:698, train: 3.333693729120693e-14\n",
      "Step:699, train: 3.335266691639175e-14\n",
      "Step:700, train: 3.3349537303419437e-14\n",
      "Step:701, train: 3.3327761580953396e-14\n",
      "Step:702, train: 3.3319634058142905e-14\n",
      "Step:703, train: 3.330927476288965e-14\n",
      "Step:704, train: 3.3299124123569e-14\n",
      "Step:705, train: 3.328879401980327e-14\n",
      "Step:706, train: 3.329257527906403e-14\n",
      "Step:707, train: 3.3292397609814496e-14\n",
      "Step:708, train: 3.3091133028592717e-14\n",
      "Step:709, train: 3.309974298582241e-14\n",
      "Step:710, train: 3.3098635181323837e-14\n",
      "Step:711, train: 3.3098379392816835e-14\n",
      "Step:712, train: 3.304774939301236e-14\n",
      "Step:713, train: 3.304401370380351e-14\n",
      "Step:714, train: 3.302850069210188e-14\n",
      "Step:715, train: 3.2998424358077626e-14\n",
      "Step:716, train: 3.3010651096897854e-14\n",
      "Step:717, train: 3.297188408932714e-14\n",
      "Step:718, train: 3.296521122409835e-14\n",
      "Step:719, train: 3.295331111065082e-14\n",
      "Step:720, train: 3.2963346706718336e-14\n",
      "Step:721, train: 3.2949808163005154e-14\n",
      "Step:722, train: 3.276095608186505e-14\n",
      "Step:723, train: 3.2744596704876647e-14\n",
      "Step:724, train: 3.275854555953025e-14\n",
      "Step:725, train: 3.2758164283621856e-14\n",
      "Step:726, train: 3.275220643514617e-14\n",
      "Step:727, train: 3.2737829575239285e-14\n",
      "Step:728, train: 3.275378682609255e-14\n",
      "Step:729, train: 3.2753791331759333e-14\n",
      "Step:730, train: 3.2714643322342504e-14\n",
      "Step:731, train: 3.2721864708252943e-14\n",
      "Step:732, train: 3.2672588935554667e-14\n",
      "Step:733, train: 3.2660156185316396e-14\n",
      "Step:734, train: 3.253586416391627e-14\n",
      "Step:735, train: 3.2201606629024956e-14\n",
      "Step:736, train: 3.208961908368617e-14\n",
      "Step:737, train: 3.2072438950082086e-14\n",
      "Step:738, train: 3.1960417891491524e-14\n",
      "Step:739, train: 3.154315143738454e-14\n",
      "Step:740, train: 3.148717066040555e-14\n",
      "Step:741, train: 3.136428262032741e-14\n",
      "Step:742, train: 3.1328260482735184e-14\n",
      "Step:743, train: 3.131564887621123e-14\n",
      "Step:744, train: 3.128494812765343e-14\n",
      "Step:745, train: 3.125926263756173e-14\n",
      "Step:746, train: 3.124195909208265e-14\n",
      "Step:747, train: 3.1227151583886486e-14\n",
      "Step:748, train: 3.1201604749800284e-14\n",
      "Step:749, train: 3.121076179729081e-14\n",
      "Step:750, train: 3.120445735217599e-14\n",
      "Step:751, train: 3.1196040105378844e-14\n",
      "Step:752, train: 3.1185853843643174e-14\n",
      "Step:753, train: 3.1195693867154133e-14\n",
      "Step:754, train: 3.117694266092467e-14\n",
      "Step:755, train: 3.115475930590954e-14\n",
      "Step:756, train: 3.1163093105035884e-14\n",
      "Step:757, train: 3.1162433380992025e-14\n",
      "Step:758, train: 3.105270792658667e-14\n",
      "Step:759, train: 3.103618082225829e-14\n",
      "Step:760, train: 3.103836434987176e-14\n",
      "Step:761, train: 3.102387768328321e-14\n",
      "Step:762, train: 3.098844825888071e-14\n",
      "Step:763, train: 3.099682226349315e-14\n",
      "Step:764, train: 3.09965184159513e-14\n",
      "Step:765, train: 3.098375116242758e-14\n",
      "Step:766, train: 3.0981923338759124e-14\n",
      "Step:767, train: 3.098229072704212e-14\n",
      "Step:768, train: 3.098218197574284e-14\n",
      "Step:769, train: 3.098209969262241e-14\n",
      "Step:770, train: 3.095128670533102e-14\n",
      "Step:771, train: 3.095122219794902e-14\n",
      "Step:772, train: 3.095116570796407e-14\n",
      "Step:773, train: 3.095087240973481e-14\n",
      "Step:774, train: 3.095083167850404e-14\n",
      "Step:775, train: 3.0950794795203586e-14\n",
      "Step:776, train: 3.095040552812829e-14\n",
      "Step:777, train: 3.0915261525681064e-14\n",
      "Step:778, train: 3.090525240518189e-14\n",
      "Step:779, train: 3.079215754915334e-14\n",
      "Step:780, train: 3.079188382549618e-14\n",
      "Step:781, train: 3.079168142771283e-14\n",
      "Step:782, train: 3.0786597946091664e-14\n",
      "Step:783, train: 3.074510835049026e-14\n",
      "Step:784, train: 3.073944332304103e-14\n",
      "Step:785, train: 3.0625184014211386e-14\n",
      "Step:786, train: 3.0607191821091505e-14\n",
      "Step:787, train: 3.0602228817404594e-14\n",
      "Step:788, train: 3.054009482806045e-14\n",
      "Step:789, train: 3.051764879479006e-14\n",
      "Step:790, train: 3.0492390056486256e-14\n",
      "Step:791, train: 3.049090023939121e-14\n",
      "Step:792, train: 3.0464933929489995e-14\n",
      "Step:793, train: 3.046427983009762e-14\n",
      "Step:794, train: 3.040407095406987e-14\n",
      "Step:795, train: 3.039968732272275e-14\n",
      "Step:796, train: 3.039904211065169e-14\n",
      "Step:797, train: 3.0394983712866674e-14\n",
      "Step:798, train: 3.0394697196557844e-14\n",
      "Step:799, train: 3.0394374179196714e-14\n",
      "Step:800, train: 3.007636977442676e-14\n",
      "Step:801, train: 3.0075891968892076e-14\n",
      "Step:802, train: 3.0021611673176645e-14\n",
      "Step:803, train: 2.998238877329113e-14\n",
      "Step:804, train: 2.9977802505439187e-14\n",
      "Step:805, train: 2.997053114103966e-14\n",
      "Step:806, train: 2.9867630251974505e-14\n",
      "Step:807, train: 2.986443637307716e-14\n",
      "Step:808, train: 2.984611674659501e-14\n",
      "Step:809, train: 2.9677361805468795e-14\n",
      "Step:810, train: 2.96508679033955e-14\n",
      "Step:811, train: 2.964911411083531e-14\n",
      "Step:812, train: 2.9553291301631915e-14\n",
      "Step:813, train: 2.9545453171762934e-14\n",
      "Step:814, train: 2.9465328942332477e-14\n",
      "Step:815, train: 2.944955627167329e-14\n",
      "Step:816, train: 2.944717827203981e-14\n",
      "Step:817, train: 2.942650002000495e-14\n",
      "Step:818, train: 2.935715869112292e-14\n",
      "Step:819, train: 2.932571189756237e-14\n",
      "Step:820, train: 2.928599512102937e-14\n",
      "Step:821, train: 2.928536786886569e-14\n",
      "Step:822, train: 2.9187257583456496e-14\n",
      "Step:823, train: 2.918150386627065e-14\n",
      "Step:824, train: 2.9160330913082955e-14\n",
      "Step:825, train: 2.915957745215978e-14\n",
      "Step:826, train: 2.9167608592819963e-14\n",
      "Step:827, train: 2.914419858702002e-14\n",
      "Step:828, train: 2.9134223945709565e-14\n",
      "Step:829, train: 2.905118451493903e-14\n",
      "Step:830, train: 2.905063677714308e-14\n",
      "Step:831, train: 2.9026800091769274e-14\n",
      "Step:832, train: 2.900792585600634e-14\n",
      "Step:833, train: 2.8988379306453396e-14\n",
      "Step:834, train: 2.8987953451228325e-14\n",
      "Step:835, train: 2.896544264788566e-14\n",
      "Step:836, train: 2.8965179485218913e-14\n",
      "Step:837, train: 2.8807268258396254e-14\n",
      "Step:838, train: 2.8807013554766666e-14\n",
      "Step:839, train: 2.88158498263339e-14\n",
      "Step:840, train: 2.88149919931198e-14\n",
      "Step:841, train: 2.880553127670396e-14\n",
      "Step:842, train: 2.869956234455647e-14\n",
      "Step:843, train: 2.866435255767611e-14\n",
      "Step:844, train: 2.862635281935905e-14\n",
      "Step:845, train: 2.862044608746877e-14\n",
      "Step:846, train: 2.8619703507901895e-14\n",
      "Step:847, train: 2.8619034890883736e-14\n",
      "Step:848, train: 2.861830586696527e-14\n",
      "Step:849, train: 2.845420000856926e-14\n",
      "Step:850, train: 2.8400941916547337e-14\n",
      "Step:851, train: 2.839505086415121e-14\n",
      "Step:852, train: 2.8399478909428958e-14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:853, train: 2.837928512098548e-14\n",
      "Step:854, train: 2.836428487076263e-14\n",
      "Step:855, train: 2.833268472370422e-14\n",
      "Step:856, train: 2.835286015491174e-14\n",
      "Step:857, train: 2.8350372029218395e-14\n",
      "Step:858, train: 2.8320519282155415e-14\n",
      "Step:859, train: 2.8323289568631748e-14\n",
      "Step:860, train: 2.8314808501733453e-14\n",
      "Step:861, train: 2.8314160798756708e-14\n",
      "Step:862, train: 2.823271306287413e-14\n",
      "Step:863, train: 2.8237108804233565e-14\n",
      "Step:864, train: 2.823427997857998e-14\n",
      "Step:865, train: 2.821198686422611e-14\n",
      "Step:866, train: 2.8219833864279217e-14\n",
      "Step:867, train: 2.8031918036123178e-14\n",
      "Step:868, train: 2.79906715547277e-14\n",
      "Step:869, train: 2.7986895189994624e-14\n",
      "Step:870, train: 2.7967636263591333e-14\n",
      "Step:871, train: 2.7757702635571868e-14\n",
      "Step:872, train: 2.7715322972822433e-14\n",
      "Step:873, train: 2.7684589685444398e-14\n",
      "Step:874, train: 2.7675767778668845e-14\n",
      "Step:875, train: 2.7682177819325187e-14\n",
      "Step:876, train: 2.7679788886550002e-14\n",
      "Step:877, train: 2.7622518081242593e-14\n",
      "Step:878, train: 2.764163454130784e-14\n",
      "Step:879, train: 2.768631751294722e-14\n",
      "Step:880, train: 2.7623027806127844e-14\n",
      "Step:881, train: 2.7586946245738575e-14\n",
      "Step:882, train: 2.762028085652094e-14\n",
      "Step:883, train: 2.7599239984487632e-14\n",
      "Step:884, train: 2.7561157544447855e-14\n",
      "Step:885, train: 2.723516655339368e-14\n",
      "Step:886, train: 2.7242103381878962e-14\n",
      "Step:887, train: 2.7195466928805697e-14\n",
      "Step:888, train: 2.7097082108433713e-14\n",
      "Step:889, train: 2.710458581229263e-14\n",
      "Step:890, train: 2.7083872527882992e-14\n",
      "Step:891, train: 2.702315021216415e-14\n",
      "Step:892, train: 2.7022141552375723e-14\n",
      "Step:893, train: 2.7021675567274354e-14\n",
      "Step:894, train: 2.7000047735391698e-14\n",
      "Step:895, train: 2.6966074010866393e-14\n",
      "Step:896, train: 2.668039379783804e-14\n",
      "Step:897, train: 2.6676924601059924e-14\n",
      "Step:898, train: 2.6669747053479875e-14\n",
      "Step:899, train: 2.6653631414806577e-14\n",
      "Step:900, train: 2.6650053576998862e-14\n",
      "Step:901, train: 2.6644159704595323e-14\n",
      "Step:902, train: 2.6639879777075832e-14\n",
      "Step:903, train: 2.6637028342963586e-14\n",
      "Step:904, train: 2.663662743430598e-14\n",
      "Step:905, train: 2.6646253108798918e-14\n",
      "Step:906, train: 2.6594404355952625e-14\n",
      "Step:907, train: 2.6093353206111442e-14\n",
      "Step:908, train: 2.5985406355749484e-14\n",
      "Step:909, train: 2.587574411980131e-14\n",
      "Step:910, train: 2.587478459620671e-14\n",
      "Step:911, train: 2.5874375933447954e-14\n",
      "Step:912, train: 2.5868434063674674e-14\n",
      "Step:913, train: 2.587239063266659e-14\n",
      "Step:914, train: 2.5852961326237913e-14\n",
      "Step:915, train: 2.5853271541377477e-14\n",
      "Step:916, train: 2.581853657449104e-14\n",
      "Step:917, train: 2.5742059541507694e-14\n",
      "Step:918, train: 2.57408366612128e-14\n",
      "Step:919, train: 2.5741022133876854e-14\n",
      "Step:920, train: 2.565537486062387e-14\n",
      "Step:921, train: 2.554324579231168e-14\n",
      "Step:922, train: 2.554376139615052e-14\n",
      "Step:923, train: 2.5542097016837585e-14\n",
      "Step:924, train: 2.552204936535748e-14\n",
      "Step:925, train: 2.5500443432994203e-14\n",
      "Step:926, train: 2.5495981068559222e-14\n",
      "Step:927, train: 2.5468617456243612e-14\n",
      "Step:928, train: 2.54662810896951e-14\n",
      "Step:929, train: 2.5465512760232475e-14\n",
      "Step:930, train: 2.5393324046628067e-14\n",
      "Step:931, train: 2.526656348759072e-14\n",
      "Step:932, train: 2.5265519783932987e-14\n",
      "Step:933, train: 2.5255757398379047e-14\n",
      "Step:934, train: 2.525453989984689e-14\n",
      "Step:935, train: 2.5231743526485483e-14\n",
      "Step:936, train: 2.522343321806493e-14\n",
      "Step:937, train: 2.5222887832250855e-14\n",
      "Step:938, train: 2.5151056014485198e-14\n",
      "Step:939, train: 2.5129229633929112e-14\n",
      "Step:940, train: 2.479050169065898e-14\n",
      "Step:941, train: 2.4773479508023974e-14\n",
      "Step:942, train: 2.477256986589375e-14\n",
      "Step:943, train: 2.4771930085208477e-14\n",
      "Step:944, train: 2.4771395729206243e-14\n",
      "Step:945, train: 2.4757972721028894e-14\n",
      "Step:946, train: 2.4751171050139027e-14\n",
      "Step:947, train: 2.475086198307348e-14\n",
      "Step:948, train: 2.465823866227659e-14\n",
      "Step:949, train: 2.461978579181541e-14\n",
      "Step:950, train: 2.461619657046695e-14\n",
      "Step:951, train: 2.4608546896992548e-14\n",
      "Step:952, train: 2.4606810468860977e-14\n",
      "Step:953, train: 2.4606641378770186e-14\n",
      "Step:954, train: 2.4606617589549245e-14\n",
      "Step:955, train: 2.4602497512897285e-14\n",
      "Step:956, train: 2.460313837288745e-14\n",
      "Step:957, train: 2.453529871324555e-14\n",
      "Step:958, train: 2.453499199333655e-14\n",
      "Step:959, train: 2.4534723943906864e-14\n",
      "Step:960, train: 2.4525121881996265e-14\n",
      "Step:961, train: 2.452473871591676e-14\n",
      "Step:962, train: 2.4524361462737028e-14\n",
      "Step:963, train: 2.452198912993845e-14\n",
      "Step:964, train: 2.4499738866583148e-14\n",
      "Step:965, train: 2.4497827656995405e-14\n",
      "Step:966, train: 2.43643783981857e-14\n",
      "Step:967, train: 2.433746942326024e-14\n",
      "Step:968, train: 2.4294048813093295e-14\n",
      "Step:969, train: 2.427832745903128e-14\n",
      "Step:970, train: 2.4266561736950107e-14\n",
      "Step:971, train: 2.4257426097348602e-14\n",
      "Step:972, train: 2.4244111837459468e-14\n",
      "Step:973, train: 2.4244025324774846e-14\n",
      "Step:974, train: 2.424372940478069e-14\n",
      "Step:975, train: 2.4243704956557274e-14\n",
      "Step:976, train: 2.424371057949334e-14\n",
      "Step:977, train: 2.4240253243836506e-14\n",
      "Step:978, train: 2.4219606906248657e-14\n",
      "Step:979, train: 2.4204076344349105e-14\n",
      "Step:980, train: 2.419864596764289e-14\n",
      "Step:981, train: 2.419862693583936e-14\n",
      "Step:982, train: 2.4188989104048625e-14\n",
      "Step:983, train: 2.420623979411483e-14\n",
      "Step:984, train: 2.4196181554959497e-14\n",
      "Step:985, train: 2.4158667843388247e-14\n",
      "Step:986, train: 2.407029616518964e-14\n",
      "Step:987, train: 2.406998057230097e-14\n",
      "Step:988, train: 2.404093810581857e-14\n",
      "Step:989, train: 2.401425191722645e-14\n",
      "Step:990, train: 2.4020844140435247e-14\n",
      "Step:991, train: 2.4019168302992884e-14\n",
      "Step:992, train: 2.3676485816059884e-14\n",
      "Step:993, train: 2.3691361656923978e-14\n",
      "Step:994, train: 2.3680227349312386e-14\n",
      "Step:995, train: 2.3610913485350666e-14\n",
      "Step:996, train: 2.3616606056324558e-14\n",
      "Step:997, train: 2.3610364463790985e-14\n",
      "Step:998, train: 2.3593554676780584e-14\n",
      "Step:999, train: 2.3606682494007125e-14\n",
      "2.3606682494007125e-14\n"
     ]
    }
   ],
   "source": [
    "model.train(inputs = [],\n",
    "            targets = [channel_target],\n",
    "            num_iter = 1000,\n",
    "            N = 0,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_qiskit",
   "language": "python",
   "name": "env_qiskit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

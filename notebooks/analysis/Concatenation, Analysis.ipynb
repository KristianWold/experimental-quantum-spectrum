{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenation, Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../src_tf/')\n",
    "\n",
    "import numpy as np\n",
    "import qiskit as qk\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from qiskit.quantum_info import DensityMatrix, random_unitary\n",
    "from qiskit.quantum_info import Operator\n",
    "from scipy.linalg import sqrtm\n",
    "from tqdm.notebook import tqdm\n",
    "from math import ceil\n",
    "\n",
    "from loss_functions import *\n",
    "from optimization import *\n",
    "from quantum_channel import *\n",
    "from kraus_channels import *\n",
    "from quantum_tools import *\n",
    "from experimental import *\n",
    "from spam import *\n",
    "from scipy.stats import gaussian_kde\n",
    "from quantum_circuits import *\n",
    "\n",
    "#np.set_printoptions(threshold=sys.maxsize)\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_channel(channel, inputs, targets):\n",
    "    d = channel.d\n",
    "    kl_div = KLDiv()\n",
    "    loss = kl_div(channel, inputs, targets)\n",
    "    return np.real(loss)/d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL Divergence with Respect to Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = loader(data_path(\"belem_concatenate_2layer_fitted.model\"))\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "n=3\n",
    "d = 2**n\n",
    "\n",
    "R1_fid_list = []\n",
    "R2_fid_list = []\n",
    "R3_fid_list = []\n",
    "\n",
    "U1_fid_list = []\n",
    "U2_fid_list = []\n",
    "U3_fid_list = []\n",
    "\n",
    "T1_fid_list = []\n",
    "T2_fid_list = []\n",
    "T12_fid_list = []\n",
    "T3_fid_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    inputs1, targets1, _, _ = loader(data_path(f\"belem_concatenate_2layer{i}0\"))\n",
    "    inputs2, targets2, _, _ = loader(data_path(f\"belem_concatenate_2layer{i}1\"))\n",
    "    inputs_full, targets_full, _, _ = loader(data_path(f\"belem_concatenate_2layer{i}2\"))\n",
    "    \n",
    "    model1 = model_list[3*i]\n",
    "    model2 = model_list[3*i+1]\n",
    "    model_full = model_list[3*i+2]\n",
    "    \n",
    "    channel1 = model1.channel\n",
    "    channel2 = model2.channel\n",
    "    channel_full = model_full.channel\n",
    "\n",
    "    channel_concat = channel_to_choi_map([channel1, channel2])\n",
    "    channel_concat.spam = channel_full.spam\n",
    "    \n",
    "    identity_channel1 = IdentityChannel(d)\n",
    "    identity_channel1.spam = channel1.spam\n",
    "\n",
    "    identity_channel2 = IdentityChannel(d)\n",
    "    identity_channel2.spam = channel2.spam\n",
    "\n",
    "    identity_channel_full = IdentityChannel(d)\n",
    "    identity_channel_full.spam = channel_full.spam\n",
    "    \n",
    "    circuit1 = pqc_basic(n, 2)#.reverse_bits()\n",
    "    U1 = circuit_to_matrix(circuit1)\n",
    "\n",
    "    circuit2 = pqc_basic(n, 2)#.reverse_bits()\n",
    "    U2 = circuit_to_matrix(circuit2)\n",
    "\n",
    "    circuit_full = deepcopy(circuit1)\n",
    "    circuit_full = circuit_full.compose(circuit2)\n",
    "    U_full = circuit_to_matrix(circuit_full)\n",
    "\n",
    "    U_channel1 = ChoiMapStatic(U1, mode=\"unitary\")\n",
    "    U_channel1.spam = channel1.spam\n",
    "\n",
    "    U_channel2 = ChoiMapStatic(U2, mode=\"unitary\")\n",
    "    U_channel2.spam = channel2.spam\n",
    "\n",
    "    U_channel_full = ChoiMapStatic(U_full, mode=\"unitary\")\n",
    "    U_channel_full.spam = channel_full.spam\n",
    "    \n",
    "    R1_fid_list.append(evaluate_channel(identity_channel1, inputs1, targets1))\n",
    "    R2_fid_list.append(evaluate_channel(identity_channel2, inputs2, targets2))\n",
    "    R3_fid_list.append(evaluate_channel(identity_channel_full, inputs_full, targets_full)) \n",
    "    \n",
    "    U1_fid_list.append(evaluate_channel(U_channel1, inputs1, targets1))\n",
    "    U2_fid_list.append(evaluate_channel(U_channel2, inputs2, targets2))\n",
    "    U3_fid_list.append(evaluate_channel(U_channel_full, inputs_full, targets_full))\n",
    "\n",
    "    T1_fid_list.append(evaluate_channel(channel1, inputs1, targets1))\n",
    "    T2_fid_list.append(evaluate_channel(channel2, inputs2, targets2))\n",
    "    T12_fid_list.append(evaluate_channel(channel_concat, inputs_full, targets_full))\n",
    "    T3_fid_list.append(evaluate_channel(channel_full, inputs_full, targets_full))\n",
    "    \n",
    "\n",
    "R1_fid_mean = np.mean(R1_fid_list)\n",
    "R2_fid_mean = np.mean(R2_fid_list)\n",
    "R3_fid_mean = np.mean(R3_fid_list)   \n",
    "    \n",
    "U1_fid_mean = np.mean(U1_fid_list)\n",
    "U2_fid_mean = np.mean(U2_fid_list)\n",
    "U3_fid_mean = np.mean(U3_fid_list)\n",
    "\n",
    "T1_fid_mean = np.mean(T1_fid_list)\n",
    "T2_fid_mean = np.mean(T2_fid_list)\n",
    "T12_fid_mean = np.mean(T12_fid_list)\n",
    "T3_fid_mean = np.mean(T3_fid_list)\n",
    "\n",
    "R1_fid_std = np.std(R1_fid_list)\n",
    "R2_fid_std = np.std(R2_fid_list)\n",
    "R3_fid_std = np.std(R3_fid_list)   \n",
    "\n",
    "U1_fid_std = np.std(U1_fid_list)\n",
    "U2_fid_std = np.std(U2_fid_list)\n",
    "U3_fid_std = np.std(U3_fid_list)\n",
    "\n",
    "T1_fid_std = np.std(T1_fid_list)\n",
    "T2_fid_std = np.std(T2_fid_list)\n",
    "T12_fid_std = np.std(T12_fid_list)\n",
    "T3_fid_std = np.std(T3_fid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R1 KL-Div: 0.13294 +-0.01040\n",
      "R2 KL-Div: 0.12627 +-0.01352\n",
      "R_full KL-Div: 0.1247 +-0.00988\n",
      "----\n",
      "U1 KL-Div: 0.06576 +-0.01772\n",
      "U2 KL-Div: 0.06506 +-0.01877\n",
      "U_full KL-Div: 0.0619 +-0.01502\n",
      "----\n",
      "T1 KL-Div: 0.00085 +-0.00015\n",
      "T2 KL-Div: 0.00130 +-0.00095\n",
      "T12 KL-Div: 0.00533 +-0.00061\n",
      "T3 KL-Div: 0.00067 +-0.00013\n"
     ]
    }
   ],
   "source": [
    "print(f\"R1 KL-Div: {R1_fid_mean:.5f} +-{R1_fid_std:.5f}\")\n",
    "print(f\"R2 KL-Div: {R2_fid_mean:.5f} +-{R2_fid_std:.5f}\")\n",
    "print(f\"R_full KL-Div: {R3_fid_mean:.4f} +-{R3_fid_std:.5f}\")\n",
    "print(\"----\")\n",
    "print(f\"U1 KL-Div: {U1_fid_mean:.5f} +-{U1_fid_std:.5f}\")\n",
    "print(f\"U2 KL-Div: {U2_fid_mean:.5f} +-{U2_fid_std:.5f}\")\n",
    "print(f\"U_full KL-Div: {U3_fid_mean:.4f} +-{U3_fid_std:.5f}\")\n",
    "print(\"----\")\n",
    "print(f\"T1 KL-Div: {T1_fid_mean:.5f} +-{T1_fid_std:.5f}\")\n",
    "print(f\"T2 KL-Div: {T2_fid_mean:.5f} +-{T2_fid_std:.5f}\")\n",
    "print(f\"T12 KL-Div: {T12_fid_mean:.5f} +-{T12_fid_std:.5f}\")\n",
    "print(f\"T3 KL-Div: {T3_fid_mean:.5f} +-{T3_fid_std:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = loader(data_path(\"belem_concatenate_4layer_fitted.model\"))\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "n=3\n",
    "d = 2**n\n",
    "\n",
    "R1_fid_list = []\n",
    "R2_fid_list = []\n",
    "R3_fid_list = []\n",
    "\n",
    "U1_fid_list = []\n",
    "U2_fid_list = []\n",
    "U3_fid_list = []\n",
    "\n",
    "T1_fid_list = []\n",
    "T2_fid_list = []\n",
    "T12_fid_list = []\n",
    "T3_fid_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    inputs1, targets1, _, _ = loader(data_path(f\"belem_concatenate_4layer{i}0\"))\n",
    "    inputs2, targets2, _, _ = loader(data_path(f\"belem_concatenate_4layer{i}1\"))\n",
    "    inputs_full, targets_full, _, _ = loader(data_path(f\"belem_concatenate_4layer{i}2\"))\n",
    "    \n",
    "    model1 = model_list[3*i]\n",
    "    model2 = model_list[3*i+1]\n",
    "    model_full = model_list[3*i+2]\n",
    "    \n",
    "    channel1 = model1.channel\n",
    "    channel2 = model2.channel\n",
    "    channel_full = model_full.channel\n",
    "\n",
    "    channel_concat = channel_to_choi_map([channel1, channel2])\n",
    "    channel_concat.spam = channel_full.spam\n",
    "    \n",
    "    identity_channel1 = IdentityChannel(d)\n",
    "    identity_channel1.spam = channel1.spam\n",
    "\n",
    "    identity_channel2 = IdentityChannel(d)\n",
    "    identity_channel2.spam = channel2.spam\n",
    "\n",
    "    identity_channel_full = IdentityChannel(d)\n",
    "    identity_channel_full.spam = channel_full.spam\n",
    "    \n",
    "    circuit1 = pqc_basic(n, 4)\n",
    "    U1 = circuit_to_matrix(circuit1)\n",
    "\n",
    "    circuit2 = pqc_basic(n, 4)\n",
    "    U2 = circuit_to_matrix(circuit2)\n",
    "\n",
    "    circuit_full = deepcopy(circuit1)\n",
    "    circuit_full = circuit_full.compose(circuit2)\n",
    "    U_full = circuit_to_matrix(circuit_full)\n",
    "\n",
    "    U_channel1 = ChoiMapStatic(U1, mode=\"unitary\")\n",
    "    U_channel1.spam = channel1.spam\n",
    "\n",
    "    U_channel2 = ChoiMapStatic(U2, mode=\"unitary\")\n",
    "    U_channel2.spam = channel2.spam\n",
    "\n",
    "    U_channel_full = ChoiMapStatic(U_full, mode=\"unitary\")\n",
    "    U_channel_full.spam = channel_full.spam\n",
    "    \n",
    "    R1_fid_list.append(evaluate_channel(identity_channel1, inputs1, targets1))\n",
    "    R2_fid_list.append(evaluate_channel(identity_channel2, inputs2, targets2))\n",
    "    R3_fid_list.append(evaluate_channel(identity_channel_full, inputs_full, targets_full)) \n",
    "    \n",
    "    U1_fid_list.append(evaluate_channel(U_channel1, inputs1, targets1))\n",
    "    U2_fid_list.append(evaluate_channel(U_channel2, inputs2, targets2))\n",
    "    U3_fid_list.append(evaluate_channel(U_channel_full, inputs_full, targets_full))\n",
    "\n",
    "    T1_fid_list.append(evaluate_channel(channel1, inputs1, targets1))\n",
    "    T2_fid_list.append(evaluate_channel(channel2, inputs2, targets2))\n",
    "    T12_fid_list.append(evaluate_channel(channel_concat, inputs_full, targets_full))\n",
    "    T3_fid_list.append(evaluate_channel(channel_full, inputs_full, targets_full))\n",
    "    \n",
    "\n",
    "R1_fid_mean = np.mean(R1_fid_list)\n",
    "R2_fid_mean = np.mean(R2_fid_list)\n",
    "R3_fid_mean = np.mean(R3_fid_list)   \n",
    "    \n",
    "U1_fid_mean = np.mean(U1_fid_list)\n",
    "U2_fid_mean = np.mean(U2_fid_list)\n",
    "U3_fid_mean = np.mean(U3_fid_list)\n",
    "\n",
    "T1_fid_mean = np.mean(T1_fid_list)\n",
    "T2_fid_mean = np.mean(T2_fid_list)\n",
    "T12_fid_mean = np.mean(T12_fid_list)\n",
    "T3_fid_mean = np.mean(T3_fid_list)\n",
    "\n",
    "R1_fid_std = np.std(R1_fid_list)\n",
    "R2_fid_std = np.std(R2_fid_list)\n",
    "R3_fid_std = np.std(R3_fid_list)   \n",
    "\n",
    "U1_fid_std = np.std(U1_fid_list)\n",
    "U2_fid_std = np.std(U2_fid_list)\n",
    "U3_fid_std = np.std(U3_fid_list)\n",
    "\n",
    "T1_fid_std = np.std(T1_fid_list)\n",
    "T2_fid_std = np.std(T2_fid_list)\n",
    "T12_fid_std = np.std(T12_fid_list)\n",
    "T3_fid_std = np.std(T3_fid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refrence 1 KL-Div: 0.1156\n",
      "Refrence 2 KL-Div: 0.1321\n",
      "Refrence Full KL-Div: 0.1100\n",
      "----\n",
      "U1 KL-Div: 0.0609\n",
      "U2 KL-Div: 0.0694\n",
      "U_full KL-Div: 0.0631\n",
      "----\n",
      "T1 KL-Div: 0.0006\n",
      "T2 KL-Div: 0.0007\n",
      "T2*T1 KL-Div: 0.0046\n",
      "T_full KL-Div: 0.0002\n"
     ]
    }
   ],
   "source": [
    "print(f\"Refrence 1 KL-Div: {evaluate_channel(identity_channel1, inputs1, targets1):.4f}\")\n",
    "print(f\"Refrence 2 KL-Div: {evaluate_channel(identity_channel2, inputs2, targets2):.4f}\")\n",
    "print(f\"Refrence Full KL-Div: {evaluate_channel(identity_channel_full, inputs_full, targets_full):.4f}\")\n",
    "print(\"----\")\n",
    "print(f\"U1 KL-Div: {evaluate_channel(U_channel1, inputs1, targets1):.4f}\")\n",
    "print(f\"U2 KL-Div: {evaluate_channel(U_channel2, inputs2, targets2):.4f}\")\n",
    "print(f\"U_full KL-Div: {evaluate_channel(U_channel_full, inputs_full, targets_full):.4f}\")\n",
    "print(\"----\")\n",
    "print(f\"T1 KL-Div: {evaluate_channel(channel1, inputs1, targets1):.4f}\")\n",
    "print(f\"T2 KL-Div: {evaluate_channel(channel2, inputs2, targets2):.4f}\")\n",
    "print(f\"T2*T1 KL-Div: {evaluate_channel(channel_concat, inputs_full, targets_full):.4f}\")\n",
    "print(f\"T_full KL-Div: {evaluate_channel(channel_full, inputs_full, targets_full):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m inputs2, targets2, _, _ \u001b[38;5;241m=\u001b[39m loader(data_path(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbelem_concatenate_8layer\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     24\u001b[0m inputs_full, targets_full, _, _ \u001b[38;5;241m=\u001b[39m loader(data_path(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbelem_concatenate_8layer\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m---> 26\u001b[0m model1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     27\u001b[0m model2 \u001b[38;5;241m=\u001b[39m model_list[\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     28\u001b[0m model_full \u001b[38;5;241m=\u001b[39m model_list[\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "model_list = loader(data_path(\"belem_concatenate_8layer_fitted.model\"))\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "n=3\n",
    "d = 2**n\n",
    "\n",
    "R1_fid_list = []\n",
    "R2_fid_list = []\n",
    "R3_fid_list = []\n",
    "\n",
    "U1_fid_list = []\n",
    "U2_fid_list = []\n",
    "U3_fid_list = []\n",
    "\n",
    "T1_fid_list = []\n",
    "T2_fid_list = []\n",
    "T12_fid_list = []\n",
    "T3_fid_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    inputs1, targets1, _, _ = loader(data_path(f\"belem_concatenate_8layer{i}0\"))\n",
    "    inputs2, targets2, _, _ = loader(data_path(f\"belem_concatenate_8layer{i}1\"))\n",
    "    inputs_full, targets_full, _, _ = loader(data_path(f\"belem_concatenate_8layer{i}2\"))\n",
    "    \n",
    "    model1 = model_list[3*i]\n",
    "    model2 = model_list[3*i+1]\n",
    "    model_full = model_list[3*i+2]\n",
    "    \n",
    "    channel1 = model1.channel\n",
    "    channel2 = model2.channel\n",
    "    channel_full = model_full.channel\n",
    "\n",
    "    channel_concat = channel_to_choi_map([channel1, channel2])\n",
    "    channel_concat.spam = channel_full.spam\n",
    "    \n",
    "    identity_channel1 = IdentityChannel(d)\n",
    "    identity_channel1.spam = channel1.spam\n",
    "\n",
    "    identity_channel2 = IdentityChannel(d)\n",
    "    identity_channel2.spam = channel2.spam\n",
    "\n",
    "    identity_channel_full = IdentityChannel(d)\n",
    "    identity_channel_full.spam = channel_full.spam\n",
    "    \n",
    "    circuit1 = pqc_basic(n, 8)\n",
    "    U1 = circuit_to_matrix(circuit1)\n",
    "\n",
    "    circuit2 = pqc_basic(n, 8)\n",
    "    U2 = circuit_to_matrix(circuit2)\n",
    "\n",
    "    circuit_full = deepcopy(circuit1)\n",
    "    circuit_full = circuit_full.compose(circuit2)\n",
    "    U_full = circuit_to_matrix(circuit_full)\n",
    "\n",
    "    U_channel1 = ChoiMapStatic(U1, mode=\"unitary\")\n",
    "    U_channel1.spam = channel1.spam\n",
    "\n",
    "    U_channel2 = ChoiMapStatic(U2, mode=\"unitary\")\n",
    "    U_channel2.spam = channel2.spam\n",
    "\n",
    "    U_channel_full = ChoiMapStatic(U_full, mode=\"unitary\")\n",
    "    U_channel_full.spam = channel_full.spam\n",
    "    \n",
    "    R1_fid_list.append(evaluate_channel(identity_channel1, inputs1, targets1))\n",
    "    R2_fid_list.append(evaluate_channel(identity_channel2, inputs2, targets2))\n",
    "    R3_fid_list.append(evaluate_channel(identity_channel_full, inputs_full, targets_full)) \n",
    "    \n",
    "    U1_fid_list.append(evaluate_channel(U_channel1, inputs1, targets1))\n",
    "    U2_fid_list.append(evaluate_channel(U_channel2, inputs2, targets2))\n",
    "    U3_fid_list.append(evaluate_channel(U_channel_full, inputs_full, targets_full))\n",
    "\n",
    "    T1_fid_list.append(evaluate_channel(channel1, inputs1, targets1))\n",
    "    T2_fid_list.append(evaluate_channel(channel2, inputs2, targets2))\n",
    "    T12_fid_list.append(evaluate_channel(channel_concat, inputs_full, targets_full))\n",
    "    T3_fid_list.append(evaluate_channel(channel_full, inputs_full, targets_full))\n",
    "    \n",
    "\n",
    "R1_fid_mean = np.mean(R1_fid_list)\n",
    "R2_fid_mean = np.mean(R2_fid_list)\n",
    "R3_fid_mean = np.mean(R3_fid_list)   \n",
    "    \n",
    "U1_fid_mean = np.mean(U1_fid_list)\n",
    "U2_fid_mean = np.mean(U2_fid_list)\n",
    "U3_fid_mean = np.mean(U3_fid_list)\n",
    "\n",
    "T1_fid_mean = np.mean(T1_fid_list)\n",
    "T2_fid_mean = np.mean(T2_fid_list)\n",
    "T12_fid_mean = np.mean(T12_fid_list)\n",
    "T3_fid_mean = np.mean(T3_fid_list)\n",
    "\n",
    "R1_fid_std = np.std(R1_fid_list)\n",
    "R2_fid_std = np.std(R2_fid_list)\n",
    "R3_fid_std = np.std(R3_fid_list)   \n",
    "\n",
    "U1_fid_std = np.std(U1_fid_list)\n",
    "U2_fid_std = np.std(U2_fid_list)\n",
    "U3_fid_std = np.std(U3_fid_list)\n",
    "\n",
    "T1_fid_std = np.std(T1_fid_list)\n",
    "T2_fid_std = np.std(T2_fid_list)\n",
    "T12_fid_std = np.std(T12_fid_list)\n",
    "T3_fid_std = np.std(T3_fid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refrence 1 KL-Div: 0.1149\n",
      "Refrence 2 KL-Div: 0.1149\n",
      "Refrence Full KL-Div: 0.1205\n",
      "----\n",
      "U1 KL-Div: 0.0593\n",
      "U2 KL-Div: 0.0637\n",
      "U_full KL-Div: 0.0553\n",
      "----\n",
      "T1 KL-Div: 0.0004\n",
      "T2 KL-Div: 0.0006\n",
      "T2*T1 KL-Div: 0.0018\n",
      "T_full KL-Div: 0.0002\n"
     ]
    }
   ],
   "source": [
    "print(f\"Refrence 1 KL-Div: {evaluate_channel(identity_channel1, inputs1, targets1):.4f}\")\n",
    "print(f\"Refrence 2 KL-Div: {evaluate_channel(identity_channel2, inputs2, targets2):.4f}\")\n",
    "print(f\"Refrence Full KL-Div: {evaluate_channel(identity_channel_full, inputs_full, targets_full):.4f}\")\n",
    "print(\"----\")\n",
    "print(f\"U1 KL-Div: {evaluate_channel(U_channel1, inputs1, targets1):.4f}\")\n",
    "print(f\"U2 KL-Div: {evaluate_channel(U_channel2, inputs2, targets2):.4f}\")\n",
    "print(f\"U_full KL-Div: {evaluate_channel(U_channel_full, inputs_full, targets_full):.4f}\")\n",
    "print(\"----\")\n",
    "print(f\"T1 KL-Div: {evaluate_channel(channel1, inputs1, targets1):.4f}\")\n",
    "print(f\"T2 KL-Div: {evaluate_channel(channel2, inputs2, targets2):.4f}\")\n",
    "print(f\"T2*T1 KL-Div: {evaluate_channel(channel_concat, inputs_full, targets_full):.4f}\")\n",
    "print(f\"T_full KL-Div: {evaluate_channel(channel_full, inputs_full, targets_full):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_qiskit",
   "language": "python",
   "name": "env_qiskit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling NIQS Hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qiskit as qk\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit.quantum_info import DensityMatrix\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_trace(X, discard_first = True):\n",
    "    d = X.shape[0]\n",
    "    d_red = int(np.sqrt(d))\n",
    "    Y = np.zeros((d_red, d_red), dtype = \"complex128\")\n",
    "    I = np.eye(d_red)\n",
    "    \n",
    "    for i in range(d_red):\n",
    "        basis_vec = np.zeros((d_red, 1),  dtype = \"complex128\")\n",
    "        basis_vec[i, 0] = 1\n",
    "        \n",
    "        if discard_first:\n",
    "            basis_vec = np.kron(basis_vec, I)\n",
    "        else:\n",
    "            basis_vec = np.kron(I, basis_vec)\n",
    "        \n",
    "        Y = Y + basis_vec.T@X@basis_vec\n",
    "    \n",
    "    return Y\n",
    "\n",
    "\n",
    "def state_fidelity(A, B):\n",
    "    sqrtA = sqrtm(A)\n",
    "    fidelity = np.trace(sqrtm(sqrtA@B@sqrtA))\n",
    "    return np.abs(fidelity)\n",
    "\n",
    "\n",
    "def apply_map(state, choi):\n",
    "    d = state.shape[0]\n",
    "    \n",
    "    #reshuffle\n",
    "    choi = choi.reshape(d,d,d,d).swapaxes(1,2).reshape(d**2, d**2)\n",
    "    \n",
    "    #flatten\n",
    "    state = state.reshape(-1, 1)\n",
    "    \n",
    "    state = (choi@state).reshape(d, d)\n",
    "    return state\n",
    "    \n",
    "\n",
    "def prepare_input(config):\n",
    "    \"\"\"1 = |0>, 2 = |1>, 3 = |+>, 4 = |->, 5 = |+i>, 6 = |-i>\"\"\"\n",
    "    n = len(config)\n",
    "    circuit = qk.QuantumCircuit(n)\n",
    "    for i, gate in enumerate(config):\n",
    "        if gate == 2:\n",
    "            circuit.x(i)\n",
    "        if gate == 3:\n",
    "            circuit.h(i)\n",
    "        if gate == 4:\n",
    "            circuit.x(i)\n",
    "            circuit.h(i)\n",
    "        if gate == 5:\n",
    "            circuit.h(i)\n",
    "            circuit.s(i)\n",
    "        if gate == 6:\n",
    "            circuit.x(i)\n",
    "            circuit.h(i)\n",
    "            circuit.s(i)\n",
    "        \n",
    "            \n",
    "    rho = DensityMatrix(circuit)\n",
    "    return rho.data\n",
    "\n",
    "\n",
    "def generate_ginibre(dim1, dim2, real = False):\n",
    "    ginibre = np.random.normal(0, 1, (dim1, dim2))\n",
    "    if not real:\n",
    "         ginibre = ginibre + 1j*np.random.normal(0, 1, (dim1, dim2))\n",
    "    return ginibre\n",
    "\n",
    "def generate_state(dim1, dim2):\n",
    "    X = generate_ginibre(dim1, dim2)\n",
    "    \n",
    "    state = X@X.conj().T/np.trace(X@X.conj().T)\n",
    "    return state\n",
    "\n",
    "def generate_choi(X):\n",
    "    d = int(np.sqrt(X.shape[0]))  # dim of Hilbert space\n",
    "    I = np.eye(d)\n",
    "\n",
    "    #partial trace\n",
    "    Y = partial_trace(X@(X.conj().T), discard_first = True)\n",
    "    sqrtYinv = np.linalg.inv(sqrtm(Y))\n",
    "\n",
    "    #choi\n",
    "    choi = np.kron(I, sqrtYinv)@X@(X.conj().T)@np.kron(I, sqrtYinv)\n",
    "    \n",
    "    return choi\n",
    "\n",
    "\n",
    "class Adam():\n",
    "    def __init__(self, dims, lr=0.01, beta1=0.9, beta2=0.999, eps=1e-8):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        \n",
    "        self.t = 0\n",
    "        self.m = np.zeros(dims, dtype=\"complex128\")\n",
    "        self.v = np.zeros(dims, dtype=\"complex128\")\n",
    "\n",
    "\n",
    "    def __call__(self, gradient):\n",
    "        self.t += 1\n",
    "\n",
    "        self.m = self.beta1 * self.m + (1 - self.beta1) * gradient\n",
    "        self.v = self.beta2 * self.v + (1 - self.beta2) * np.abs(gradient)**2\n",
    "\n",
    "        m_hat = self.m / (1 - self.beta1**self.t)\n",
    "        v_hat = self.v / (1 - self.beta2**self.t)\n",
    "        gradient_modified = m_hat / (np.sqrt(v_hat) + self.eps)\n",
    "\n",
    "        return gradient_modified\n",
    "    \n",
    "    \n",
    "class ModelQuantumMap:\n",
    "    def __init__(self, n, rank, lr, h):\n",
    "        self.n = n\n",
    "        self.rank = rank\n",
    "        self.lr = lr\n",
    "        self.h = h\n",
    "        \n",
    "        self.d = 2**n\n",
    "        self.X_model = generate_ginibre(self.d**2, self.rank)\n",
    "        \n",
    "        self.adam = Adam(dims = (self.d**2, self.rank))\n",
    "        self.fid_list = []  \n",
    "        \n",
    "    def train(self, choi_target, num_iter, use_adam=False):\n",
    "        for step in range(num_iter):  \n",
    "            grad_matrix = np.zeros((dim1, dim2), dtype=\"complex128\")\n",
    "            indicies = [np.random.randint(1,6) for i in range(n)]\n",
    "            state_input = prepare_input(indicies)\n",
    "            state_target = apply_map(state_input, choi_target)\n",
    "            h = self.h\n",
    "    \n",
    "            for i in range(self.d**2):\n",
    "                for j in range(self.rank):\n",
    "                    \n",
    "                    #Finite difference, real value\n",
    "                    self.X_model[i, j] += h\n",
    "                    choi_plus = generate_choi(self.X_model)\n",
    "                    state_plus = apply_map(state_input, choi_plus)\n",
    "                    fid_plus = state_fidelity(state_plus, state_target)\n",
    "\n",
    "                    self.X_model[i, j] -= 2*h\n",
    "                    choi_minus = generate_choi(self.X_model)\n",
    "                    state_minus = apply_map(state_input, choi_minus)\n",
    "                    fid_minus = state_fidelity(state_minus, state_target)\n",
    "                    self.X_model[i, j] += h\n",
    "\n",
    "                    grad = (fid_plus-fid_minus)/h\n",
    "                    grad_matrix[i, j] += grad \n",
    "\n",
    "                    #Finite difference, imaginary value\n",
    "                    self.X_model[i, j] += 1j*h\n",
    "                    choi_plus = generate_choi(self.X_model)\n",
    "                    state_plus = apply_map(state_input, choi_plus)\n",
    "                    fid_plus = state_fidelity(state_plus, state_target)\n",
    "\n",
    "                    self.X_model[i, j] -= 2j*h\n",
    "                    choi_minus = generate_choi(self.X_model)\n",
    "                    state_minus = apply_map(state_input, choi_minus)\n",
    "                    fid_minus = state_fidelity(state_minus, state_target)\n",
    "                    self.X_model[i, j] += 1j*h\n",
    "\n",
    "                    grad = 1j*(fid_plus-fid_minus)/h\n",
    "                    grad_matrix[i, j] += grad\n",
    "\n",
    "            if use_adam:\n",
    "                grad_matrix = self.adam(grad_matrix)\n",
    "                \n",
    "            self.X_model += self.lr*grad_matrix\n",
    "\n",
    "            choi_model = generate_choi(self.X_model)\n",
    "            state_model = apply_map(state_input, choi_model)\n",
    "            fid = state_fidelity(state_model, state_target)\n",
    "            \n",
    "            self.fid_list.append(fid)\n",
    "            print(f\"{step}: {fid:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.334\n",
      "1: 0.354\n",
      "2: 0.230\n",
      "3: 0.440\n",
      "4: 0.284\n",
      "5: 0.364\n",
      "6: 0.380\n",
      "7: 0.357\n",
      "8: 0.386\n",
      "9: 0.446\n",
      "10: 0.233\n",
      "11: 0.426\n",
      "12: 0.609\n",
      "13: 0.362\n",
      "14: 0.584\n",
      "15: 0.455\n",
      "16: 0.339\n",
      "17: 0.611\n",
      "18: 0.237\n",
      "19: 0.508\n",
      "20: 0.373\n",
      "21: 0.412\n",
      "22: 0.373\n",
      "23: 0.508\n",
      "24: 0.518\n",
      "25: 0.389\n",
      "26: 0.381\n",
      "27: 0.589\n",
      "28: 0.306\n",
      "29: 0.398\n",
      "30: 0.442\n",
      "31: 0.343\n",
      "32: 0.446\n",
      "33: 0.340\n",
      "34: 0.427\n",
      "35: 0.497\n",
      "36: 0.469\n",
      "37: 0.360\n",
      "38: 0.288\n",
      "39: 0.436\n",
      "40: 0.564\n",
      "41: 0.376\n",
      "42: 0.329\n",
      "43: 0.398\n",
      "44: 0.307\n",
      "45: 0.332\n",
      "46: 0.490\n",
      "47: 0.335\n",
      "48: 0.450\n",
      "49: 0.510\n",
      "50: 0.440\n",
      "51: 0.508\n",
      "52: 0.314\n",
      "53: 0.246\n",
      "54: 0.430\n",
      "55: 0.367\n",
      "56: 0.391\n",
      "57: 0.468\n",
      "58: 0.371\n",
      "59: 0.340\n",
      "60: 0.352\n",
      "61: 0.493\n",
      "62: 0.496\n",
      "63: 0.441\n",
      "64: 0.317\n",
      "65: 0.503\n",
      "66: 0.599\n",
      "67: 0.493\n",
      "68: 0.615\n",
      "69: 0.487\n",
      "70: 0.492\n",
      "71: 0.349\n",
      "72: 0.362\n",
      "73: 0.253\n",
      "74: 0.435\n",
      "75: 0.363\n",
      "76: 0.337\n",
      "77: 0.224\n",
      "78: 0.352\n",
      "79: 0.498\n",
      "80: 0.500\n",
      "81: 0.384\n",
      "82: 0.492\n",
      "83: 0.468\n",
      "84: 0.359\n",
      "85: 0.378\n",
      "86: 0.399\n",
      "87: 0.495\n",
      "88: 0.463\n",
      "89: 0.447\n",
      "90: 0.406\n",
      "91: 0.240\n",
      "92: 0.382\n",
      "93: 0.399\n",
      "94: 0.302\n",
      "95: 0.607\n",
      "96: 0.327\n",
      "97: 0.403\n",
      "98: 0.495\n",
      "99: 0.389\n",
      "100: 0.393\n",
      "101: 0.352\n",
      "102: 0.607\n",
      "103: 0.496\n",
      "104: 0.443\n",
      "105: 0.407\n",
      "106: 0.432\n",
      "107: 0.224\n",
      "108: 0.470\n",
      "109: 0.345\n",
      "110: 0.414\n",
      "111: 0.350\n",
      "112: 0.359\n",
      "113: 0.356\n",
      "114: 0.390\n",
      "115: 0.499\n",
      "116: 0.367\n",
      "117: 0.310\n",
      "118: 0.381\n",
      "119: 0.426\n",
      "120: 0.417\n",
      "121: 0.386\n",
      "122: 0.623\n",
      "123: 0.521\n",
      "124: 0.372\n",
      "125: 0.412\n",
      "126: 0.432\n",
      "127: 0.499\n",
      "128: 0.334\n",
      "129: 0.369\n",
      "130: 0.331\n",
      "131: 0.390\n",
      "132: 0.450\n",
      "133: 0.346\n",
      "134: 0.404\n",
      "135: 0.429\n",
      "136: 0.587\n",
      "137: 0.465\n",
      "138: 0.379\n",
      "139: 0.591\n",
      "140: 0.423\n",
      "141: 0.401\n",
      "142: 0.434\n",
      "143: 0.363\n",
      "144: 0.358\n",
      "145: 0.434\n",
      "146: 0.426\n",
      "147: 0.381\n",
      "148: 0.501\n",
      "149: 0.368\n",
      "150: 0.506\n",
      "151: 0.384\n",
      "152: 0.384\n",
      "153: 0.451\n",
      "154: 0.512\n",
      "155: 0.341\n",
      "156: 0.487\n",
      "157: 0.430\n",
      "158: 0.372\n",
      "159: 0.407\n",
      "160: 0.406\n",
      "161: 0.516\n",
      "162: 0.621\n",
      "163: 0.437\n",
      "164: 0.621\n",
      "165: 0.387\n",
      "166: 0.357\n",
      "167: 0.457\n",
      "168: 0.458\n",
      "169: 0.406\n",
      "170: 0.441\n",
      "171: 0.501\n",
      "172: 0.428\n",
      "173: 0.387\n",
      "174: 0.496\n",
      "175: 0.600\n",
      "176: 0.405\n",
      "177: 0.566\n",
      "178: 0.346\n",
      "179: 0.454\n",
      "180: 0.444\n",
      "181: 0.390\n",
      "182: 0.249\n",
      "183: 0.628\n",
      "184: 0.372\n",
      "185: 0.458\n",
      "186: 0.434\n",
      "187: 0.441\n",
      "188: 0.512\n",
      "189: 0.397\n",
      "190: 0.319\n",
      "191: 0.377\n",
      "192: 0.481\n",
      "193: 0.251\n",
      "194: 0.568\n",
      "195: 0.464\n",
      "196: 0.450\n",
      "197: 0.273\n",
      "198: 0.296\n",
      "199: 0.436\n",
      "200: 0.445\n",
      "201: 0.574\n",
      "202: 0.595\n",
      "203: 0.442\n",
      "204: 0.445\n",
      "205: 0.366\n",
      "206: 0.277\n",
      "207: 0.509\n",
      "208: 0.415\n",
      "209: 0.436\n",
      "210: 0.380\n",
      "211: 0.352\n",
      "212: 0.325\n",
      "213: 0.629\n",
      "214: 0.462\n",
      "215: 0.518\n",
      "216: 0.340\n",
      "217: 0.432\n",
      "218: 0.430\n",
      "219: 0.345\n",
      "220: 0.586\n",
      "221: 0.341\n",
      "222: 0.330\n",
      "223: 0.467\n",
      "224: 0.349\n",
      "225: 0.485\n",
      "226: 0.444\n",
      "227: 0.416\n",
      "228: 0.411\n",
      "229: 0.341\n",
      "230: 0.379\n",
      "231: 0.605\n",
      "232: 0.540\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-ca706943cc03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m model1.train(choi_target = choi_target, \n\u001b[1;32m     15\u001b[0m             \u001b[0mnum_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             use_adam = False)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-82-10157e76b3cb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, choi_target, num_iter, use_adam)\u001b[0m\n\u001b[1;32m    140\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                     \u001b[0mchoi_plus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_choi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                     \u001b[0mstate_plus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoi_plus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m                     \u001b[0mfid_plus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_fidelity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_plus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-82-10157e76b3cb>\u001b[0m in \u001b[0;36mapply_map\u001b[0;34m(state, choi)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchoi\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "d = 2**n\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X_target = generate_ginibre(d**2, 2)\n",
    "choi_target = generate_choi(X_target)\n",
    "\n",
    "model1 = ModelQuantumMap(n = 3, \n",
    "                         rank = 2, \n",
    "                         lr = 0.5, \n",
    "                         h = 1e-4)\n",
    "\n",
    "model1.train(choi_target = choi_target, \n",
    "             num_iter = 1000, \n",
    "             use_adam = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "d = 2**n\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X_target = generate_ginibre(d**2, 2)\n",
    "choi_target = generate_choi(X_target)\n",
    "\n",
    "model2 = ModelQuantumMap(n = 3, \n",
    "                         rank = 2, \n",
    "                         lr = 0.05, \n",
    "                         h = 1e-4)\n",
    "\n",
    "model2.train(choi_target = choi_target, \n",
    "            num_iter = 1000, \n",
    "            use_adam = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_qiskit",
   "language": "python",
   "name": "env_qiskit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
